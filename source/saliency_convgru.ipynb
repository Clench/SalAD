{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "from csv import reader\n",
    "from os import listdir, makedirs, path\n",
    "from pickle import dump\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from model import Seq2Seq, RecurrentAutoencoder, DNNAE, SalTransformer, SalAE, SalSCINet, SalGATSCINet, SalGATSCINetV2, SalGATConvLSTM, SalGATConvGRU, ConvGRU, SalGATConvGRUwoSal, SalConvGRUwoALL, SalGATConvGRUwoGAT\n",
    "\n",
    "\n",
    "import os, random\n",
    "import torch\n",
    "from torch.nn import TransformerAE\n",
    "from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "# from args import get_parser\n",
    "\n",
    "\n",
    "def load_and_save(category, filename, dataset, dataset_folder, output_folder):\n",
    "    temp = np.genfromtxt(\n",
    "        path.join(dataset_folder, category, filename),\n",
    "        dtype=np.float32,\n",
    "        delimiter=\",\",\n",
    "    )\n",
    "    print(dataset, category, filename, temp.shape)\n",
    "    with open(path.join(output_folder, dataset + \"_\" + category + \".pkl\"), \"wb\") as file:\n",
    "        dump(temp, file)\n",
    "\n",
    "\n",
    "def load_data(dataset):\n",
    "    \"\"\" Method from OmniAnomaly (https://github.com/NetManAIOps/OmniAnomaly) \"\"\"\n",
    "\n",
    "    if dataset == \"SMD\":\n",
    "        dataset_folder = \"/home/sangyup/saliency_anomaly_detection/dataset/ServerMachineDataset\"\n",
    "        output_folder = \"/home/sangyup/saliency_anomaly_detection/dataset/ServerMachineDataset/processed\"\n",
    "        makedirs(output_folder, exist_ok=True)\n",
    "        file_list = listdir(path.join(dataset_folder, \"train\"))\n",
    "        for filename in file_list:\n",
    "            if filename.endswith(\".txt\"):\n",
    "                load_and_save(\n",
    "                    \"train\",\n",
    "                    filename,\n",
    "                    filename.strip(\".txt\"),\n",
    "                    dataset_folder,\n",
    "                    output_folder,\n",
    "                )\n",
    "                load_and_save(\n",
    "                    \"test_label\",\n",
    "                    filename,\n",
    "                    filename.strip(\".txt\"),\n",
    "                    dataset_folder,\n",
    "                    output_folder,\n",
    "                )\n",
    "                load_and_save(\n",
    "                    \"test\",\n",
    "                    filename,\n",
    "                    filename.strip(\".txt\"),\n",
    "                    dataset_folder,\n",
    "                    output_folder,\n",
    "                )\n",
    "\n",
    "    elif dataset == \"SMAP\" or dataset == \"MSL\":\n",
    "        # Change the dataset path accordingly\n",
    "        dataset_folder = \"/SMAPMSL/data\"\n",
    "        output_folder = \"/SMAPMSL/data/processed\"\n",
    "        makedirs(output_folder, exist_ok=True)\n",
    "        with open(path.join(dataset_folder, \"labeled_anomalies.csv\"), \"r\") as file:\n",
    "            csv_reader = reader(file, delimiter=\",\")\n",
    "            res = [row for row in csv_reader][1:]\n",
    "        res = sorted(res, key=lambda k: k[0])\n",
    "        data_info = [row for row in res if row[1] == dataset and row[0] != \"P-2\"]\n",
    "        labels = []\n",
    "        for row in data_info:\n",
    "            anomalies = literal_eval(row[2])\n",
    "            length = int(row[-1])\n",
    "            label = np.zeros([length], dtype=np.bool_)\n",
    "            for anomaly in anomalies:\n",
    "                label[anomaly[0] : anomaly[1] + 1] = True\n",
    "            labels.extend(label)\n",
    "\n",
    "        labels = np.asarray(labels)\n",
    "        print(dataset, \"test_label\", labels.shape)\n",
    "\n",
    "        with open(path.join(output_folder, dataset + \"_\" + \"test_label\" + \".pkl\"), \"wb\") as file:\n",
    "            dump(labels, file)\n",
    "\n",
    "        def concatenate_and_save(category):\n",
    "            data = []\n",
    "            for row in data_info:\n",
    "                filename = row[0]\n",
    "                temp = np.load(path.join(dataset_folder, category, filename + \".npy\"))\n",
    "                data.extend(temp)\n",
    "            data = np.asarray(data)\n",
    "            print(dataset, category, data.shape)\n",
    "            with open(path.join(output_folder, dataset + \"_\" + category + \".pkl\"), \"wb\") as file:\n",
    "                dump(data, file)\n",
    "\n",
    "        for c in [\"train\", \"test\"]:\n",
    "            concatenate_and_save(c)\n",
    "\n",
    "def normalize_data(data, scaler=None):\n",
    "    data = np.asarray(data, dtype=np.float32)\n",
    "    if np.any(sum(np.isnan(data))):\n",
    "        data = np.nan_to_num(data)\n",
    "\n",
    "    if scaler is None:\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(data)\n",
    "    data = scaler.transform(data)\n",
    "    print(\"Data normalized\")\n",
    "\n",
    "    return data, scaler\n",
    "\n",
    "def get_data_dim(dataset):\n",
    "    \"\"\"\n",
    "    :param dataset: Name of dataset\n",
    "    :return: Number of dimensions in data\n",
    "    \"\"\"\n",
    "    if dataset == \"SMAP\":\n",
    "        return 25\n",
    "    elif dataset == \"MSL\":\n",
    "        return 55\n",
    "    elif str(dataset).startswith(\"machine\"):\n",
    "        return 38\n",
    "    else:\n",
    "        raise ValueError(\"unknown dataset \" + str(dataset))\n",
    "\n",
    "        \n",
    "def get_data(dataset, max_train_size=None, max_test_size=None,\n",
    "             normalize=False, spec_res=False, train_start=0, test_start=0):\n",
    "    \"\"\"\n",
    "    Get data from pkl files\n",
    "\n",
    "    return shape: (([train_size, x_dim], [train_size] or None), ([test_size, x_dim], [test_size]))\n",
    "    Method from OmniAnomaly (https://github.com/NetManAIOps/OmniAnomaly)\n",
    "    \"\"\"\n",
    "    prefix = \"/home/sangyup/saliency_anomaly_detection/dataset\"\n",
    "    if str(dataset).startswith(\"machine\"):\n",
    "        prefix += \"/ServerMachineDataset/processed\"\n",
    "    elif dataset in [\"MSL\", \"SMAP\"]:\n",
    "        prefix += \"/SMAPMSL/data/processed\"\n",
    "    if max_train_size is None:\n",
    "        train_end = None\n",
    "    else:\n",
    "        train_end = train_start + max_train_size\n",
    "    if max_test_size is None:\n",
    "        test_end = None\n",
    "    else:\n",
    "        test_end = test_start + max_test_size\n",
    "    print(\"load data of:\", dataset)\n",
    "    print(\"train: \", train_start, train_end)\n",
    "    print(\"test: \", test_start, test_end)\n",
    "    x_dim = get_data_dim(dataset)\n",
    "    f = open(os.path.join(prefix, dataset + \"_train.pkl\"), \"rb\")\n",
    "    train_data = pickle.load(f).reshape((-1, x_dim))[train_start:train_end, :]\n",
    "    f.close()\n",
    "    try:\n",
    "        f = open(os.path.join(prefix, dataset + \"_test.pkl\"), \"rb\")\n",
    "        test_data = pickle.load(f).reshape((-1, x_dim))[test_start:test_end, :]\n",
    "        f.close()\n",
    "    except (KeyError, FileNotFoundError):\n",
    "        test_data = None\n",
    "    try:\n",
    "        f = open(os.path.join(prefix, dataset + \"_test_label.pkl\"), \"rb\")\n",
    "        test_label = pickle.load(f).reshape((-1))[test_start:test_end]\n",
    "        f.close()\n",
    "    except (KeyError, FileNotFoundError):\n",
    "        test_label = None\n",
    "\n",
    "    if normalize:\n",
    "        train_data, scaler = normalize_data(train_data, scaler=None)\n",
    "        test_data, _ = normalize_data(test_data, scaler=scaler)\n",
    "\n",
    "    print(\"train set shape: \", train_data.shape)\n",
    "    print(\"test set shape: \", test_data.shape)\n",
    "    print(\"test set label shape: \", None if test_label is None else test_label.shape)\n",
    "    return (train_data, None), (test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSL test_label (73729,)\n",
      "MSL train (58317, 55)\n",
      "MSL test (73729, 55)\n"
     ]
    }
   ],
   "source": [
    "ds = 'MSL'  # SMD / MSL / SMD\n",
    "load_data(ds.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data of: MSL\n",
      "train:  0 None\n",
      "test:  0 None\n",
      "Data normalized\n",
      "Data normalized\n",
      "train set shape:  (58317, 55)\n",
      "test set shape:  (73729, 55)\n",
      "test set label shape:  (73729,)\n"
     ]
    }
   ],
   "source": [
    "# SMD 1-1, 1-2, 1-3\n",
    "# (x_train, _), (x_test, y_test) = get_data('machine-1-1', normalize=True)\n",
    "\n",
    "# MSL\n",
    "# (x_train, _), (x_test, y_test) = get_data('MSL', normalize=True)\n",
    "\n",
    "# SMAP\n",
    "(x_train, _), (x_test, y_test) = get_data('SMAP', normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73629, 100, 55)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_series(series, n_past, n_future):\n",
    "    '''\n",
    "\n",
    "    :param series: input time series\n",
    "    :param n_past: number of past observations\n",
    "    :param n_future: number of future series\n",
    "    :return: X, y(label)\n",
    "    '''\n",
    "    X, y = list(), list()\n",
    "    for window_start in range(len(series)):\n",
    "        past_end = window_start + n_past\n",
    "        future_end = past_end + n_future\n",
    "        if future_end > len(series):\n",
    "            break\n",
    "        # slicing the past and future parts of the window\n",
    "        past, future = series[window_start:past_end, :], series[past_end:future_end, :]\n",
    "        X.append(past)\n",
    "        y.append(future)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "x_test_windowed, _ = split_series(x_test, 100, 1)\n",
    "np.array(x_test_windowed).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class ReconDataset(Dataset):\n",
    "    def __init__(self, data, window, target_cols):\n",
    "        self.data = torch.Tensor(data)\n",
    "        self.window = window\n",
    "        self.target_cols = target_cols\n",
    "        self.shape = self.__getshape__()\n",
    "        self.size = self.__getsize__()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index:index+self.window]\n",
    "        y = self.data[index:index+self.window]\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) -  self.window \n",
    "    \n",
    "    def __getshape__(self):\n",
    "        return (self.__len__(), *self.__getitem__(0)[0].shape)\n",
    "\n",
    "    def __getsize__(self):\n",
    "        return (self.__len__())\n",
    "\n",
    "class ForecastDataset(Dataset):\n",
    "    def __init__(self, data, window, target_cols):\n",
    "        self.data = torch.Tensor(data)\n",
    "        self.window = window\n",
    "        self.target_cols = target_cols\n",
    "        self.shape = self.__getshape__()\n",
    "        self.size = self.__getsize__()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index:index+self.window]\n",
    "        y = self.data[index+self.window,0:self.target_cols]\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) -  self.window \n",
    "    \n",
    "    def __getshape__(self):\n",
    "        return (self.__len__(), *self.__getitem__(0)[0].shape)\n",
    "    \n",
    "    def __getsize__(self):\n",
    "        return (self.__len__())\n",
    "\n",
    "class ReconForecastDataset(Dataset):\n",
    "    def __init__(self, data, window, horizon):\n",
    "        self.data = torch.Tensor(data)\n",
    "        self.window = window\n",
    "        self.horizon = horizon\n",
    "        self.shape = self.__getshape__()\n",
    "        self.size = self.__getsize__()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index:index+self.window]\n",
    "        y_recon = self.data[index:index+self.window]\n",
    "        y_fore = self.data[index+self.window:index+self.window+self.horizon]\n",
    "        return x, y_recon, y_fore\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) -  self.window \n",
    "    \n",
    "    def __getshape__(self):\n",
    "        return (self.__len__(), *self.__getitem__(0)[0].shape), (self.__len__(), *self.__getitem__(0)[1].shape), (self.__len__(), *self.__getitem__(0)[2].shape)\n",
    "    \n",
    "    def __getsize__(self):\n",
    "        return (self.__len__())\n",
    "\n",
    "\n",
    "def create_data_loaders(train_dataset, batch_size, val_split=0.1, shuffle=False, test_dataset=None):\n",
    "    train_loader, val_loader, test_loader = None, None, None\n",
    "    if val_split == 0.0:\n",
    "        print(f\"train_size: {len(train_dataset)}\")\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle, drop_last=True)\n",
    "\n",
    "    else:\n",
    "        dataset_size = len(train_dataset)\n",
    "        indices = list(range(dataset_size))\n",
    "        split = int(np.floor(val_split * dataset_size))\n",
    "        if shuffle:\n",
    "            np.random.shuffle(indices)\n",
    "        train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "        train_sampler = SubsetRandomSampler(train_indices)\n",
    "        valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle, sampler=train_sampler, drop_last=True)\n",
    "        val_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle, sampler=valid_sampler, drop_last=True)\n",
    "\n",
    "        print(f\"train_size: {len(train_indices)}\")\n",
    "        print(f\"validation_size: {len(val_indices)}\")\n",
    "\n",
    "    if test_dataset is not None:\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "        print(f\"test_size: {len(test_dataset)}\")\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "\n",
    "# From Informer\n",
    "\n",
    "class StandardScaler():\n",
    "    def __init__(self):\n",
    "        self.mean = 0.\n",
    "        self.std = 1.\n",
    "    \n",
    "    def fit(self, data):\n",
    "        self.mean = data.mean(0)\n",
    "        self.std = data.std(0)\n",
    "\n",
    "    def transform(self, data):\n",
    "        mean = torch.from_numpy(self.mean).type_as(data).to(data.device) if torch.is_tensor(data) else self.mean\n",
    "        std = torch.from_numpy(self.std).type_as(data).to(data.device) if torch.is_tensor(data) else self.std\n",
    "        return (data - mean) / std\n",
    "\n",
    "    def inverse_transform(self, data):\n",
    "        mean = torch.from_numpy(self.mean).type_as(data).to(data.device) if torch.is_tensor(data) else self.mean\n",
    "        std = torch.from_numpy(self.std).type_as(data).to(data.device) if torch.is_tensor(data) else self.std\n",
    "        return (data * std) + mean\n",
    "\n",
    "# 시간 특징을 freq에 따라 추출\n",
    "def time_features(dates, freq='h'):\n",
    "    dates['month'] = dates.date.apply(lambda row:row.month,1)\n",
    "    dates['day'] = dates.date.apply(lambda row:row.day,1)\n",
    "    dates['weekday'] = dates.date.apply(lambda row:row.weekday(),1)\n",
    "    dates['hour'] = dates.date.apply(lambda row:row.hour,1)\n",
    "    dates['minute'] = dates.date.apply(lambda row:row.minute,1)\n",
    "    dates['minute'] = dates.minute.map(lambda x:x//15)\n",
    "    freq_map = {\n",
    "        'y':[],'m':['month'],'w':['month'],'d':['month','day','weekday'],\n",
    "        'b':['month','day','weekday'],'h':['month','day','weekday','hour'],\n",
    "        't':['month','day','weekday','hour','minute'],\n",
    "    }\n",
    "    return dates[freq_map[freq.lower()]].values\n",
    "\n",
    "# 한번의 batch를 실행하는 코드\n",
    "def _process_one_batch(batch_x, batch_y, batch_x_mark, batch_y_mark):\n",
    "    batch_x = batch_x.float().to(device)\n",
    "    batch_y = batch_y.float()\n",
    "    batch_x_mark = batch_x_mark.float().to(device)\n",
    "    batch_y_mark = batch_y_mark.float().to(device)\n",
    "    dec_inp = torch.zeros([batch_y.shape[0], pred_len, batch_y.shape[-1]]).float()\n",
    "    dec_inp = torch.cat([batch_y[:,:label_len,:], dec_inp], dim=1).float().to(device)\n",
    "    outputs = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "    batch_y = batch_y[:,-pred_len:,0:].to(device)\n",
    "    return outputs, batch_y\n",
    "\n",
    "\n",
    "class Dataset_Pred(Dataset):\n",
    "    def __init__(self, dataframe, size=None, scale=True):\n",
    "        self.seq_len = size[0]\n",
    "        self.label_len = size[1]\n",
    "        self.pred_len = size[2]\n",
    "        self.dataframe = dataframe\n",
    "        \n",
    "        self.scale = scale\n",
    "        self.__read_data__()\n",
    "\n",
    "    def __read_data__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        df_raw = self.dataframe\n",
    "        df_raw[\"date\"] = pd.to_datetime(df_raw[\"date\"])\n",
    "\n",
    "        delta = df_raw[\"date\"].iloc[1] - df_raw[\"date\"].iloc[0]\n",
    "        if delta>=timedelta(hours=1):\n",
    "            self.freq='h'\n",
    "        else:\n",
    "            self.freq='t'\n",
    "\n",
    "        border1 = 0\n",
    "        border2 = len(df_raw)\n",
    "        cols_data = df_raw.columns[1:]\n",
    "        df_data = df_raw[cols_data]\n",
    "\n",
    "\n",
    "        if self.scale:\n",
    "            self.scaler.fit(df_data.values)\n",
    "            data = self.scaler.transform(df_data.values)\n",
    "        else:\n",
    "            data = df_data.values\n",
    "            \n",
    "        tmp_stamp = df_raw[['date']][border1:border2]\n",
    "        tmp_stamp['date'] = pd.to_datetime(tmp_stamp.date)\n",
    "        pred_dates = pd.date_range(tmp_stamp.date.values[-1], periods=self.pred_len+1, freq=self.freq)\n",
    "        \n",
    "        df_stamp = pd.DataFrame(columns = ['date'])\n",
    "        df_stamp.date = list(tmp_stamp.date.values) + list(pred_dates[1:])\n",
    "        data_stamp = time_features(df_stamp, freq=self.freq)\n",
    "\n",
    "        self.data_x = data[border1:border2]\n",
    "        self.data_y = data[border1:border2]\n",
    "        self.data_stamp = data_stamp\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        s_begin = index\n",
    "        s_end = s_begin + self.seq_len\n",
    "        r_begin = s_end - self.label_len\n",
    "        r_end = r_begin + self.label_len + self.pred_len\n",
    "\n",
    "        seq_x = self.data_x[s_begin:s_end]\n",
    "        seq_y = self.data_y[r_begin:r_end]\n",
    "        seq_x_mark = self.data_stamp[s_begin:s_end]\n",
    "        seq_y_mark = self.data_stamp[r_begin:r_end]\n",
    "        return seq_x, seq_y, seq_x_mark, seq_y_mark\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_x) - self.seq_len- self.pred_len + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size: 40745\n",
      "validation_size: 17462\n",
      "test_size: 73629\n"
     ]
    }
   ],
   "source": [
    "window_size = 100\n",
    "batch_size = 512\n",
    "horizon = 10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = ReconForecastDataset(x_train, window_size, horizon)\n",
    "indices = torch.arange(len(train_dataset)-horizon)\n",
    "train_dataset = torch.utils.data.Subset(train_dataset, indices)\n",
    "test_dataset = ReconForecastDataset(x_test, window_size, horizon)\n",
    "\n",
    "train_loader, val_loader, test_loader = create_data_loaders(train_dataset, batch_size, val_split=0.3, shuffle=False, test_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "plt.figure(figsize=(10,6))\n",
    "total_len = len(x_test)\n",
    "\n",
    "plt.plot(x_test[:total_len])\n",
    "plt.plot(y_test[:total_len]*-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "def train_model(dataloader, val_loader, model, batch_size, n_epochs, model_name):\n",
    "    optimizer = torch.optim.AdamW(model.parameters())\n",
    "    \n",
    "    loss_fn_AE = torch.nn.MSELoss()\n",
    "    loss_fn_sci = torch.nn.MSELoss()\n",
    "\n",
    "    epochs = range(n_epochs)\n",
    "    best = {\"loss\": sys.float_info.max}\n",
    "    loss_history, loss_history_AE, loss_history_TF = [], [], []\n",
    "    val_loss_history, val_loss_history_AE, val_loss_history_TF = [], [], []\n",
    "    for e in epochs:\n",
    "        model.train()\n",
    "        start = time()\n",
    "        epoch_loss = 0\n",
    "        epoch_loss_AE = 0\n",
    "        epoch_loss_sci = 0\n",
    "        for i, (x,y_recon,y_fore) in enumerate(dataloader):  \n",
    "            optimizer.zero_grad()\n",
    "            x = x.cuda()\n",
    "            y_recon = y_recon.cuda()\n",
    "            y_fore = y_fore.cuda()\n",
    "            sal, dec_x, out = model(x)\n",
    "            \n",
    "            loss_AE = loss_fn_AE(y_recon, dec_x)\n",
    "            loss_sci = loss_fn_sci(y_fore, out)\n",
    "            loss = loss_AE + loss_sci\n",
    "            loss.backward()\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_loss_AE += loss_AE.item()\n",
    "            epoch_loss_sci += loss_sci.item()\n",
    "            optimizer.step()\n",
    "        loss_history.append(epoch_loss)\n",
    "        loss_history_AE.append(epoch_loss_AE)\n",
    "        loss_history_TF.append(epoch_loss_sci)\n",
    "\n",
    "        \n",
    "        # Validation step\n",
    "        model.eval()\n",
    "        val_epoch_loss = 0\n",
    "        val_epoch_loss_AE = 0\n",
    "        val_epoch_loss_sci = 0\n",
    "        with torch.no_grad():\n",
    "            for i, (x,y_recon,y_fore) in enumerate(val_loader):  \n",
    "                x = x.cuda()\n",
    "                y_recon = y_recon.cuda()\n",
    "                y_fore = y_fore.cuda()\n",
    "                sal, dec_x, out = model(x)\n",
    "\n",
    "                valloss_AE = loss_fn_AE(y_recon, dec_x)\n",
    "                valloss_sci = loss_fn_sci(y_fore, out)\n",
    "                valloss = valloss_AE + valloss_sci\n",
    "                \n",
    "                val_epoch_loss += valloss.item()\n",
    "                val_epoch_loss_AE += valloss_AE.item()\n",
    "                val_epoch_loss_sci += valloss_sci.item()\n",
    "                \n",
    "                val_loss_history.append(val_epoch_loss)\n",
    "                val_loss_history_AE.append(val_epoch_loss_AE)\n",
    "                val_loss_history_TF.append(val_epoch_loss_sci)  \n",
    "\n",
    "        print(f'Training loss EPOCH: [{e+1}|{len(epochs)}], training loss: [{epoch_loss}], AE loss: [{epoch_loss_AE}], TF loss: [{epoch_loss_sci}] took', time()-start)\n",
    "        print(f'Validation loss EPOCH: [{e+1}|{len(epochs)}], validation loss: [{val_epoch_loss}], AE loss: [{val_epoch_loss_AE}], TF loss: [{val_epoch_loss_sci}]')\n",
    "        if val_epoch_loss < best[\"loss\"]:\n",
    "            best[\"state\"] = model.state_dict()\n",
    "            best[\"loss\"] = val_epoch_loss\n",
    "            best[\"loss_AE\"] = val_epoch_loss_AE\n",
    "            best[\"loss_TF\"] = val_epoch_loss_sci\n",
    "            best[\"epoch\"] = e + 1\n",
    "            with open(\"result/model_\" + model_name + \"_best.pt\", \"wb\") as f:\n",
    "                torch.save(\n",
    "                    {\n",
    "                        \"state\": best[\"state\"],\n",
    "                        \"best_epoch\": best[\"epoch\"],\n",
    "                        \"loss_history\": val_loss_history,\n",
    "                        \"loss_AE_history\": val_loss_history_AE,\n",
    "                        \"loss_TF_history\": val_loss_history_TF,\n",
    "                    },\n",
    "                    f,\n",
    "                )\n",
    "\n",
    "    # Save last epoch\n",
    "    with open(\"result/model_\" + model_name + \"_last.pt\", \"wb\") as f:\n",
    "        torch.save(\n",
    "            {\n",
    "                \"state\": model.state_dict(),\n",
    "                \"best_epoch\": e + 1,\n",
    "                \"loss_history\": val_loss_history,\n",
    "                \"loss_AE_history\": val_loss_history_AE,\n",
    "                \"loss_TF_history\": val_loss_history_TF,\n",
    "            },\n",
    "            f,\n",
    "        )\n",
    "\n",
    "    return best, loss_history, loss_history_AE, loss_history_TF\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SalConvGRUwoALL(\n",
       "  (encoder): RecurEncoder(\n",
       "    (rnn1): GRU(55, 54, batch_first=True)\n",
       "    (rnn2): GRU(54, 27, batch_first=True)\n",
       "  )\n",
       "  (decoder): RecurDecoder(\n",
       "    (rnn1): GRU(27, 27, batch_first=True)\n",
       "    (rnn2): GRU(27, 54, batch_first=True)\n",
       "    (output_layer): Linear(in_features=54, out_features=55, bias=True)\n",
       "    (timedist): TimeDistributed(\n",
       "      (module): Linear(in_features=54, out_features=55, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (feature_gat): FeatureAttentionLayer(\n",
       "    (lin): Linear(in_features=100, out_features=100, bias=True)\n",
       "    (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (temporal_gat): TemporalAttentionLayer(\n",
       "    (lin): Linear(in_features=55, out_features=55, bias=True)\n",
       "    (leakyrelu): LeakyReLU(negative_slope=0.2)\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (convGRU): ConvGRU(\n",
       "    (cell_list): ModuleList(\n",
       "      (0): ConvGRUCell(\n",
       "        (conv_gates): Conv2d(87, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv_can): Conv2d(87, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (1): ConvGRUCell(\n",
       "        (conv_gates): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv_can): Conv2d(96, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=64, out_features=55, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "MODEL = SalGATConvGRU(seq_len=window_size, output_len=10, n_features=x_train.shape[1], out_n_features=x_train.shape[1], embedding_dim=int(x_train.shape[1]/2), kernel_size=3, cell='gru')\n",
    "# MODEL = SalGATConvGRUwoSal(seq_len=window_size, output_len=10, n_features=x_train.shape[1], out_n_features=x_train.shape[1], embedding_dim=int(x_train.shape[1]/2), kernel_size=3, cell='gru')\n",
    "# MODEL = SalConvGRUwoALL(seq_len=window_size, output_len=10, n_features=x_train.shape[1], out_n_features=x_train.shape[1], embedding_dim=int(x_train.shape[1]/2), kernel_size=3, cell='gru')\n",
    "MODEL.cuda()\n",
    "MODEL.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss EPOCH: [1|1000], training loss: [0.8351437486708164], AE loss: [0.4062061086297035], TF loss: [0.42893764143809676] took 9.77617073059082\n",
      "Validation loss EPOCH: [1|1000], validation loss: [0.33475812152028084], AE loss: [0.16696897009387612], TF loss: [0.167789151892066]\n",
      "Training loss EPOCH: [2|1000], training loss: [0.6546003115363419], AE loss: [0.3240144355222583], TF loss: [0.33058587717823684] took 9.586318969726562\n",
      "Validation loss EPOCH: [2|1000], validation loss: [0.3115943782031536], AE loss: [0.1542913462035358], TF loss: [0.15730303199961782]\n",
      "Training loss EPOCH: [3|1000], training loss: [0.635971758980304], AE loss: [0.31510387430898845], TF loss: [0.3208678839728236] took 9.682246685028076\n",
      "Validation loss EPOCH: [3|1000], validation loss: [0.2977301552891731], AE loss: [0.1492515429854393], TF loss: [0.14847861416637897]\n",
      "Training loss EPOCH: [4|1000], training loss: [0.6292705605737865], AE loss: [0.3122178551275283], TF loss: [0.3170527059119195] took 8.986626625061035\n",
      "Validation loss EPOCH: [4|1000], validation loss: [0.28632965171709657], AE loss: [0.14342643599957228], TF loss: [0.1429032157175243]\n",
      "Training loss EPOCH: [5|1000], training loss: [0.6241303011775017], AE loss: [0.31015755888074636], TF loss: [0.3139727453235537] took 9.348122119903564\n",
      "Validation loss EPOCH: [5|1000], validation loss: [0.28005252964794636], AE loss: [0.13922699494287372], TF loss: [0.140825534472242]\n",
      "Training loss EPOCH: [6|1000], training loss: [0.6194960419088602], AE loss: [0.30872484226711094], TF loss: [0.31077120266854763] took 9.000938177108765\n",
      "Validation loss EPOCH: [6|1000], validation loss: [0.277893609367311], AE loss: [0.13816661410965025], TF loss: [0.13972699455916882]\n",
      "Training loss EPOCH: [7|1000], training loss: [0.6163503373973072], AE loss: [0.3080669045448303], TF loss: [0.3082834321539849] took 9.538730144500732\n",
      "Validation loss EPOCH: [7|1000], validation loss: [0.27705089561641216], AE loss: [0.13780994550324976], TF loss: [0.1392409480176866]\n",
      "Training loss EPOCH: [8|1000], training loss: [0.6139257270842791], AE loss: [0.3077822995837778], TF loss: [0.3061434286646545] took 10.205691576004028\n",
      "Validation loss EPOCH: [8|1000], validation loss: [0.2764178579673171], AE loss: [0.13751437002792954], TF loss: [0.13890348630957305]\n",
      "Training loss EPOCH: [9|1000], training loss: [0.6115551963448524], AE loss: [0.30744841881096363], TF loss: [0.3041067759040743] took 9.621559143066406\n",
      "Validation loss EPOCH: [9|1000], validation loss: [0.27624251460656524], AE loss: [0.1373459321912378], TF loss: [0.1388965817168355]\n",
      "Training loss EPOCH: [10|1000], training loss: [0.6101630302146077], AE loss: [0.30740966508165], TF loss: [0.3027533639688045] took 11.467192649841309\n",
      "Validation loss EPOCH: [10|1000], validation loss: [0.2760308547876775], AE loss: [0.13728455873206258], TF loss: [0.1387462974525988]\n",
      "Training loss EPOCH: [11|1000], training loss: [0.608187307137996], AE loss: [0.3070828823838383], TF loss: [0.30110442684963346] took 9.567961931228638\n",
      "Validation loss EPOCH: [11|1000], validation loss: [0.27595645980909467], AE loss: [0.13709120033308864], TF loss: [0.13886525970883667]\n",
      "Training loss EPOCH: [12|1000], training loss: [0.6068200166337192], AE loss: [0.3070243245456368], TF loss: [0.2997956923209131] took 11.55317497253418\n",
      "Validation loss EPOCH: [12|1000], validation loss: [0.27567105926573277], AE loss: [0.1368585559539497], TF loss: [0.13881250470876694]\n",
      "Training loss EPOCH: [13|1000], training loss: [0.6057501868344843], AE loss: [0.30697326152585447], TF loss: [0.29877692623995245] took 9.665128946304321\n",
      "Validation loss EPOCH: [13|1000], validation loss: [0.2755118487402797], AE loss: [0.13671426521614194], TF loss: [0.13879758212715387]\n",
      "Training loss EPOCH: [14|1000], training loss: [0.604898929130286], AE loss: [0.3069732484873384], TF loss: [0.29792567784897983] took 17.652838706970215\n",
      "Validation loss EPOCH: [14|1000], validation loss: [0.2754008583724499], AE loss: [0.1366638164035976], TF loss: [0.13873704127036035]\n",
      "Training loss EPOCH: [15|1000], training loss: [0.6032721162773669], AE loss: [0.3067884617485106], TF loss: [0.2964836545288563] took 23.84848666191101\n",
      "Validation loss EPOCH: [15|1000], validation loss: [0.27590835001319647], AE loss: [0.1366770318709314], TF loss: [0.13923131953924894]\n",
      "Training loss EPOCH: [16|1000], training loss: [0.6020808350294828], AE loss: [0.30671495478600264], TF loss: [0.2953658795449883] took 20.3430016040802\n",
      "Validation loss EPOCH: [16|1000], validation loss: [0.2753812721930444], AE loss: [0.136447140481323], TF loss: [0.13893413124606013]\n",
      "Training loss EPOCH: [17|1000], training loss: [0.6007030848413706], AE loss: [0.3066302319057286], TF loss: [0.2940728508401662] took 20.917885065078735\n",
      "Validation loss EPOCH: [17|1000], validation loss: [0.27546550100669265], AE loss: [0.13641389505937696], TF loss: [0.13905160734429955]\n",
      "Training loss EPOCH: [18|1000], training loss: [0.5997018669731915], AE loss: [0.3066318838391453], TF loss: [0.2930699842981994] took 23.985634803771973\n",
      "Validation loss EPOCH: [18|1000], validation loss: [0.275259533431381], AE loss: [0.13623137841932476], TF loss: [0.1390281547792256]\n",
      "Training loss EPOCH: [19|1000], training loss: [0.5986822852864861], AE loss: [0.30655829631723464], TF loss: [0.29212398803792894] took 23.648763179779053\n",
      "Validation loss EPOCH: [19|1000], validation loss: [0.27530408650636673], AE loss: [0.13626875216141343], TF loss: [0.13903533248230815]\n",
      "Training loss EPOCH: [20|1000], training loss: [0.5978482449427247], AE loss: [0.3066544975154102], TF loss: [0.2911937478929758] took 24.34563946723938\n",
      "Validation loss EPOCH: [20|1000], validation loss: [0.27539259381592274], AE loss: [0.1363166207447648], TF loss: [0.13907597260549664]\n",
      "Training loss EPOCH: [21|1000], training loss: [0.5971592986024916], AE loss: [0.30672581773251295], TF loss: [0.29043348133563995] took 30.609954118728638\n",
      "Validation loss EPOCH: [21|1000], validation loss: [0.2750992556102574], AE loss: [0.13613332505337894], TF loss: [0.13896592915989459]\n",
      "Training loss EPOCH: [22|1000], training loss: [0.5963715496473014], AE loss: [0.3064257053192705], TF loss: [0.28994584549218416] took 30.506108045578003\n",
      "Validation loss EPOCH: [22|1000], validation loss: [0.27535515930503607], AE loss: [0.13614977453835309], TF loss: [0.1392053854651749]\n",
      "Training loss EPOCH: [23|1000], training loss: [0.5954611171036959], AE loss: [0.3064274883363396], TF loss: [0.2890336306300014] took 29.741992712020874\n",
      "Validation loss EPOCH: [23|1000], validation loss: [0.2752767940983176], AE loss: [0.13601535162888467], TF loss: [0.13926144293509424]\n",
      "Training loss EPOCH: [24|1000], training loss: [0.5946506857872009], AE loss: [0.30634904582984746], TF loss: [0.288301641587168] took 32.73847198486328\n",
      "Validation loss EPOCH: [24|1000], validation loss: [0.27560423873364925], AE loss: [0.13606069865636528], TF loss: [0.1395435407757759]\n",
      "Training loss EPOCH: [25|1000], training loss: [0.5938385874032974], AE loss: [0.3062407716643065], TF loss: [0.2875978173688054] took 30.538737773895264\n",
      "Validation loss EPOCH: [25|1000], validation loss: [0.2758892076089978], AE loss: [0.13607948296703398], TF loss: [0.13980972720310092]\n",
      "Training loss EPOCH: [26|1000], training loss: [0.5938336537219584], AE loss: [0.30643153958953917], TF loss: [0.2874021145980805] took 28.370853900909424\n",
      "Validation loss EPOCH: [26|1000], validation loss: [0.275411712937057], AE loss: [0.13600481767207384], TF loss: [0.13940689503215253]\n",
      "Training loss EPOCH: [27|1000], training loss: [0.5930422353558242], AE loss: [0.3064530217088759], TF loss: [0.2865892122499645] took 29.89420795440674\n",
      "Validation loss EPOCH: [27|1000], validation loss: [0.27548602875322104], AE loss: [0.1358275911770761], TF loss: [0.13965843641199172]\n",
      "Training loss EPOCH: [28|1000], training loss: [0.5925720385275781], AE loss: [0.3064164612442255], TF loss: [0.28615557635203004] took 36.52826905250549\n",
      "Validation loss EPOCH: [28|1000], validation loss: [0.27576075680553913], AE loss: [0.13590283505618572], TF loss: [0.13985791755840182]\n",
      "Training loss EPOCH: [29|1000], training loss: [0.5921146334148943], AE loss: [0.30645102355629206], TF loss: [0.2856636110227555] took 42.83589291572571\n",
      "Validation loss EPOCH: [29|1000], validation loss: [0.27593483636155725], AE loss: [0.13593835174106061], TF loss: [0.13999648462049663]\n",
      "Training loss EPOCH: [30|1000], training loss: [0.5913564404472709], AE loss: [0.30635125283151865], TF loss: [0.2850051855202764] took 41.90253233909607\n",
      "Validation loss EPOCH: [30|1000], validation loss: [0.2759592882357538], AE loss: [0.1358737382106483], TF loss: [0.14008554932661355]\n",
      "Training loss EPOCH: [31|1000], training loss: [0.5907676052302122], AE loss: [0.30631261388771236], TF loss: [0.2844549920409918] took 44.58194851875305\n",
      "Validation loss EPOCH: [31|1000], validation loss: [0.275934305973351], AE loss: [0.13576072151772678], TF loss: [0.14017358515411615]\n",
      "Training loss EPOCH: [32|1000], training loss: [0.5904699568636715], AE loss: [0.30640978645533323], TF loss: [0.28406017180532217] took 41.4997775554657\n",
      "Validation loss EPOCH: [32|1000], validation loss: [0.2761322883889079], AE loss: [0.13574911397881806], TF loss: [0.14038317534141243]\n",
      "Training loss EPOCH: [33|1000], training loss: [0.5895685805007815], AE loss: [0.306171587202698], TF loss: [0.28339699376374483] took 42.91056489944458\n",
      "Validation loss EPOCH: [33|1000], validation loss: [0.27626542653888464], AE loss: [0.13573968294076622], TF loss: [0.14052574546076357]\n",
      "Training loss EPOCH: [34|1000], training loss: [0.5893128286115825], AE loss: [0.30643237358890474], TF loss: [0.28288045478984714] took 42.75218439102173\n",
      "Validation loss EPOCH: [34|1000], validation loss: [0.27639396116137505], AE loss: [0.135768071282655], TF loss: [0.1406258896458894]\n",
      "Training loss EPOCH: [35|1000], training loss: [0.5882757259532809], AE loss: [0.30624496401287615], TF loss: [0.2820307619404048] took 44.58726692199707\n",
      "Validation loss EPOCH: [35|1000], validation loss: [0.27661119494587183], AE loss: [0.13578153564594686], TF loss: [0.14082965860143304]\n",
      "Training loss EPOCH: [36|1000], training loss: [0.5882178856991231], AE loss: [0.30626291083171964], TF loss: [0.28195497393608093] took 42.269519090652466\n",
      "Validation loss EPOCH: [36|1000], validation loss: [0.27663359185680747], AE loss: [0.1356943417340517], TF loss: [0.14093925175257027]\n",
      "Training loss EPOCH: [37|1000], training loss: [0.5875008613802493], AE loss: [0.30632060253992677], TF loss: [0.2811802588403225] took 44.833313941955566\n",
      "Validation loss EPOCH: [37|1000], validation loss: [0.27689555613324046], AE loss: [0.1357009462080896], TF loss: [0.14119461178779602]\n",
      "Training loss EPOCH: [38|1000], training loss: [0.5867410944774747], AE loss: [0.3061501723714173], TF loss: [0.2805909216403961] took 42.11984729766846\n",
      "Validation loss EPOCH: [38|1000], validation loss: [0.27676461078226566], AE loss: [0.13557344488799572], TF loss: [0.1411911635659635]\n",
      "Training loss EPOCH: [39|1000], training loss: [0.5860224580392241], AE loss: [0.30614410410635173], TF loss: [0.2798783553298563] took 39.4372501373291\n",
      "Validation loss EPOCH: [39|1000], validation loss: [0.2771101435646415], AE loss: [0.13554943655617535], TF loss: [0.14156070863828063]\n",
      "Training loss EPOCH: [40|1000], training loss: [0.5854905522428453], AE loss: [0.3060972588136792], TF loss: [0.27939329319633543] took 40.989086866378784\n",
      "Validation loss EPOCH: [40|1000], validation loss: [0.27709290012717247], AE loss: [0.13556757918559015], TF loss: [0.14152532164007425]\n",
      "Training loss EPOCH: [41|1000], training loss: [0.5847501652315259], AE loss: [0.30606958735734224], TF loss: [0.27868057624436915] took 41.656564474105835\n",
      "Validation loss EPOCH: [41|1000], validation loss: [0.2770187486894429], AE loss: [0.13551570824347436], TF loss: [0.1415030409116298]\n",
      "Training loss EPOCH: [42|1000], training loss: [0.5848634764552116], AE loss: [0.30623085028491914], TF loss: [0.27863262640312314] took 40.26066875457764\n",
      "Validation loss EPOCH: [42|1000], validation loss: [0.27721769316121936], AE loss: [0.13542091753333807], TF loss: [0.1417967793531716]\n",
      "Training loss EPOCH: [43|1000], training loss: [0.5836969092488289], AE loss: [0.30605887877754867], TF loss: [0.277638032566756] took 38.7966685295105\n",
      "Validation loss EPOCH: [43|1000], validation loss: [0.27755984757095575], AE loss: [0.1354172369465232], TF loss: [0.14214261225424707]\n",
      "Training loss EPOCH: [44|1000], training loss: [0.5832827701233327], AE loss: [0.3061286478769034], TF loss: [0.27715412387624383] took 42.8451771736145\n",
      "Validation loss EPOCH: [44|1000], validation loss: [0.2775003146380186], AE loss: [0.13538007414899766], TF loss: [0.1421202407218516]\n",
      "Training loss EPOCH: [45|1000], training loss: [0.5826102602295578], AE loss: [0.306078159250319], TF loss: [0.2765321016777307] took 42.55974054336548\n",
      "Validation loss EPOCH: [45|1000], validation loss: [0.27797446912154555], AE loss: [0.1354425207246095], TF loss: [0.14253194769844413]\n",
      "Training loss EPOCH: [46|1000], training loss: [0.5819768579676747], AE loss: [0.3061239826492965], TF loss: [0.2758528769481927] took 40.556761741638184\n",
      "Validation loss EPOCH: [46|1000], validation loss: [0.27800733176991343], AE loss: [0.1354074717964977], TF loss: [0.14259986416436732]\n",
      "Training loss EPOCH: [47|1000], training loss: [0.5812169783748686], AE loss: [0.30594602646306157], TF loss: [0.27527095191180706] took 42.494405031204224\n",
      "Validation loss EPOCH: [47|1000], validation loss: [0.2784593845717609], AE loss: [0.13534749881364405], TF loss: [0.14311188529245555]\n",
      "Training loss EPOCH: [48|1000], training loss: [0.5811293153092265], AE loss: [0.3062445723917335], TF loss: [0.27488474175333977] took 40.204219341278076\n",
      "Validation loss EPOCH: [48|1000], validation loss: [0.2786067835986614], AE loss: [0.1354135274887085], TF loss: [0.14319325215183198]\n",
      "Training loss EPOCH: [49|1000], training loss: [0.5801484826952219], AE loss: [0.30604702117852867], TF loss: [0.2741014619823545] took 40.23355793952942\n",
      "Validation loss EPOCH: [49|1000], validation loss: [0.2786035481840372], AE loss: [0.13528491044417024], TF loss: [0.14331863867118955]\n",
      "Training loss EPOCH: [50|1000], training loss: [0.5798953846096992], AE loss: [0.3062185838352889], TF loss: [0.2736768026370555] took 43.814857006073\n",
      "Validation loss EPOCH: [50|1000], validation loss: [0.27859621914103627], AE loss: [0.13539628055877984], TF loss: [0.14319993508979678]\n",
      "Training loss EPOCH: [51|1000], training loss: [0.5787709848955274], AE loss: [0.30596760706976056], TF loss: [0.2728033773601055] took 43.156742334365845\n",
      "Validation loss EPOCH: [51|1000], validation loss: [0.2792179058305919], AE loss: [0.13541173026897013], TF loss: [0.143806176725775]\n",
      "Training loss EPOCH: [52|1000], training loss: [0.5783169325441122], AE loss: [0.3060657582245767], TF loss: [0.27225117292255163] took 41.23948383331299\n",
      "Validation loss EPOCH: [52|1000], validation loss: [0.27929823473095894], AE loss: [0.1353360505308956], TF loss: [0.1439621855970472]\n",
      "Training loss EPOCH: [53|1000], training loss: [0.577548642642796], AE loss: [0.30588291655294597], TF loss: [0.27166572539135814] took 43.02765250205994\n",
      "Validation loss EPOCH: [53|1000], validation loss: [0.27922759344801307], AE loss: [0.13527990970760584], TF loss: [0.14394768350757658]\n",
      "Training loss EPOCH: [54|1000], training loss: [0.5771930487826467], AE loss: [0.3060348548460752], TF loss: [0.27115819370374084] took 42.959754943847656\n",
      "Validation loss EPOCH: [54|1000], validation loss: [0.27931759785860777], AE loss: [0.13531856192275882], TF loss: [0.14399903477169573]\n",
      "Training loss EPOCH: [55|1000], training loss: [0.5766355521045625], AE loss: [0.306120831053704], TF loss: [0.27051472081802785] took 41.847283363342285\n",
      "Validation loss EPOCH: [55|1000], validation loss: [0.27997140353545547], AE loss: [0.13537626108154655], TF loss: [0.1445951471105218]\n",
      "Training loss EPOCH: [56|1000], training loss: [0.575843199621886], AE loss: [0.3060424558352679], TF loss: [0.26980074401944876] took 44.92909789085388\n",
      "Validation loss EPOCH: [56|1000], validation loss: [0.2800774900242686], AE loss: [0.13537763385102153], TF loss: [0.14469985710456967]\n",
      "Training loss EPOCH: [57|1000], training loss: [0.5749188866466284], AE loss: [0.30588599597103894], TF loss: [0.26903289183974266] took 40.857972383499146\n",
      "Validation loss EPOCH: [57|1000], validation loss: [0.28081584395840764], AE loss: [0.13535196520388126], TF loss: [0.14546387922018766]\n",
      "Training loss EPOCH: [58|1000], training loss: [0.57455979520455], AE loss: [0.3059733116533607], TF loss: [0.2685864814557135] took 42.29933714866638\n",
      "Validation loss EPOCH: [58|1000], validation loss: [0.2804561499506235], AE loss: [0.1352114798501134], TF loss: [0.14524467149749398]\n",
      "Training loss EPOCH: [59|1000], training loss: [0.5735907992348075], AE loss: [0.30589669616892934], TF loss: [0.2676941021345556] took 42.91078329086304\n",
      "Validation loss EPOCH: [59|1000], validation loss: [0.28057992504909635], AE loss: [0.1353238474112004], TF loss: [0.1452560795005411]\n",
      "Training loss EPOCH: [60|1000], training loss: [0.5734504046849906], AE loss: [0.30601777182891965], TF loss: [0.2674326319247484] took 43.21253275871277\n",
      "Validation loss EPOCH: [60|1000], validation loss: [0.2809184081852436], AE loss: [0.1352097864728421], TF loss: [0.14570862194523215]\n",
      "Training loss EPOCH: [61|1000], training loss: [0.5722844460979104], AE loss: [0.3059110939502716], TF loss: [0.2663733537774533] took 40.99218678474426\n",
      "Validation loss EPOCH: [61|1000], validation loss: [0.28101700358092785], AE loss: [0.13532988796941936], TF loss: [0.14568711817264557]\n",
      "Training loss EPOCH: [62|1000], training loss: [0.5716873249039054], AE loss: [0.3059515196364373], TF loss: [0.2657358052674681] took 42.45288014411926\n",
      "Validation loss EPOCH: [62|1000], validation loss: [0.2813458936288953], AE loss: [0.13516511162742972], TF loss: [0.1461807822342962]\n",
      "Training loss EPOCH: [63|1000], training loss: [0.5711428015492857], AE loss: [0.3060199455358088], TF loss: [0.2651228541508317] took 44.03069519996643\n",
      "Validation loss EPOCH: [63|1000], validation loss: [0.28184230579063296], AE loss: [0.13521360256709158], TF loss: [0.14662870089523494]\n",
      "Training loss EPOCH: [64|1000], training loss: [0.5703765619546175], AE loss: [0.3058513237629086], TF loss: [0.26452523516491055] took 40.72279500961304\n",
      "Validation loss EPOCH: [64|1000], validation loss: [0.28156325314193964], AE loss: [0.1350956312380731], TF loss: [0.14646762213669717]\n",
      "Training loss EPOCH: [65|1000], training loss: [0.5696023344062269], AE loss: [0.3059264940675348], TF loss: [0.2636758401058614] took 42.28201389312744\n",
      "Validation loss EPOCH: [65|1000], validation loss: [0.28133542323485017], AE loss: [0.13497994281351566], TF loss: [0.14635547972284257]\n",
      "Training loss EPOCH: [66|1000], training loss: [0.5692927879281342], AE loss: [0.306011235807091], TF loss: [0.26328155561350286] took 42.865817070007324\n",
      "Validation loss EPOCH: [66|1000], validation loss: [0.28186118695884943], AE loss: [0.13509552157483995], TF loss: [0.1467656665481627]\n",
      "Training loss EPOCH: [67|1000], training loss: [0.5684914165176451], AE loss: [0.305928195361048], TF loss: [0.2625632209237665] took 41.16912245750427\n",
      "Validation loss EPOCH: [67|1000], validation loss: [0.28228712920099497], AE loss: [0.13506521563977003], TF loss: [0.1472219154238701]\n",
      "Training loss EPOCH: [68|1000], training loss: [0.5674430206418037], AE loss: [0.30582833755761385], TF loss: [0.2616146819200367] took 38.496649742126465\n",
      "Validation loss EPOCH: [68|1000], validation loss: [0.2828856837004423], AE loss: [0.1350476525258273], TF loss: [0.1478380316402763]\n",
      "Training loss EPOCH: [69|1000], training loss: [0.5674807536415756], AE loss: [0.30605379631742835], TF loss: [0.26142695848830044] took 42.45249009132385\n",
      "Validation loss EPOCH: [69|1000], validation loss: [0.28279532538726926], AE loss: [0.1350543077569455], TF loss: [0.1477410199586302]\n",
      "Training loss EPOCH: [70|1000], training loss: [0.5665976162999868], AE loss: [0.30597552470862865], TF loss: [0.26062209345400333] took 41.13416337966919\n",
      "Validation loss EPOCH: [70|1000], validation loss: [0.28253370709717274], AE loss: [0.13491974491626024], TF loss: [0.14761396194808185]\n",
      "Training loss EPOCH: [71|1000], training loss: [0.5659075081348419], AE loss: [0.30588236288167536], TF loss: [0.26002514525316656] took 39.91959023475647\n",
      "Validation loss EPOCH: [71|1000], validation loss: [0.28335604071617126], AE loss: [0.13498288625851274], TF loss: [0.14837315259501338]\n",
      "Training loss EPOCH: [72|1000], training loss: [0.5654396396130323], AE loss: [0.30598845705389977], TF loss: [0.2594511832576245] took 42.10276675224304\n",
      "Validation loss EPOCH: [72|1000], validation loss: [0.2832035291939974], AE loss: [0.13485855143517256], TF loss: [0.14834497682750225]\n",
      "Training loss EPOCH: [73|1000], training loss: [0.5642664632759988], AE loss: [0.30576753290370107], TF loss: [0.2584989289753139] took 40.5264618396759\n",
      "Validation loss EPOCH: [73|1000], validation loss: [0.2833081176504493], AE loss: [0.13486016751267016], TF loss: [0.14844794874079525]\n",
      "Training loss EPOCH: [74|1000], training loss: [0.563901461660862], AE loss: [0.3059524456039071], TF loss: [0.257949014659971] took 41.55418157577515\n",
      "Validation loss EPOCH: [74|1000], validation loss: [0.2839979501441121], AE loss: [0.13491631671786308], TF loss: [0.14908163575455546]\n",
      "Training loss EPOCH: [75|1000], training loss: [0.5629484015516937], AE loss: [0.30569445458240807], TF loss: [0.2572539481334388] took 42.69853711128235\n",
      "Validation loss EPOCH: [75|1000], validation loss: [0.28365681786090136], AE loss: [0.1347212044056505], TF loss: [0.14893561694771051]\n",
      "Training loss EPOCH: [76|1000], training loss: [0.5625731754116714], AE loss: [0.3057753276079893], TF loss: [0.25679784431122243] took 40.43096160888672\n",
      "Validation loss EPOCH: [76|1000], validation loss: [0.2841373896226287], AE loss: [0.13478707266040146], TF loss: [0.14935031766071916]\n",
      "Training loss EPOCH: [77|1000], training loss: [0.5621309108100832], AE loss: [0.3059248602949083], TF loss: [0.256206049118191] took 40.48373246192932\n",
      "Validation loss EPOCH: [77|1000], validation loss: [0.2843571901321411], AE loss: [0.13486241060309112], TF loss: [0.14949477836489677]\n",
      "Training loss EPOCH: [78|1000], training loss: [0.5615461049601436], AE loss: [0.3059251874219626], TF loss: [0.2556209177710116] took 41.58705997467041\n",
      "Validation loss EPOCH: [78|1000], validation loss: [0.2846188135445118], AE loss: [0.13489200407639146], TF loss: [0.14972680853679776]\n",
      "Training loss EPOCH: [79|1000], training loss: [0.5611141789704561], AE loss: [0.3059370869304985], TF loss: [0.25517709203995764] took 39.57352948188782\n",
      "Validation loss EPOCH: [79|1000], validation loss: [0.2852161284536123], AE loss: [0.13492373353801668], TF loss: [0.15029239561408758]\n",
      "Training loss EPOCH: [80|1000], training loss: [0.5605193586088717], AE loss: [0.30589894158765674], TF loss: [0.2546204167883843] took 41.783984899520874\n",
      "Validation loss EPOCH: [80|1000], validation loss: [0.28534773038700223], AE loss: [0.13478387682698667], TF loss: [0.1505638542585075]\n",
      "Training loss EPOCH: [81|1000], training loss: [0.5599021194502711], AE loss: [0.30582073447294533], TF loss: [0.25408138311468065] took 41.12345004081726\n",
      "Validation loss EPOCH: [81|1000], validation loss: [0.2849302161484957], AE loss: [0.13478934834711254], TF loss: [0.1501408712938428]\n",
      "Training loss EPOCH: [82|1000], training loss: [0.5590720968320966], AE loss: [0.30589889944531024], TF loss: [0.253173197619617] took 41.09425330162048\n",
      "Validation loss EPOCH: [82|1000], validation loss: [0.28560419101268053], AE loss: [0.13477256754413247], TF loss: [0.15083162486553192]\n",
      "Training loss EPOCH: [83|1000], training loss: [0.5586166768334806], AE loss: [0.3059704911429435], TF loss: [0.2526461868546903] took 43.268234729766846\n",
      "Validation loss EPOCH: [83|1000], validation loss: [0.28540017642080784], AE loss: [0.13466525659896433], TF loss: [0.15073492005467415]\n",
      "Training loss EPOCH: [84|1000], training loss: [0.5578284249641001], AE loss: [0.3058677725493908], TF loss: [0.2519606512505561] took 40.423707246780396\n",
      "Validation loss EPOCH: [84|1000], validation loss: [0.28590790182352066], AE loss: [0.13472680002450943], TF loss: [0.15118110226467252]\n",
      "Training loss EPOCH: [85|1000], training loss: [0.5577104552648962], AE loss: [0.30603599920868874], TF loss: [0.2516744544263929] took 43.551363706588745\n",
      "Validation loss EPOCH: [85|1000], validation loss: [0.2858992153778672], AE loss: [0.13482225011102855], TF loss: [0.15107696410268545]\n",
      "Training loss EPOCH: [86|1000], training loss: [0.5568958087824285], AE loss: [0.30593486968427896], TF loss: [0.25096093979664147] took 42.00149607658386\n",
      "Validation loss EPOCH: [86|1000], validation loss: [0.2860707249492407], AE loss: [0.13473268924281], TF loss: [0.15133803291246295]\n",
      "Training loss EPOCH: [87|1000], training loss: [0.5563570400699973], AE loss: [0.3058257114607841], TF loss: [0.2505313279107213] took 41.19313406944275\n",
      "Validation loss EPOCH: [87|1000], validation loss: [0.28651196975260973], AE loss: [0.13475034735165536], TF loss: [0.15176162170246243]\n",
      "Training loss EPOCH: [88|1000], training loss: [0.5559119344688952], AE loss: [0.3059161838609725], TF loss: [0.2499957475811243] took 40.8461229801178\n",
      "Validation loss EPOCH: [88|1000], validation loss: [0.28597867488861084], AE loss: [0.13473069318570197], TF loss: [0.15124798053875566]\n",
      "Training loss EPOCH: [89|1000], training loss: [0.5554322525858879], AE loss: [0.30585737410001457], TF loss: [0.24957487639039755] took 41.05925965309143\n",
      "Validation loss EPOCH: [89|1000], validation loss: [0.2867573816329241], AE loss: [0.1347417247015983], TF loss: [0.152015658095479]\n",
      "Training loss EPOCH: [90|1000], training loss: [0.554504765663296], AE loss: [0.30578654957935214], TF loss: [0.24871821561828256] took 41.309364318847656\n",
      "Validation loss EPOCH: [90|1000], validation loss: [0.2870812355540693], AE loss: [0.1348475394770503], TF loss: [0.15223369607701898]\n",
      "Training loss EPOCH: [91|1000], training loss: [0.5535343647934496], AE loss: [0.30514513282105327], TF loss: [0.24838923220522702] took 39.945621967315674\n",
      "Validation loss EPOCH: [91|1000], validation loss: [0.2870138450525701], AE loss: [0.13472228241153061], TF loss: [0.15229156240820885]\n",
      "Training loss EPOCH: [92|1000], training loss: [0.5524009843356907], AE loss: [0.3045912263914943], TF loss: [0.24780975724570453] took 38.416476249694824\n",
      "Validation loss EPOCH: [92|1000], validation loss: [0.286893698386848], AE loss: [0.13460451597347856], TF loss: [0.15228918055072427]\n",
      "Training loss EPOCH: [93|1000], training loss: [0.5520269349217415], AE loss: [0.30444194516167045], TF loss: [0.24758498696610332] took 40.734657526016235\n",
      "Validation loss EPOCH: [93|1000], validation loss: [0.28687585797160864], AE loss: [0.13435669243335724], TF loss: [0.15251916483975947]\n",
      "Training loss EPOCH: [94|1000], training loss: [0.5512259579263628], AE loss: [0.30439063045196235], TF loss: [0.24683532817289233] took 38.459964990615845\n",
      "Validation loss EPOCH: [94|1000], validation loss: [0.28673816565424204], AE loss: [0.1343967574648559], TF loss: [0.1523414053954184]\n",
      "Training loss EPOCH: [95|1000], training loss: [0.5507345157675445], AE loss: [0.30429980368353426], TF loss: [0.2464347134809941] took 39.475573778152466\n",
      "Validation loss EPOCH: [95|1000], validation loss: [0.2870970172807574], AE loss: [0.13421750627458096], TF loss: [0.15287950728088617]\n",
      "Training loss EPOCH: [96|1000], training loss: [0.5500456970185041], AE loss: [0.3042453059460968], TF loss: [0.2458003901410848] took 39.800878047943115\n",
      "Validation loss EPOCH: [96|1000], validation loss: [0.28763339575380087], AE loss: [0.134319027652964], TF loss: [0.1533143692649901]\n",
      "Training loss EPOCH: [97|1000], training loss: [0.5498968837782741], AE loss: [0.30429032747633755], TF loss: [0.24560655583627522] took 40.533448457717896\n",
      "Validation loss EPOCH: [97|1000], validation loss: [0.2876650234684348], AE loss: [0.1343513943720609], TF loss: [0.15331362606957555]\n",
      "Training loss EPOCH: [98|1000], training loss: [0.5491912681609392], AE loss: [0.3040842602495104], TF loss: [0.24510700884275138] took 38.55301523208618\n",
      "Validation loss EPOCH: [98|1000], validation loss: [0.28777468390762806], AE loss: [0.1342672521714121], TF loss: [0.1535074315033853]\n",
      "Training loss EPOCH: [99|1000], training loss: [0.5487028420902789], AE loss: [0.3039758496452123], TF loss: [0.24472699197940528] took 39.63745355606079\n",
      "Validation loss EPOCH: [99|1000], validation loss: [0.2883249022997916], AE loss: [0.13476742035709321], TF loss: [0.15355748170986772]\n",
      "Training loss EPOCH: [100|1000], training loss: [0.5472417934797704], AE loss: [0.30319756362587214], TF loss: [0.2440442272927612] took 39.49767303466797\n",
      "Validation loss EPOCH: [100|1000], validation loss: [0.28831661213189363], AE loss: [0.1342356859240681], TF loss: [0.15408092783764005]\n",
      "Training loss EPOCH: [101|1000], training loss: [0.546200386248529], AE loss: [0.3024639612995088], TF loss: [0.24373642611317337] took 38.54383301734924\n",
      "Validation loss EPOCH: [101|1000], validation loss: [0.28850801661610603], AE loss: [0.13429361581802368], TF loss: [0.15421439846977592]\n",
      "Training loss EPOCH: [102|1000], training loss: [0.54512401483953], AE loss: [0.30179285909980536], TF loss: [0.24333115690387785] took 41.866912841796875\n",
      "Validation loss EPOCH: [102|1000], validation loss: [0.2884441753849387], AE loss: [0.1341876103542745], TF loss: [0.15425656456500292]\n",
      "Training loss EPOCH: [103|1000], training loss: [0.5437087994068861], AE loss: [0.3009195157792419], TF loss: [0.24278928409330547] took 41.91600155830383\n",
      "Validation loss EPOCH: [103|1000], validation loss: [0.2886470491066575], AE loss: [0.13414270873181522], TF loss: [0.15450433967635036]\n",
      "Training loss EPOCH: [104|1000], training loss: [0.542962939478457], AE loss: [0.3004746919032186], TF loss: [0.24248824594542384] took 42.221004247665405\n",
      "Validation loss EPOCH: [104|1000], validation loss: [0.288545947521925], AE loss: [0.1340136679355055], TF loss: [0.15453227749094367]\n",
      "Training loss EPOCH: [105|1000], training loss: [0.5421285829506814], AE loss: [0.3000671770423651], TF loss: [0.24206140590831637] took 37.73258972167969\n",
      "Validation loss EPOCH: [105|1000], validation loss: [0.28880439372733235], AE loss: [0.13425370398908854], TF loss: [0.15455069299787283]\n",
      "Training loss EPOCH: [106|1000], training loss: [0.5415188386105001], AE loss: [0.29979763459414244], TF loss: [0.24172120750881732] took 42.823514223098755\n",
      "Validation loss EPOCH: [106|1000], validation loss: [0.28850363101810217], AE loss: [0.13415664830245078], TF loss: [0.15434698341414332]\n",
      "Training loss EPOCH: [107|1000], training loss: [0.5404422776773572], AE loss: [0.2991125239059329], TF loss: [0.24132975307293236] took 43.56814527511597\n",
      "Validation loss EPOCH: [107|1000], validation loss: [0.2886363295838237], AE loss: [0.1340714015532285], TF loss: [0.15456492779776454]\n",
      "Training loss EPOCH: [108|1000], training loss: [0.5399743285961449], AE loss: [0.2988427036907524], TF loss: [0.24113162537105381] took 40.803202390670776\n",
      "Validation loss EPOCH: [108|1000], validation loss: [0.2885019015520811], AE loss: [0.1340551204048097], TF loss: [0.15444677975028753]\n",
      "Training loss EPOCH: [109|1000], training loss: [0.5387517279013991], AE loss: [0.2981169249396771], TF loss: [0.24063480366021395] took 39.8698308467865\n",
      "Validation loss EPOCH: [109|1000], validation loss: [0.28941132593899965], AE loss: [0.1340883185621351], TF loss: [0.15532300900667906]\n",
      "Training loss EPOCH: [110|1000], training loss: [0.5378291280940175], AE loss: [0.29755335790105164], TF loss: [0.24027577275410295] took 41.61089038848877\n",
      "Validation loss EPOCH: [110|1000], validation loss: [0.28884506318718195], AE loss: [0.13394604483619332], TF loss: [0.15489901835098863]\n",
      "Training loss EPOCH: [111|1000], training loss: [0.536728233564645], AE loss: [0.29695978364907205], TF loss: [0.2397684478200972] took 42.65374732017517\n",
      "Validation loss EPOCH: [111|1000], validation loss: [0.2893111202865839], AE loss: [0.13387131853960454], TF loss: [0.15543980011716485]\n",
      "Training loss EPOCH: [112|1000], training loss: [0.5361113646067679], AE loss: [0.2965510841459036], TF loss: [0.23956027952954173] took 39.145474910736084\n",
      "Validation loss EPOCH: [112|1000], validation loss: [0.28902815422043204], AE loss: [0.13388068112544715], TF loss: [0.15514747146517038]\n",
      "Training loss EPOCH: [113|1000], training loss: [0.535333885345608], AE loss: [0.2961764959618449], TF loss: [0.23915738705545664] took 39.712984561920166\n",
      "Validation loss EPOCH: [113|1000], validation loss: [0.289685714058578], AE loss: [0.13390678074210882], TF loss: [0.15577893564477563]\n",
      "Training loss EPOCH: [114|1000], training loss: [0.5343051012605429], AE loss: [0.2953881823923439], TF loss: [0.23891691863536835] took 42.164390325546265\n",
      "Validation loss EPOCH: [114|1000], validation loss: [0.2899887040257454], AE loss: [0.1338488389737904], TF loss: [0.15613986598327756]\n",
      "Training loss EPOCH: [115|1000], training loss: [0.5334492847323418], AE loss: [0.29516479396261275], TF loss: [0.23828449076972902] took 40.38974976539612\n",
      "Validation loss EPOCH: [115|1000], validation loss: [0.28999354504048824], AE loss: [0.13406519731506705], TF loss: [0.1559283477254212]\n",
      "Training loss EPOCH: [116|1000], training loss: [0.5329216769896448], AE loss: [0.29475439339876175], TF loss: [0.23816728312522173] took 41.957541704177856\n",
      "Validation loss EPOCH: [116|1000], validation loss: [0.29005314130336046], AE loss: [0.1339116431772709], TF loss: [0.15614149952307343]\n",
      "Training loss EPOCH: [117|1000], training loss: [0.5319388806819916], AE loss: [0.29426724556833506], TF loss: [0.2376716381404549] took 41.024397134780884\n",
      "Validation loss EPOCH: [117|1000], validation loss: [0.29007092770189047], AE loss: [0.13394489139318466], TF loss: [0.1561260400339961]\n",
      "Training loss EPOCH: [118|1000], training loss: [0.5309686926193535], AE loss: [0.2937478683888912], TF loss: [0.2372208246961236] took 40.07975649833679\n",
      "Validation loss EPOCH: [118|1000], validation loss: [0.289979905821383], AE loss: [0.13407738227397203], TF loss: [0.15590252308174968]\n",
      "Training loss EPOCH: [119|1000], training loss: [0.5307101281359792], AE loss: [0.2937327353283763], TF loss: [0.2369773918762803] took 39.69953680038452\n",
      "Validation loss EPOCH: [119|1000], validation loss: [0.2908050389960408], AE loss: [0.13415524875745177], TF loss: [0.15664979303255677]\n",
      "Training loss EPOCH: [120|1000], training loss: [0.5301111876033247], AE loss: [0.29336541797965765], TF loss: [0.23674576822668314] took 39.43880748748779\n",
      "Validation loss EPOCH: [120|1000], validation loss: [0.2904627090319991], AE loss: [0.13425446301698685], TF loss: [0.15620824694633484]\n",
      "Training loss EPOCH: [121|1000], training loss: [0.5298942383378744], AE loss: [0.29323708917945623], TF loss: [0.23665715008974075] took 39.85192012786865\n",
      "Validation loss EPOCH: [121|1000], validation loss: [0.29066125117242336], AE loss: [0.13426689011976123], TF loss: [0.15639436431229115]\n",
      "Training loss EPOCH: [122|1000], training loss: [0.5293817613273859], AE loss: [0.29302149754948914], TF loss: [0.23636026168242097] took 38.63859701156616\n",
      "Validation loss EPOCH: [122|1000], validation loss: [0.2915409980341792], AE loss: [0.13444125116802752], TF loss: [0.15709975082427263]\n",
      "Training loss EPOCH: [123|1000], training loss: [0.5284267915412784], AE loss: [0.2925630018580705], TF loss: [0.23586379061453044] took 38.34370470046997\n",
      "Validation loss EPOCH: [123|1000], validation loss: [0.29174668062478304], AE loss: [0.1343418143223971], TF loss: [0.15740486606955528]\n",
      "Training loss EPOCH: [124|1000], training loss: [0.527544085867703], AE loss: [0.2920730817131698], TF loss: [0.23547100485302508] took 39.955843687057495\n",
      "Validation loss EPOCH: [124|1000], validation loss: [0.29101509507745504], AE loss: [0.13444836298003793], TF loss: [0.15656673396006227]\n",
      "Training loss EPOCH: [125|1000], training loss: [0.5269788498990238], AE loss: [0.2919459664262831], TF loss: [0.23503288091160357] took 41.88868546485901\n",
      "Validation loss EPOCH: [125|1000], validation loss: [0.2920620432123542], AE loss: [0.1345661913510412], TF loss: [0.15749585116282105]\n",
      "Training loss EPOCH: [126|1000], training loss: [0.5269569205120206], AE loss: [0.2920241276733577], TF loss: [0.23493279260583222] took 40.05308699607849\n",
      "Validation loss EPOCH: [126|1000], validation loss: [0.2918935129418969], AE loss: [0.13460827735252678], TF loss: [0.1572852344252169]\n",
      "Training loss EPOCH: [127|1000], training loss: [0.5263839224353433], AE loss: [0.29170545982196927], TF loss: [0.2346784637775272] took 40.3760507106781\n",
      "Validation loss EPOCH: [127|1000], validation loss: [0.2913909247145057], AE loss: [0.13457358651794493], TF loss: [0.15681733563542366]\n",
      "Training loss EPOCH: [128|1000], training loss: [0.525691008195281], AE loss: [0.2912711778189987], TF loss: [0.23441983154043555] took 39.45709466934204\n",
      "Validation loss EPOCH: [128|1000], validation loss: [0.2921642241999507], AE loss: [0.13457536487840116], TF loss: [0.15758886048570275]\n",
      "Training loss EPOCH: [129|1000], training loss: [0.5251398584805429], AE loss: [0.2912229117937386], TF loss: [0.2339169487822801] took 41.11137080192566\n",
      "Validation loss EPOCH: [129|1000], validation loss: [0.2924126470461488], AE loss: [0.1346304677426815], TF loss: [0.1577821779064834]\n",
      "Training loss EPOCH: [130|1000], training loss: [0.5253197229467332], AE loss: [0.291345909005031], TF loss: [0.2339738116133958] took 40.784583568573\n",
      "Validation loss EPOCH: [130|1000], validation loss: [0.29295952152460814], AE loss: [0.13470915704965591], TF loss: [0.15825036354362965]\n",
      "Training loss EPOCH: [131|1000], training loss: [0.5243051419965923], AE loss: [0.2908026441000402], TF loss: [0.23350249719806015] took 41.611961126327515\n",
      "Validation loss EPOCH: [131|1000], validation loss: [0.2911862079054117], AE loss: [0.13458819803781807], TF loss: [0.15659801056608558]\n",
      "Training loss EPOCH: [132|1000], training loss: [0.5238112104125321], AE loss: [0.29054202092811465], TF loss: [0.23326918855309486] took 40.30280327796936\n",
      "Validation loss EPOCH: [132|1000], validation loss: [0.2924829740077257], AE loss: [0.13459526002407074], TF loss: [0.15788771444931626]\n",
      "Training loss EPOCH: [133|1000], training loss: [0.5236619296483696], AE loss: [0.29044292867183685], TF loss: [0.23321900004521012] took 37.08755445480347\n",
      "Validation loss EPOCH: [133|1000], validation loss: [0.29295030795037746], AE loss: [0.13469176460057497], TF loss: [0.15825854241847992]\n",
      "Training loss EPOCH: [134|1000], training loss: [0.5229740287177265], AE loss: [0.29016806930303574], TF loss: [0.23280595894902945] took 36.46604514122009\n",
      "Validation loss EPOCH: [134|1000], validation loss: [0.2931539276614785], AE loss: [0.13466364424675703], TF loss: [0.15849028248339891]\n",
      "Training loss EPOCH: [135|1000], training loss: [0.5226868721656501], AE loss: [0.2902563593816012], TF loss: [0.2324305137153715] took 38.263492584228516\n",
      "Validation loss EPOCH: [135|1000], validation loss: [0.29269818123430014], AE loss: [0.1345714449416846], TF loss: [0.15812673652544618]\n",
      "Training loss EPOCH: [136|1000], training loss: [0.5221493700519204], AE loss: [0.28999559790827334], TF loss: [0.23215377097949386] took 41.18046474456787\n",
      "Validation loss EPOCH: [136|1000], validation loss: [0.2923387214541435], AE loss: [0.1344365153927356], TF loss: [0.15790220582857728]\n",
      "Training loss EPOCH: [137|1000], training loss: [0.5220397640950978], AE loss: [0.2898548003286123], TF loss: [0.2321849660947919] took 40.092501401901245\n",
      "Validation loss EPOCH: [137|1000], validation loss: [0.29270304553210735], AE loss: [0.1345073515549302], TF loss: [0.15819569304585457]\n",
      "Training loss EPOCH: [138|1000], training loss: [0.5216098059900105], AE loss: [0.28970056725665927], TF loss: [0.23190924036316574] took 42.3175311088562\n",
      "Validation loss EPOCH: [138|1000], validation loss: [0.29330998938530684], AE loss: [0.13454035762697458], TF loss: [0.15876963594928384]\n",
      "Training loss EPOCH: [139|1000], training loss: [0.5210340307094157], AE loss: [0.2894319898914546], TF loss: [0.23160204151645303] took 39.98627305030823\n",
      "Validation loss EPOCH: [139|1000], validation loss: [0.2929123491048813], AE loss: [0.13447369262576103], TF loss: [0.1584386550821364]\n",
      "Training loss EPOCH: [140|1000], training loss: [0.5205959784798324], AE loss: [0.2892061909660697], TF loss: [0.23138978914357722] took 39.07758355140686\n",
      "Validation loss EPOCH: [140|1000], validation loss: [0.29318608343601227], AE loss: [0.1345742775592953], TF loss: [0.15861180564388633]\n",
      "Training loss EPOCH: [141|1000], training loss: [0.520295993424952], AE loss: [0.28918799106031656], TF loss: [0.23110800236463547] took 39.8080198764801\n",
      "Validation loss EPOCH: [141|1000], validation loss: [0.29365712963044643], AE loss: [0.13446660828776658], TF loss: [0.15919051971286535]\n",
      "Training loss EPOCH: [142|1000], training loss: [0.5198901924304664], AE loss: [0.289054294815287], TF loss: [0.2308358997106552] took 40.287700176239014\n",
      "Validation loss EPOCH: [142|1000], validation loss: [0.2932774741202593], AE loss: [0.13450479274615645], TF loss: [0.15877268137410283]\n",
      "Training loss EPOCH: [143|1000], training loss: [0.5193648701533675], AE loss: [0.28886112733744085], TF loss: [0.23050374304875731] took 39.116243839263916\n",
      "Validation loss EPOCH: [143|1000], validation loss: [0.2937859734520316], AE loss: [0.13466459745541215], TF loss: [0.1591213778592646]\n",
      "Training loss EPOCH: [144|1000], training loss: [0.5191895444877446], AE loss: [0.28881830838508904], TF loss: [0.2303712358698249] took 38.66419696807861\n",
      "Validation loss EPOCH: [144|1000], validation loss: [0.29340199660509825], AE loss: [0.13463320513255894], TF loss: [0.1587687903083861]\n",
      "Training loss EPOCH: [145|1000], training loss: [0.5189159805886447], AE loss: [0.2886353142093867], TF loss: [0.23028066847473383] took 40.52203297615051\n",
      "Validation loss EPOCH: [145|1000], validation loss: [0.293491005897522], AE loss: [0.1345752750057727], TF loss: [0.15891572972759604]\n",
      "Training loss EPOCH: [146|1000], training loss: [0.5185173121280968], AE loss: [0.2885196884162724], TF loss: [0.2299976209178567] took 41.571155309677124\n",
      "Validation loss EPOCH: [146|1000], validation loss: [0.2939576981589198], AE loss: [0.1347511967178434], TF loss: [0.15920650400221348]\n",
      "Training loss EPOCH: [147|1000], training loss: [0.5184913044795394], AE loss: [0.2885206483770162], TF loss: [0.22997065470553935] took 38.15772008895874\n",
      "Validation loss EPOCH: [147|1000], validation loss: [0.29399447701871395], AE loss: [0.13452680152840912], TF loss: [0.15946767712011933]\n",
      "Training loss EPOCH: [148|1000], training loss: [0.5178104410879314], AE loss: [0.2881707742344588], TF loss: [0.22963966499082744] took 40.92159914970398\n",
      "Validation loss EPOCH: [148|1000], validation loss: [0.29364934377372265], AE loss: [0.13440358568914235], TF loss: [0.1592457564547658]\n",
      "Training loss EPOCH: [149|1000], training loss: [0.5172495706938207], AE loss: [0.2877908619120717], TF loss: [0.22945870668627322] took 39.932637453079224\n",
      "Validation loss EPOCH: [149|1000], validation loss: [0.2938739862293005], AE loss: [0.13475766498595476], TF loss: [0.1591163189150393]\n",
      "Training loss EPOCH: [150|1000], training loss: [0.5170110412873328], AE loss: [0.2877706722356379], TF loss: [0.22924036998301744] took 39.34504055976868\n",
      "Validation loss EPOCH: [150|1000], validation loss: [0.29348526429384947], AE loss: [0.13461884367279708], TF loss: [0.15886641899123788]\n",
      "Training loss EPOCH: [151|1000], training loss: [0.5169888306409121], AE loss: [0.2879479546099901], TF loss: [0.22904087789356709] took 36.82307434082031\n",
      "Validation loss EPOCH: [151|1000], validation loss: [0.29418326960876584], AE loss: [0.1346365676727146], TF loss: [0.1595467021688819]\n",
      "Training loss EPOCH: [152|1000], training loss: [0.5164876319468021], AE loss: [0.287650391459465], TF loss: [0.22883724188432097] took 40.591649532318115\n",
      "Validation loss EPOCH: [152|1000], validation loss: [0.29461928736418486], AE loss: [0.13457063026726246], TF loss: [0.1600486570969224]\n",
      "Training loss EPOCH: [153|1000], training loss: [0.5162936146371067], AE loss: [0.28761475114151835], TF loss: [0.2286788639612496] took 40.066869497299194\n",
      "Validation loss EPOCH: [153|1000], validation loss: [0.2943181237205863], AE loss: [0.1347149652428925], TF loss: [0.15960315614938736]\n",
      "Training loss EPOCH: [154|1000], training loss: [0.516086355317384], AE loss: [0.28746634093113244], TF loss: [0.228620013454929] took 37.35395407676697\n",
      "Validation loss EPOCH: [154|1000], validation loss: [0.29473717883229256], AE loss: [0.13476551440544426], TF loss: [0.15997166652232409]\n",
      "Training loss EPOCH: [155|1000], training loss: [0.5154915181919932], AE loss: [0.2874239617958665], TF loss: [0.2280675561632961] took 38.538170337677\n",
      "Validation loss EPOCH: [155|1000], validation loss: [0.2939858864992857], AE loss: [0.13475283049046993], TF loss: [0.15923305274918675]\n",
      "Training loss EPOCH: [156|1000], training loss: [0.5152277289889753], AE loss: [0.28709593671374023], TF loss: [0.22813178994692862] took 39.19710659980774\n",
      "Validation loss EPOCH: [156|1000], validation loss: [0.29401158448308706], AE loss: [0.13473036675713956], TF loss: [0.15928122075274587]\n",
      "Training loss EPOCH: [157|1000], training loss: [0.5152793782763183], AE loss: [0.28730414784513414], TF loss: [0.22797523229382932] took 37.73708772659302\n",
      "Validation loss EPOCH: [157|1000], validation loss: [0.29434586875140667], AE loss: [0.1347300794441253], TF loss: [0.1596157900057733]\n",
      "Training loss EPOCH: [158|1000], training loss: [0.5151536478661001], AE loss: [0.28757481602951884], TF loss: [0.22757882997393608] took 37.430458784103394\n",
      "Validation loss EPOCH: [158|1000], validation loss: [0.29521541576832533], AE loss: [0.13492808397859335], TF loss: [0.16028732992708683]\n",
      "Training loss EPOCH: [159|1000], training loss: [0.5144290449097753], AE loss: [0.2867910750210285], TF loss: [0.22763797058723867] took 41.32331037521362\n",
      "Validation loss EPOCH: [159|1000], validation loss: [0.2954873130656779], AE loss: [0.1347508653998375], TF loss: [0.16073644533753395]\n",
      "Training loss EPOCH: [160|1000], training loss: [0.5138449231162667], AE loss: [0.286549573764205], TF loss: [0.2272953512147069] took 39.62161827087402\n",
      "Validation loss EPOCH: [160|1000], validation loss: [0.29508508648723364], AE loss: [0.13479475886560977], TF loss: [0.16029032599180937]\n",
      "Training loss EPOCH: [161|1000], training loss: [0.5135351214557886], AE loss: [0.2864426476880908], TF loss: [0.2270924709737301] took 36.749815225601196\n",
      "Validation loss EPOCH: [161|1000], validation loss: [0.29483166616410017], AE loss: [0.1348101960029453], TF loss: [0.1600214708596468]\n",
      "Training loss EPOCH: [162|1000], training loss: [0.5136185502633452], AE loss: [0.2866114913485944], TF loss: [0.22700706007890403] took 39.99586033821106\n",
      "Validation loss EPOCH: [162|1000], validation loss: [0.2956344448029995], AE loss: [0.13502629636786878], TF loss: [0.16060814959928393]\n",
      "Training loss EPOCH: [163|1000], training loss: [0.5129303801804781], AE loss: [0.28613042342476547], TF loss: [0.22679995582439005] took 39.43043375015259\n",
      "Validation loss EPOCH: [163|1000], validation loss: [0.29594078520312905], AE loss: [0.13492467487230897], TF loss: [0.16101611079648137]\n",
      "Training loss EPOCH: [164|1000], training loss: [0.5128907873295248], AE loss: [0.28624703432433307], TF loss: [0.22664375440217555] took 40.04603052139282\n",
      "Validation loss EPOCH: [164|1000], validation loss: [0.29542974196374416], AE loss: [0.13492501573637128], TF loss: [0.16050472296774387]\n",
      "Training loss EPOCH: [165|1000], training loss: [0.5124470442533493], AE loss: [0.28587495419196784], TF loss: [0.2265720907598734] took 38.57423448562622\n",
      "Validation loss EPOCH: [165|1000], validation loss: [0.2951533952727914], AE loss: [0.13494074903428555], TF loss: [0.16021264577284455]\n",
      "Training loss EPOCH: [166|1000], training loss: [0.512309031561017], AE loss: [0.2860243527684361], TF loss: [0.22628468042239547] took 38.44774317741394\n",
      "Validation loss EPOCH: [166|1000], validation loss: [0.295791320502758], AE loss: [0.13490038691088557], TF loss: [0.16089093731716275]\n",
      "Training loss EPOCH: [167|1000], training loss: [0.5123407449573278], AE loss: [0.2862538178451359], TF loss: [0.22608692687936127] took 38.95186257362366\n",
      "Validation loss EPOCH: [167|1000], validation loss: [0.29596490226686], AE loss: [0.1349233326036483], TF loss: [0.16104156849905849]\n",
      "Training loss EPOCH: [168|1000], training loss: [0.5117227272130549], AE loss: [0.2857272233814001], TF loss: [0.2259955066256225] took 39.859169244766235\n",
      "Validation loss EPOCH: [168|1000], validation loss: [0.2952996529638767], AE loss: [0.13511467399075627], TF loss: [0.1601849775761366]\n",
      "Training loss EPOCH: [169|1000], training loss: [0.511372197419405], AE loss: [0.28561588819138706], TF loss: [0.22575630876235664] took 36.77664589881897\n",
      "Validation loss EPOCH: [169|1000], validation loss: [0.2953868452459574], AE loss: [0.13487118994817138], TF loss: [0.1605156548321247]\n",
      "Training loss EPOCH: [170|1000], training loss: [0.5117603843100369], AE loss: [0.286035398254171], TF loss: [0.22572498698718846] took 40.12279272079468\n",
      "Validation loss EPOCH: [170|1000], validation loss: [0.2954683257266879], AE loss: [0.13487897347658873], TF loss: [0.16058935085311532]\n",
      "Training loss EPOCH: [171|1000], training loss: [0.511092628352344], AE loss: [0.28549379855394363], TF loss: [0.22559882886707783] took 37.08385443687439\n",
      "Validation loss EPOCH: [171|1000], validation loss: [0.2962302975356579], AE loss: [0.13521112268790603], TF loss: [0.16101917624473572]\n",
      "Training loss EPOCH: [172|1000], training loss: [0.5111018805764616], AE loss: [0.285630275728181], TF loss: [0.22547160577960312] took 40.44406485557556\n",
      "Validation loss EPOCH: [172|1000], validation loss: [0.29598942305892706], AE loss: [0.13496828195638955], TF loss: [0.16102114273235202]\n",
      "Training loss EPOCH: [173|1000], training loss: [0.5104106087237597], AE loss: [0.28514055884443223], TF loss: [0.22527004941366613] took 39.66130065917969\n",
      "Validation loss EPOCH: [173|1000], validation loss: [0.29553629644215107], AE loss: [0.13506474252790213], TF loss: [0.16047155018895864]\n",
      "Training loss EPOCH: [174|1000], training loss: [0.5107858898118138], AE loss: [0.28581333742477], TF loss: [0.22497255122289062] took 39.07771158218384\n",
      "Validation loss EPOCH: [174|1000], validation loss: [0.2962801931425929], AE loss: [0.13513407274149358], TF loss: [0.16114611737430096]\n",
      "Training loss EPOCH: [175|1000], training loss: [0.5099181942641735], AE loss: [0.28504227730445564], TF loss: [0.22487591789104044] took 39.502103328704834\n",
      "Validation loss EPOCH: [175|1000], validation loss: [0.296533246524632], AE loss: [0.13501651119440794], TF loss: [0.1615167334675789]\n",
      "Training loss EPOCH: [176|1000], training loss: [0.5095936125144362], AE loss: [0.2848317048046738], TF loss: [0.22476190514862537] took 38.49853205680847\n",
      "Validation loss EPOCH: [176|1000], validation loss: [0.29613344743847847], AE loss: [0.1349716274999082], TF loss: [0.16116182040423155]\n",
      "Training loss EPOCH: [177|1000], training loss: [0.509420377202332], AE loss: [0.2848024901468307], TF loss: [0.22461788589134812] took 42.19776749610901\n",
      "Validation loss EPOCH: [177|1000], validation loss: [0.29665087815374136], AE loss: [0.1350656864233315], TF loss: [0.16158519266173244]\n",
      "Training loss EPOCH: [178|1000], training loss: [0.5089487261138856], AE loss: [0.2844519142527133], TF loss: [0.2244968106970191] took 36.50759315490723\n",
      "Validation loss EPOCH: [178|1000], validation loss: [0.2971837669610977], AE loss: [0.1352751161903143], TF loss: [0.16190865403041244]\n",
      "Training loss EPOCH: [179|1000], training loss: [0.5086318869143724], AE loss: [0.2842989070340991], TF loss: [0.2243329791817814] took 40.82321500778198\n",
      "Validation loss EPOCH: [179|1000], validation loss: [0.2971490379422903], AE loss: [0.13528201635926962], TF loss: [0.16186701972037554]\n",
      "Training loss EPOCH: [180|1000], training loss: [0.5084305698983371], AE loss: [0.2843972574919462], TF loss: [0.2240333124063909] took 39.000351667404175\n",
      "Validation loss EPOCH: [180|1000], validation loss: [0.29779219534248114], AE loss: [0.13522398564964533], TF loss: [0.16256820689886808]\n",
      "Training loss EPOCH: [181|1000], training loss: [0.5088722389191389], AE loss: [0.2846748929005116], TF loss: [0.22419734671711922] took 39.417449951171875\n",
      "Validation loss EPOCH: [181|1000], validation loss: [0.29781604930758476], AE loss: [0.13523746374994516], TF loss: [0.1625785822980106]\n",
      "Training loss EPOCH: [182|1000], training loss: [0.5080490121617913], AE loss: [0.284025683067739], TF loss: [0.22402332862839103] took 39.62006711959839\n",
      "Validation loss EPOCH: [182|1000], validation loss: [0.2970225475728512], AE loss: [0.13546205661259592], TF loss: [0.16156049026176333]\n",
      "Training loss EPOCH: [183|1000], training loss: [0.508205414749682], AE loss: [0.2843204236123711], TF loss: [0.22388499206863344] took 40.127705574035645\n",
      "Validation loss EPOCH: [183|1000], validation loss: [0.29738484136760235], AE loss: [0.1353653606493026], TF loss: [0.16201947908848524]\n",
      "Training loss EPOCH: [184|1000], training loss: [0.5075995908118784], AE loss: [0.28386105853132904], TF loss: [0.22373852971941233] took 38.771920680999756\n",
      "Validation loss EPOCH: [184|1000], validation loss: [0.2972535667940974], AE loss: [0.13546848064288497], TF loss: [0.16178508568555117]\n",
      "Training loss EPOCH: [185|1000], training loss: [0.5075446087867022], AE loss: [0.2839642916806042], TF loss: [0.2235803168732673] took 39.70371747016907\n",
      "Validation loss EPOCH: [185|1000], validation loss: [0.29817855823785067], AE loss: [0.1355533201713115], TF loss: [0.1626252392306924]\n",
      "Training loss EPOCH: [186|1000], training loss: [0.5068441247567534], AE loss: [0.2835869409609586], TF loss: [0.22325718333013356] took 37.57448410987854\n",
      "Validation loss EPOCH: [186|1000], validation loss: [0.29750978015363216], AE loss: [0.13540424243547022], TF loss: [0.16210553701967]\n",
      "Training loss EPOCH: [187|1000], training loss: [0.5063499286770821], AE loss: [0.2833627553191036], TF loss: [0.22298717149533331] took 41.00873780250549\n",
      "Validation loss EPOCH: [187|1000], validation loss: [0.29757465701550245], AE loss: [0.1354853017255664], TF loss: [0.16208935668691993]\n",
      "Training loss EPOCH: [188|1000], training loss: [0.5066331080161035], AE loss: [0.28351999446749687], TF loss: [0.22311311191879213] took 38.21524405479431\n",
      "Validation loss EPOCH: [188|1000], validation loss: [0.2974411938339472], AE loss: [0.13528781989589334], TF loss: [0.16215337254106998]\n",
      "Training loss EPOCH: [189|1000], training loss: [0.5063359285704792], AE loss: [0.28339234576560557], TF loss: [0.22294358327053487] took 38.32824087142944\n",
      "Validation loss EPOCH: [189|1000], validation loss: [0.29761129431426525], AE loss: [0.13542845309711993], TF loss: [0.16218284144997597]\n",
      "Training loss EPOCH: [190|1000], training loss: [0.5057574668899179], AE loss: [0.28273225482553244], TF loss: [0.2230252088047564] took 42.171706438064575\n",
      "Validation loss EPOCH: [190|1000], validation loss: [0.29805462434887886], AE loss: [0.13567215483635664], TF loss: [0.16238246858119965]\n",
      "Training loss EPOCH: [191|1000], training loss: [0.5057998532429338], AE loss: [0.283133263932541], TF loss: [0.22266659000888467] took 38.55525517463684\n",
      "Validation loss EPOCH: [191|1000], validation loss: [0.29776150919497013], AE loss: [0.13573892577551305], TF loss: [0.16202258877456188]\n",
      "Training loss EPOCH: [192|1000], training loss: [0.5062345270998776], AE loss: [0.28352699684910476], TF loss: [0.22270753257907927] took 39.34995245933533\n",
      "Validation loss EPOCH: [192|1000], validation loss: [0.29795476514846087], AE loss: [0.13560446491464972], TF loss: [0.16235029511153698]\n",
      "Training loss EPOCH: [193|1000], training loss: [0.5049628023989499], AE loss: [0.28255799994803965], TF loss: [0.22240480338223279] took 40.718236684799194\n",
      "Validation loss EPOCH: [193|1000], validation loss: [0.29751551523804665], AE loss: [0.13568466785363853], TF loss: [0.16183084854856133]\n",
      "Training loss EPOCH: [194|1000], training loss: [0.5050527639687061], AE loss: [0.28264345205388963], TF loss: [0.22240931214764714] took 40.55074715614319\n",
      "Validation loss EPOCH: [194|1000], validation loss: [0.2983114644885063], AE loss: [0.13568110228516161], TF loss: [0.16263036150485277]\n",
      "Training loss EPOCH: [195|1000], training loss: [0.5047007980756462], AE loss: [0.28245631023310125], TF loss: [0.22224448714405298] took 38.0690131187439\n",
      "Validation loss EPOCH: [195|1000], validation loss: [0.296832256950438], AE loss: [0.1355892331339419], TF loss: [0.16124302381649613]\n",
      "Training loss EPOCH: [196|1000], training loss: [0.5045519983395934], AE loss: [0.2823752227704972], TF loss: [0.22217677370645106] took 40.291537284851074\n",
      "Validation loss EPOCH: [196|1000], validation loss: [0.29865522403270006], AE loss: [0.135574844898656], TF loss: [0.16308037750422955]\n",
      "Training loss EPOCH: [197|1000], training loss: [0.505319896619767], AE loss: [0.2833408487495035], TF loss: [0.22197904717177153] took 38.48864555358887\n",
      "Validation loss EPOCH: [197|1000], validation loss: [0.2982243336737156], AE loss: [0.13590737036429346], TF loss: [0.16231696028262377]\n",
      "Training loss EPOCH: [198|1000], training loss: [0.5041951090097427], AE loss: [0.2822221899405122], TF loss: [0.22197291743941605] took 38.30904817581177\n",
      "Validation loss EPOCH: [198|1000], validation loss: [0.2985857781022787], AE loss: [0.13598666596226394], TF loss: [0.16259911516681314]\n",
      "Training loss EPOCH: [199|1000], training loss: [0.5039219977334142], AE loss: [0.2821621294133365], TF loss: [0.22175986878573895] took 39.531943559646606\n",
      "Validation loss EPOCH: [199|1000], validation loss: [0.29836267977952957], AE loss: [0.13599045434966683], TF loss: [0.16237222775816917]\n",
      "Training loss EPOCH: [200|1000], training loss: [0.5039464556612074], AE loss: [0.2822071018163115], TF loss: [0.22173935477621853] took 39.48257565498352\n",
      "Validation loss EPOCH: [200|1000], validation loss: [0.29932318814098835], AE loss: [0.13597084116190672], TF loss: [0.16335234558209777]\n",
      "Training loss EPOCH: [201|1000], training loss: [0.5037040109746158], AE loss: [0.28208717540837824], TF loss: [0.22161683510057628] took 38.534783363342285\n",
      "Validation loss EPOCH: [201|1000], validation loss: [0.2984334584325552], AE loss: [0.13583185872994363], TF loss: [0.16260159853845835]\n",
      "Training loss EPOCH: [202|1000], training loss: [0.5037730117328465], AE loss: [0.28233937243930995], TF loss: [0.22143363882787526] took 38.532798290252686\n",
      "Validation loss EPOCH: [202|1000], validation loss: [0.2981751197949052], AE loss: [0.13584798900410533], TF loss: [0.16232713405042887]\n",
      "Training loss EPOCH: [203|1000], training loss: [0.5023268288932741], AE loss: [0.2810731949284673], TF loss: [0.22125363419763744] took 40.36345648765564\n",
      "Validation loss EPOCH: [203|1000], validation loss: [0.29868071246892214], AE loss: [0.13644751580432057], TF loss: [0.16223320038989186]\n",
      "Training loss EPOCH: [204|1000], training loss: [0.5033399551175535], AE loss: [0.28209912520833313], TF loss: [0.22124082944355905] took 38.73202991485596\n",
      "Validation loss EPOCH: [204|1000], validation loss: [0.2988853454589844], AE loss: [0.1359567369800061], TF loss: [0.16292860638350248]\n",
      "Training loss EPOCH: [205|1000], training loss: [0.5023675528354943], AE loss: [0.2812401719857007], TF loss: [0.22112737991847098] took 38.18319320678711\n",
      "Validation loss EPOCH: [205|1000], validation loss: [0.2990830522030592], AE loss: [0.13611951493658125], TF loss: [0.16296353889629245]\n",
      "Training loss EPOCH: [206|1000], training loss: [0.5020835143513978], AE loss: [0.28122872952371836], TF loss: [0.22085478506051004] took 37.65344834327698\n",
      "Validation loss EPOCH: [206|1000], validation loss: [0.29863073769956827], AE loss: [0.13590033748187125], TF loss: [0.16273040045052767]\n",
      "Training loss EPOCH: [207|1000], training loss: [0.5019730259664357], AE loss: [0.28101954772137105], TF loss: [0.22095347894355655] took 41.472288846969604\n",
      "Validation loss EPOCH: [207|1000], validation loss: [0.2993377996608615], AE loss: [0.1363617400638759], TF loss: [0.16297605820000172]\n",
      "Training loss EPOCH: [208|1000], training loss: [0.5020375098101795], AE loss: [0.28116576955653727], TF loss: [0.22087173978798091] took 39.14658522605896\n",
      "Validation loss EPOCH: [208|1000], validation loss: [0.299542379565537], AE loss: [0.13641308480873704], TF loss: [0.16312929522246122]\n",
      "Training loss EPOCH: [209|1000], training loss: [0.5016151797026396], AE loss: [0.28089264780282974], TF loss: [0.2207225332967937] took 40.554009199142456\n",
      "Validation loss EPOCH: [209|1000], validation loss: [0.29929476976394653], AE loss: [0.13626367622055113], TF loss: [0.16303109331056476]\n",
      "Training loss EPOCH: [210|1000], training loss: [0.5011059902608395], AE loss: [0.28064623195677996], TF loss: [0.22045975853689015] took 39.197386026382446\n",
      "Validation loss EPOCH: [210|1000], validation loss: [0.2998919552192092], AE loss: [0.13672758894972503], TF loss: [0.1631643669679761]\n",
      "Training loss EPOCH: [211|1000], training loss: [0.5013450956903398], AE loss: [0.28076116647571325], TF loss: [0.22058392828330398] took 38.66317296028137\n",
      "Validation loss EPOCH: [211|1000], validation loss: [0.2992903692647815], AE loss: [0.13656657608225942], TF loss: [0.16272379271686077]\n",
      "Training loss EPOCH: [212|1000], training loss: [0.5009196461178362], AE loss: [0.28045879234559834], TF loss: [0.22046085353940725] took 41.10666823387146\n",
      "Validation loss EPOCH: [212|1000], validation loss: [0.2998593393713236], AE loss: [0.13667546398937702], TF loss: [0.1631838772445917]\n",
      "Training loss EPOCH: [213|1000], training loss: [0.5017615011893213], AE loss: [0.2815960622392595], TF loss: [0.22016543801873922] took 40.45277738571167\n",
      "Validation loss EPOCH: [213|1000], validation loss: [0.3004681905731559], AE loss: [0.13641887716948986], TF loss: [0.16404931340366602]\n",
      "Training loss EPOCH: [214|1000], training loss: [0.5008414625190198], AE loss: [0.28064265800639987], TF loss: [0.22019880264997482] took 39.19173836708069\n",
      "Validation loss EPOCH: [214|1000], validation loss: [0.3000736180692911], AE loss: [0.13657673611305654], TF loss: [0.16349688125774264]\n",
      "Training loss EPOCH: [215|1000], training loss: [0.5007885927334428], AE loss: [0.2806161534972489], TF loss: [0.2201724408660084] took 39.88984942436218\n",
      "Validation loss EPOCH: [215|1000], validation loss: [0.30011887941509485], AE loss: [0.13667192496359348], TF loss: [0.16344695538282394]\n",
      "Training loss EPOCH: [216|1000], training loss: [0.5000009667128325], AE loss: [0.27998257195577025], TF loss: [0.22001839382573962] took 38.31525206565857\n",
      "Validation loss EPOCH: [216|1000], validation loss: [0.3002701308578253], AE loss: [0.13700406183488667], TF loss: [0.16326606879010797]\n",
      "Training loss EPOCH: [217|1000], training loss: [0.5011497214436531], AE loss: [0.28129248740151525], TF loss: [0.21985723567195237] took 41.605440855026245\n",
      "Validation loss EPOCH: [217|1000], validation loss: [0.300085817463696], AE loss: [0.13694448745809495], TF loss: [0.16314132930710912]\n",
      "Training loss EPOCH: [218|1000], training loss: [0.49906401755288243], AE loss: [0.2793206472415477], TF loss: [0.2197433717083186] took 37.97181510925293\n",
      "Validation loss EPOCH: [218|1000], validation loss: [0.30117454193532467], AE loss: [0.1370882790070027], TF loss: [0.16408626222983003]\n",
      "Training loss EPOCH: [219|1000], training loss: [0.4999521942809224], AE loss: [0.28018032503314316], TF loss: [0.21977186994627118] took 41.127463579177856\n",
      "Validation loss EPOCH: [219|1000], validation loss: [0.30082834511995316], AE loss: [0.1371287307702005], TF loss: [0.1636996171437204]\n",
      "Training loss EPOCH: [220|1000], training loss: [0.49961787834763527], AE loss: [0.28023301740176976], TF loss: [0.21938486257568002] took 39.238614082336426\n",
      "Validation loss EPOCH: [220|1000], validation loss: [0.3008351484313607], AE loss: [0.1369759247172624], TF loss: [0.16385922627523541]\n",
      "Training loss EPOCH: [221|1000], training loss: [0.5000786590389907], AE loss: [0.2804155780468136], TF loss: [0.21966308122500777] took 39.09966707229614\n",
      "Validation loss EPOCH: [221|1000], validation loss: [0.30209525488317013], AE loss: [0.13715006015263498], TF loss: [0.1649451949633658]\n",
      "Training loss EPOCH: [222|1000], training loss: [0.49938679998740554], AE loss: [0.2798457827884704], TF loss: [0.2195410174317658] took 39.030635356903076\n",
      "Validation loss EPOCH: [222|1000], validation loss: [0.3007732657715678], AE loss: [0.13702236441895366], TF loss: [0.1637509036809206]\n",
      "Training loss EPOCH: [223|1000], training loss: [0.49979148898273706], AE loss: [0.28038677223958075], TF loss: [0.21940471651032567] took 36.99938368797302\n",
      "Validation loss EPOCH: [223|1000], validation loss: [0.3008911292999983], AE loss: [0.1372103348840028], TF loss: [0.16368079464882612]\n",
      "Training loss EPOCH: [224|1000], training loss: [0.49791706120595336], AE loss: [0.2787534254603088], TF loss: [0.2191636359784752] took 37.33464312553406\n",
      "Validation loss EPOCH: [224|1000], validation loss: [0.3016194514930248], AE loss: [0.1375304339453578], TF loss: [0.16408901335671544]\n",
      "Training loss EPOCH: [225|1000], training loss: [0.49869147641584277], AE loss: [0.2795255759265274], TF loss: [0.21916590072214603] took 40.95918369293213\n",
      "Validation loss EPOCH: [225|1000], validation loss: [0.30154977552592754], AE loss: [0.13723259535618126], TF loss: [0.16431717900559306]\n",
      "Training loss EPOCH: [226|1000], training loss: [0.4982250458560884], AE loss: [0.2792418012395501], TF loss: [0.2189832436852157] took 39.68593144416809\n",
      "Validation loss EPOCH: [226|1000], validation loss: [0.3012512717396021], AE loss: [0.13786413660272956], TF loss: [0.1633871360681951]\n",
      "Training loss EPOCH: [227|1000], training loss: [0.49901412380859256], AE loss: [0.2801141228992492], TF loss: [0.2189000016078353] took 40.27038621902466\n",
      "Validation loss EPOCH: [227|1000], validation loss: [0.3019368005916476], AE loss: [0.137688591144979], TF loss: [0.16424820804968476]\n",
      "Training loss EPOCH: [228|1000], training loss: [0.49772563436999917], AE loss: [0.2788374712690711], TF loss: [0.21888816100545228] took 39.846436977386475\n",
      "Validation loss EPOCH: [228|1000], validation loss: [0.3016087058931589], AE loss: [0.13714359141886234], TF loss: [0.16446512006223202]\n",
      "Training loss EPOCH: [229|1000], training loss: [0.498448871076107], AE loss: [0.27947848290205], TF loss: [0.21897038794122636] took 41.200181007385254\n",
      "Validation loss EPOCH: [229|1000], validation loss: [0.30126130767166615], AE loss: [0.13752167741768062], TF loss: [0.16373963002115488]\n",
      "Training loss EPOCH: [230|1000], training loss: [0.4980662977322936], AE loss: [0.27930488297715783], TF loss: [0.21876141522079706] took 38.42225456237793\n",
      "Validation loss EPOCH: [230|1000], validation loss: [0.3020925857126713], AE loss: [0.13758226623758674], TF loss: [0.1645103208720684]\n",
      "Training loss EPOCH: [231|1000], training loss: [0.4973627715371549], AE loss: [0.2787035161163658], TF loss: [0.21865925518795848] took 37.67692852020264\n",
      "Validation loss EPOCH: [231|1000], validation loss: [0.30206882301717997], AE loss: [0.13762677018530667], TF loss: [0.1644420507363975]\n",
      "Training loss EPOCH: [232|1000], training loss: [0.49871518509462476], AE loss: [0.28007601597346365], TF loss: [0.21863917005248368] took 38.726972818374634\n",
      "Validation loss EPOCH: [232|1000], validation loss: [0.30129681434482336], AE loss: [0.13769657583907247], TF loss: [0.16360023897141218]\n",
      "Training loss EPOCH: [233|1000], training loss: [0.4962906036525965], AE loss: [0.277953747427091], TF loss: [0.21833685645833611] took 37.925108909606934\n",
      "Validation loss EPOCH: [233|1000], validation loss: [0.30256125424057245], AE loss: [0.1381158826407045], TF loss: [0.16444537229835987]\n",
      "Training loss EPOCH: [234|1000], training loss: [0.49816886940971017], AE loss: [0.27973461942747235], TF loss: [0.21843425370752811] took 41.9605827331543\n",
      "Validation loss EPOCH: [234|1000], validation loss: [0.3015759550035], AE loss: [0.1377642061561346], TF loss: [0.16381174698472023]\n",
      "Training loss EPOCH: [235|1000], training loss: [0.4963607396930456], AE loss: [0.2780409900005907], TF loss: [0.21831974992528558] took 41.00606155395508\n",
      "Validation loss EPOCH: [235|1000], validation loss: [0.3017969774082303], AE loss: [0.1379104449879378], TF loss: [0.16388653218746185]\n",
      "Training loss EPOCH: [236|1000], training loss: [0.49778726790100336], AE loss: [0.27962505957111716], TF loss: [0.21816221135668457] took 37.12291741371155\n",
      "Validation loss EPOCH: [236|1000], validation loss: [0.30219781026244164], AE loss: [0.13775947061367333], TF loss: [0.1644383384846151]\n",
      "Training loss EPOCH: [237|1000], training loss: [0.49690933618694544], AE loss: [0.27871290827170014], TF loss: [0.21819642814807594] took 36.22936129570007\n",
      "Validation loss EPOCH: [237|1000], validation loss: [0.3023486603051424], AE loss: [0.13786692474968731], TF loss: [0.16448173392564058]\n",
      "Training loss EPOCH: [238|1000], training loss: [0.49639324797317386], AE loss: [0.27825048845261335], TF loss: [0.21814276068471372] took 40.95060634613037\n",
      "Validation loss EPOCH: [238|1000], validation loss: [0.3023683987557888], AE loss: [0.13810985581949353], TF loss: [0.1642585452646017]\n",
      "Training loss EPOCH: [239|1000], training loss: [0.4953530323691666], AE loss: [0.2773264138959348], TF loss: [0.2180266184732318] took 37.934269428253174\n",
      "Validation loss EPOCH: [239|1000], validation loss: [0.30277307238429785], AE loss: [0.13842614996246994], TF loss: [0.16434692544862628]\n",
      "Training loss EPOCH: [240|1000], training loss: [0.4961872734129429], AE loss: [0.27818822558037937], TF loss: [0.2179990487638861] took 37.35620403289795\n",
      "Validation loss EPOCH: [240|1000], validation loss: [0.3028910253196955], AE loss: [0.13837438076734543], TF loss: [0.1645166459493339]\n",
      "Training loss EPOCH: [241|1000], training loss: [0.49534799717366695], AE loss: [0.2775690737180412], TF loss: [0.2177789208944887] took 41.08238506317139\n",
      "Validation loss EPOCH: [241|1000], validation loss: [0.3024494396522641], AE loss: [0.13833574508316815], TF loss: [0.16411369387060404]\n",
      "Training loss EPOCH: [242|1000], training loss: [0.49636950716376305], AE loss: [0.27855659020133317], TF loss: [0.21781291672959924] took 40.92625069618225\n",
      "Validation loss EPOCH: [242|1000], validation loss: [0.3031978942453861], AE loss: [0.13846304221078753], TF loss: [0.1647348520345986]\n",
      "Training loss EPOCH: [243|1000], training loss: [0.4959712936542928], AE loss: [0.27828212594613433], TF loss: [0.21768916747532785] took 40.03670597076416\n",
      "Validation loss EPOCH: [243|1000], validation loss: [0.3021620577201247], AE loss: [0.13808128982782364], TF loss: [0.16408076928928494]\n",
      "Training loss EPOCH: [244|1000], training loss: [0.4950977684929967], AE loss: [0.2773384538013488], TF loss: [0.2177593158558011] took 39.07094740867615\n",
      "Validation loss EPOCH: [244|1000], validation loss: [0.3032638169825077], AE loss: [0.1383178341202438], TF loss: [0.16494598239660263]\n",
      "Training loss EPOCH: [245|1000], training loss: [0.49573583947494626], AE loss: [0.27815308584831655], TF loss: [0.21758275548927486] took 40.38143754005432\n",
      "Validation loss EPOCH: [245|1000], validation loss: [0.30259935930371284], AE loss: [0.13835534756071866], TF loss: [0.16424401151016355]\n",
      "Training loss EPOCH: [246|1000], training loss: [0.49407630134373903], AE loss: [0.27647437318228185], TF loss: [0.21760192816145718] took 40.24684977531433\n",
      "Validation loss EPOCH: [246|1000], validation loss: [0.30307109747081995], AE loss: [0.13878865609876812], TF loss: [0.1642824406735599]\n",
      "Training loss EPOCH: [247|1000], training loss: [0.4953284249641001], AE loss: [0.2777503877878189], TF loss: [0.21757803694345057] took 36.57981014251709\n",
      "Validation loss EPOCH: [247|1000], validation loss: [0.30352598056197166], AE loss: [0.13868322409689426], TF loss: [0.1648427527397871]\n",
      "Training loss EPOCH: [248|1000], training loss: [0.4953270051628351], AE loss: [0.2780122272670269], TF loss: [0.21731477440334857] took 37.22558546066284\n",
      "Validation loss EPOCH: [248|1000], validation loss: [0.3017786704003811], AE loss: [0.1370348664931953], TF loss: [0.1647438034415245]\n",
      "Training loss EPOCH: [249|1000], training loss: [0.49499659705907106], AE loss: [0.27766764373518527], TF loss: [0.2173289565835148] took 40.58740854263306\n",
      "Validation loss EPOCH: [249|1000], validation loss: [0.30347864516079426], AE loss: [0.13894105539657176], TF loss: [0.16453758580610156]\n",
      "Training loss EPOCH: [250|1000], training loss: [0.49461613362655044], AE loss: [0.2774271871894598], TF loss: [0.21718894504010677] took 37.37817597389221\n",
      "Validation loss EPOCH: [250|1000], validation loss: [0.3029408184811473], AE loss: [0.13840004010125995], TF loss: [0.16454077791422606]\n",
      "Training loss EPOCH: [251|1000], training loss: [0.494930203538388], AE loss: [0.27764678257517517], TF loss: [0.21728342212736607] took 35.59316301345825\n",
      "Validation loss EPOCH: [251|1000], validation loss: [0.3035962264984846], AE loss: [0.13842782215215266], TF loss: [0.16516840178519487]\n",
      "Training loss EPOCH: [252|1000], training loss: [0.4941656100563705], AE loss: [0.27704837382771075], TF loss: [0.21711723529733717] took 35.36658239364624\n",
      "Validation loss EPOCH: [252|1000], validation loss: [0.304032351821661], AE loss: [0.13888062979094684], TF loss: [0.16515172133222222]\n",
      "Training loss EPOCH: [253|1000], training loss: [0.4946386073715985], AE loss: [0.27743350015953183], TF loss: [0.21720510767772794] took 39.404141902923584\n",
      "Validation loss EPOCH: [253|1000], validation loss: [0.3029862055554986], AE loss: [0.13872971013188362], TF loss: [0.16425649309530854]\n",
      "Training loss EPOCH: [254|1000], training loss: [0.494315633084625], AE loss: [0.27736569405533373], TF loss: [0.21694993693381548] took 37.28788495063782\n",
      "Validation loss EPOCH: [254|1000], validation loss: [0.30352617520838976], AE loss: [0.13825100241228938], TF loss: [0.16527517326176167]\n",
      "Training loss EPOCH: [255|1000], training loss: [0.49400001764297485], AE loss: [0.27718540700152516], TF loss: [0.2168146106414497] took 40.88274264335632\n",
      "Validation loss EPOCH: [255|1000], validation loss: [0.30377494916319847], AE loss: [0.1390140384901315], TF loss: [0.16476091323420405]\n",
      "Training loss EPOCH: [256|1000], training loss: [0.4938092599622905], AE loss: [0.277107018744573], TF loss: [0.2167022400535643] took 39.17787170410156\n",
      "Validation loss EPOCH: [256|1000], validation loss: [0.3034417312592268], AE loss: [0.13802397437393665], TF loss: [0.165417758282274]\n",
      "Training loss EPOCH: [257|1000], training loss: [0.49339777370914817], AE loss: [0.27670769370160997], TF loss: [0.2166900800075382] took 38.12769341468811\n",
      "Validation loss EPOCH: [257|1000], validation loss: [0.30470627546310425], AE loss: [0.13894015038385987], TF loss: [0.1657661246135831]\n",
      "Training loss EPOCH: [258|1000], training loss: [0.4932395573705435], AE loss: [0.2765108284074813], TF loss: [0.2167287275660783] took 39.633092641830444\n",
      "Validation loss EPOCH: [258|1000], validation loss: [0.30345688201487064], AE loss: [0.13891917769797146], TF loss: [0.16453770268708467]\n",
      "Training loss EPOCH: [259|1000], training loss: [0.49288419261574745], AE loss: [0.27627229993231595], TF loss: [0.216611891053617] took 39.355891942977905\n",
      "Validation loss EPOCH: [259|1000], validation loss: [0.30414885096251965], AE loss: [0.13927237642928958], TF loss: [0.16487647499889135]\n",
      "Training loss EPOCH: [260|1000], training loss: [0.49229702400043607], AE loss: [0.2758403620682657], TF loss: [0.21645666239783168] took 37.891051292419434\n",
      "Validation loss EPOCH: [260|1000], validation loss: [0.304626720957458], AE loss: [0.1394989904947579], TF loss: [0.16512773046270013]\n",
      "Training loss EPOCH: [261|1000], training loss: [0.49303993163630366], AE loss: [0.27655020728707314], TF loss: [0.21648972388356924] took 39.715067863464355\n",
      "Validation loss EPOCH: [261|1000], validation loss: [0.3037329027429223], AE loss: [0.1390472585335374], TF loss: [0.16468564234673977]\n",
      "Training loss EPOCH: [262|1000], training loss: [0.4933343594893813], AE loss: [0.2768094828352332], TF loss: [0.21652487781830132] took 40.55165982246399\n",
      "Validation loss EPOCH: [262|1000], validation loss: [0.30427501536905766], AE loss: [0.13900891179218888], TF loss: [0.16526610543951392]\n",
      "Training loss EPOCH: [263|1000], training loss: [0.49227076256647706], AE loss: [0.27600425691343844], TF loss: [0.21626650379039347] took 37.54923439025879\n",
      "Validation loss EPOCH: [263|1000], validation loss: [0.30410969350486994], AE loss: [0.13895482732914388], TF loss: [0.16515486501157284]\n",
      "Training loss EPOCH: [264|1000], training loss: [0.492528289090842], AE loss: [0.2762924076523632], TF loss: [0.21623588120564818] took 39.683390855789185\n",
      "Validation loss EPOCH: [264|1000], validation loss: [0.30460663698613644], AE loss: [0.13890320505015552], TF loss: [0.165703434497118]\n",
      "Training loss EPOCH: [265|1000], training loss: [0.4930890277028084], AE loss: [0.27670566947199404], TF loss: [0.2163833591621369] took 39.1155743598938\n",
      "Validation loss EPOCH: [265|1000], validation loss: [0.30440615117549896], AE loss: [0.13856107811443508], TF loss: [0.16584507236257195]\n",
      "Training loss EPOCH: [266|1000], training loss: [0.49125131173059344], AE loss: [0.27505913260392845], TF loss: [0.21619218029081821] took 40.20072793960571\n",
      "Validation loss EPOCH: [266|1000], validation loss: [0.30425387248396873], AE loss: [0.1393967792391777], TF loss: [0.1648570946417749]\n",
      "Training loss EPOCH: [267|1000], training loss: [0.4927476826123893], AE loss: [0.2765485856216401], TF loss: [0.21619909582659602] took 39.721243381500244\n",
      "Validation loss EPOCH: [267|1000], validation loss: [0.3047149647027254], AE loss: [0.1391024647746235], TF loss: [0.1656125015579164]\n",
      "Training loss EPOCH: [268|1000], training loss: [0.49289946584030986], AE loss: [0.2767673197668046], TF loss: [0.2161321451421827] took 40.48110389709473\n",
      "Validation loss EPOCH: [268|1000], validation loss: [0.303787793032825], AE loss: [0.1387414513155818], TF loss: [0.16504633659496903]\n",
      "Training loss EPOCH: [269|1000], training loss: [0.4906036052852869], AE loss: [0.2748032542876899], TF loss: [0.2158003500662744] took 42.85101890563965\n",
      "Validation loss EPOCH: [269|1000], validation loss: [0.30476590152829885], AE loss: [0.13944711326621473], TF loss: [0.16531878802925348]\n",
      "Training loss EPOCH: [270|1000], training loss: [0.49171919329091907], AE loss: [0.2759337960742414], TF loss: [0.2157853974495083] took 37.23144888877869\n",
      "Validation loss EPOCH: [270|1000], validation loss: [0.30490016750991344], AE loss: [0.13949805428273976], TF loss: [0.16540211392566562]\n",
      "Training loss EPOCH: [271|1000], training loss: [0.4909703703597188], AE loss: [0.27491645235568285], TF loss: [0.21605391846969724] took 40.78077816963196\n",
      "Validation loss EPOCH: [271|1000], validation loss: [0.3057029861956835], AE loss: [0.1399904708378017], TF loss: [0.16571251628920436]\n",
      "Training loss EPOCH: [272|1000], training loss: [0.4911836148239672], AE loss: [0.2753075922373682], TF loss: [0.21587602305226028] took 37.63731050491333\n",
      "Validation loss EPOCH: [272|1000], validation loss: [0.30454746447503567], AE loss: [0.1394890418741852], TF loss: [0.16505842143669724]\n",
      "Training loss EPOCH: [273|1000], training loss: [0.49041468789801], AE loss: [0.27464132267050445], TF loss: [0.21577336639165878] took 41.62215304374695\n",
      "Validation loss EPOCH: [273|1000], validation loss: [0.30579681787639856], AE loss: [0.13978087017312646], TF loss: [0.16601594723761082]\n",
      "Training loss EPOCH: [274|1000], training loss: [0.49326567351818085], AE loss: [0.27746605523861945], TF loss: [0.2157996178139001] took 41.21753191947937\n",
      "Validation loss EPOCH: [274|1000], validation loss: [0.30541599355638027], AE loss: [0.13961756858043373], TF loss: [0.16579842334613204]\n",
      "Training loss EPOCH: [275|1000], training loss: [0.4907701122574508], AE loss: [0.27517081005498767], TF loss: [0.21559930336661637] took 42.42386794090271\n",
      "Validation loss EPOCH: [275|1000], validation loss: [0.3048476865515113], AE loss: [0.1397015054244548], TF loss: [0.1651461790315807]\n",
      "Training loss EPOCH: [276|1000], training loss: [0.4899679059162736], AE loss: [0.27434929786249995], TF loss: [0.2156186094507575] took 39.914387226104736\n",
      "Validation loss EPOCH: [276|1000], validation loss: [0.30556186847388744], AE loss: [0.1394568297546357], TF loss: [0.16610504174605012]\n",
      "Training loss EPOCH: [277|1000], training loss: [0.49054783396422863], AE loss: [0.27511335583403707], TF loss: [0.215434480458498] took 43.62381362915039\n",
      "Validation loss EPOCH: [277|1000], validation loss: [0.3056971551850438], AE loss: [0.1398013245780021], TF loss: [0.1658958294428885]\n",
      "Training loss EPOCH: [278|1000], training loss: [0.4901980119757354], AE loss: [0.2747986330650747], TF loss: [0.21539937844499946] took 40.60875868797302\n",
      "Validation loss EPOCH: [278|1000], validation loss: [0.3049724167212844], AE loss: [0.13943986711092293], TF loss: [0.16553255170583725]\n",
      "Training loss EPOCH: [279|1000], training loss: [0.48904388630762696], AE loss: [0.273550258949399], TF loss: [0.21549362782388926] took 38.1299204826355\n",
      "Validation loss EPOCH: [279|1000], validation loss: [0.30485989805310965], AE loss: [0.13999515236355364], TF loss: [0.16486474545672536]\n",
      "Training loss EPOCH: [280|1000], training loss: [0.49053711723536253], AE loss: [0.2749880275223404], TF loss: [0.21554908901453018] took 40.36584973335266\n",
      "Validation loss EPOCH: [280|1000], validation loss: [0.3067810982465744], AE loss: [0.1401445847004652], TF loss: [0.1666365168057382]\n",
      "Training loss EPOCH: [281|1000], training loss: [0.4884071215055883], AE loss: [0.2731473599560559], TF loss: [0.21525976224802434] took 38.18265438079834\n",
      "Validation loss EPOCH: [281|1000], validation loss: [0.3058416787534952], AE loss: [0.14006226183846593], TF loss: [0.16577941831201315]\n",
      "Training loss EPOCH: [282|1000], training loss: [0.48911393200978637], AE loss: [0.2739021989982575], TF loss: [0.2152117327786982] took 38.71888732910156\n",
      "Validation loss EPOCH: [282|1000], validation loss: [0.3057698458433151], AE loss: [0.1399176176637411], TF loss: [0.16585222957655787]\n",
      "Training loss EPOCH: [283|1000], training loss: [0.48987852595746517], AE loss: [0.2746618236415088], TF loss: [0.21521669952198863] took 39.08209991455078\n",
      "Validation loss EPOCH: [283|1000], validation loss: [0.3055634265765548], AE loss: [0.13990019960328937], TF loss: [0.16566322650760412]\n",
      "Training loss EPOCH: [284|1000], training loss: [0.4907949762418866], AE loss: [0.27556783403269947], TF loss: [0.21522714290767908] took 39.00960969924927\n",
      "Validation loss EPOCH: [284|1000], validation loss: [0.3050636360421777], AE loss: [0.1397838566917926], TF loss: [0.16527977865189314]\n",
      "Training loss EPOCH: [285|1000], training loss: [0.4900057544000447], AE loss: [0.2748250877484679], TF loss: [0.2151806673500687] took 39.97447729110718\n",
      "Validation loss EPOCH: [285|1000], validation loss: [0.30594001803547144], AE loss: [0.1399424890987575], TF loss: [0.16599752847105265]\n",
      "Training loss EPOCH: [286|1000], training loss: [0.4884616434574127], AE loss: [0.2733229328878224], TF loss: [0.21513871173374355] took 41.31934976577759\n",
      "Validation loss EPOCH: [286|1000], validation loss: [0.30511763226240873], AE loss: [0.1396671982947737], TF loss: [0.16545043466612697]\n",
      "Training loss EPOCH: [287|1000], training loss: [0.4906356814317405], AE loss: [0.2756902400869876], TF loss: [0.21494544274173677] took 35.914766788482666\n",
      "Validation loss EPOCH: [287|1000], validation loss: [0.3051133928820491], AE loss: [0.1398785763885826], TF loss: [0.16523481393232942]\n",
      "Training loss EPOCH: [288|1000], training loss: [0.4876024196855724], AE loss: [0.2728587822057307], TF loss: [0.21474363608285785] took 39.17549395561218\n",
      "Validation loss EPOCH: [288|1000], validation loss: [0.3065616022795439], AE loss: [0.14024635730311275], TF loss: [0.16631524357944727]\n",
      "Training loss EPOCH: [289|1000], training loss: [0.48852850031107664], AE loss: [0.27361733303405344], TF loss: [0.21491116588003933] took 40.51749849319458\n",
      "Validation loss EPOCH: [289|1000], validation loss: [0.3050824236124754], AE loss: [0.1399098145775497], TF loss: [0.16517260763794184]\n",
      "Training loss EPOCH: [290|1000], training loss: [0.488011728040874], AE loss: [0.27321303403005004], TF loss: [0.21479869377799332] took 37.5182888507843\n",
      "Validation loss EPOCH: [290|1000], validation loss: [0.3075681012123823], AE loss: [0.1410443102940917], TF loss: [0.16652379045262933]\n",
      "Training loss EPOCH: [291|1000], training loss: [0.4893048885278404], AE loss: [0.27444097865372896], TF loss: [0.21486390940845013] took 38.78038239479065\n",
      "Validation loss EPOCH: [291|1000], validation loss: [0.30568876676261425], AE loss: [0.13972511747851968], TF loss: [0.16596365068107843]\n",
      "Training loss EPOCH: [292|1000], training loss: [0.48969462141394615], AE loss: [0.27481928397901356], TF loss: [0.21487533953040838] took 38.68107843399048\n",
      "Validation loss EPOCH: [292|1000], validation loss: [0.3057222794741392], AE loss: [0.1399377475026995], TF loss: [0.16578452987596393]\n",
      "Training loss EPOCH: [293|1000], training loss: [0.4886118797585368], AE loss: [0.2736598988994956], TF loss: [0.2149519817903638] took 39.18013954162598\n",
      "Validation loss EPOCH: [293|1000], validation loss: [0.3065713560208678], AE loss: [0.14007893414236605], TF loss: [0.16649242211133242]\n",
      "Training loss EPOCH: [294|1000], training loss: [0.487101748585701], AE loss: [0.27244259719736874], TF loss: [0.21465915231965482] took 35.96262764930725\n",
      "Validation loss EPOCH: [294|1000], validation loss: [0.30562347639352083], AE loss: [0.14006991498172283], TF loss: [0.16555356234312057]\n",
      "Training loss EPOCH: [295|1000], training loss: [0.48767628241330385], AE loss: [0.27307263924740255], TF loss: [0.21460364339873195] took 38.14793586730957\n",
      "Validation loss EPOCH: [295|1000], validation loss: [0.30619605351239443], AE loss: [0.14008714584633708], TF loss: [0.16610890766605735]\n",
      "Training loss EPOCH: [296|1000], training loss: [0.4881775798276067], AE loss: [0.2735347826965153], TF loss: [0.21464279643259943] took 37.42875361442566\n",
      "Validation loss EPOCH: [296|1000], validation loss: [0.3061290429905057], AE loss: [0.14017707202583551], TF loss: [0.16595196910202503]\n",
      "Training loss EPOCH: [297|1000], training loss: [0.48722589667886496], AE loss: [0.27273840992711484], TF loss: [0.21448748698458076] took 39.43972563743591\n",
      "Validation loss EPOCH: [297|1000], validation loss: [0.3061237372457981], AE loss: [0.14015579712577164], TF loss: [0.16596793988719583]\n",
      "Training loss EPOCH: [298|1000], training loss: [0.49136789003387094], AE loss: [0.27695915568619967], TF loss: [0.21440873271785676] took 39.6950101852417\n",
      "Validation loss EPOCH: [298|1000], validation loss: [0.3056229781359434], AE loss: [0.13954682066105306], TF loss: [0.16607616003602743]\n",
      "Training loss EPOCH: [299|1000], training loss: [0.48726325668394566], AE loss: [0.27263339376077056], TF loss: [0.21462986269034445] took 41.379905462265015\n",
      "Validation loss EPOCH: [299|1000], validation loss: [0.3054132675752044], AE loss: [0.13982252916321158], TF loss: [0.1655907384119928]\n",
      "Training loss EPOCH: [300|1000], training loss: [0.4881244678981602], AE loss: [0.2737881843931973], TF loss: [0.21433628350496292] took 38.06550312042236\n",
      "Validation loss EPOCH: [300|1000], validation loss: [0.306324765086174], AE loss: [0.14035041979514062], TF loss: [0.1659743464551866]\n",
      "Training loss EPOCH: [301|1000], training loss: [0.48632627818733454], AE loss: [0.2721357170958072], TF loss: [0.21419055899605155] took 38.783019065856934\n",
      "Validation loss EPOCH: [301|1000], validation loss: [0.30627442337572575], AE loss: [0.14075317280367017], TF loss: [0.16552125103771687]\n",
      "Training loss EPOCH: [302|1000], training loss: [0.48738320311531425], AE loss: [0.27314509241841733], TF loss: [0.2142381106968969] took 36.6211998462677\n",
      "Validation loss EPOCH: [302|1000], validation loss: [0.30723990220576525], AE loss: [0.14035931858234107], TF loss: [0.16688058385625482]\n",
      "Training loss EPOCH: [303|1000], training loss: [0.4883167049847543], AE loss: [0.2740654784720391], TF loss: [0.21425122558139265] took 40.71169972419739\n",
      "Validation loss EPOCH: [303|1000], validation loss: [0.3060758332721889], AE loss: [0.14002145663835108], TF loss: [0.1660543759353459]\n",
      "Training loss EPOCH: [304|1000], training loss: [0.4873735117726028], AE loss: [0.27333943359553814], TF loss: [0.21403408097103238] took 40.688225746154785\n",
      "Validation loss EPOCH: [304|1000], validation loss: [0.30655320920050144], AE loss: [0.14038238232024014], TF loss: [0.16617082245647907]\n",
      "Training loss EPOCH: [305|1000], training loss: [0.4872605395503342], AE loss: [0.27314252546057105], TF loss: [0.21411801199428737] took 40.50229048728943\n",
      "Validation loss EPOCH: [305|1000], validation loss: [0.30782205518335104], AE loss: [0.14061864442192018], TF loss: [0.16720341006293893]\n",
      "Training loss EPOCH: [306|1000], training loss: [0.4871384804137051], AE loss: [0.27288183802738786], TF loss: [0.2142566421534866] took 41.20260214805603\n",
      "Validation loss EPOCH: [306|1000], validation loss: [0.30659655295312405], AE loss: [0.14033653191290796], TF loss: [0.1662600189447403]\n",
      "Training loss EPOCH: [307|1000], training loss: [0.48603692604228854], AE loss: [0.2718741428107023], TF loss: [0.21416278555989265] took 38.23153305053711\n",
      "Validation loss EPOCH: [307|1000], validation loss: [0.30645198095589876], AE loss: [0.14060339354909956], TF loss: [0.16584858670830727]\n",
      "Training loss EPOCH: [308|1000], training loss: [0.486952131614089], AE loss: [0.2727064089849591], TF loss: [0.21424572076648474] took 40.523699045181274\n",
      "Validation loss EPOCH: [308|1000], validation loss: [0.3071980532258749], AE loss: [0.14092510053887963], TF loss: [0.16627295361831784]\n",
      "Training loss EPOCH: [309|1000], training loss: [0.4869933482259512], AE loss: [0.2732336262706667], TF loss: [0.2137597231194377] took 38.667431592941284\n",
      "Validation loss EPOCH: [309|1000], validation loss: [0.30667818151414394], AE loss: [0.14071944286115468], TF loss: [0.16595873795449734]\n",
      "Training loss EPOCH: [310|1000], training loss: [0.4863617392256856], AE loss: [0.27246117731556296], TF loss: [0.21390056074596941] took 42.0827476978302\n",
      "Validation loss EPOCH: [310|1000], validation loss: [0.30642346758395433], AE loss: [0.14054516633041203], TF loss: [0.16587830008938909]\n",
      "Training loss EPOCH: [311|1000], training loss: [0.486768601462245], AE loss: [0.2728986737783998], TF loss: [0.21386992861516774] took 37.151522159576416\n",
      "Validation loss EPOCH: [311|1000], validation loss: [0.30716535449028015], AE loss: [0.1407339028082788], TF loss: [0.1664314535446465]\n",
      "Training loss EPOCH: [312|1000], training loss: [0.4845932270400226], AE loss: [0.27059460850432515], TF loss: [0.21399861853569746] took 38.01351189613342\n",
      "Validation loss EPOCH: [312|1000], validation loss: [0.30699344258755445], AE loss: [0.14084115298464894], TF loss: [0.1661522905342281]\n",
      "Training loss EPOCH: [313|1000], training loss: [0.4863958512432873], AE loss: [0.27260537003166974], TF loss: [0.21379048097878695] took 38.07714104652405\n",
      "Validation loss EPOCH: [313|1000], validation loss: [0.30777046643197536], AE loss: [0.14110591169446707], TF loss: [0.16666455613449216]\n",
      "Training loss EPOCH: [314|1000], training loss: [0.4882977493107319], AE loss: [0.2746006592642516], TF loss: [0.21369709144346416] took 38.249268531799316\n",
      "Validation loss EPOCH: [314|1000], validation loss: [0.30770891159772873], AE loss: [0.14091597218066454], TF loss: [0.16679294127970934]\n",
      "Training loss EPOCH: [315|1000], training loss: [0.48543466441333294], AE loss: [0.27175999456085265], TF loss: [0.21367466798983514] took 40.01094889640808\n",
      "Validation loss EPOCH: [315|1000], validation loss: [0.3072552802041173], AE loss: [0.14077582210302353], TF loss: [0.16647945949807763]\n",
      "Training loss EPOCH: [316|1000], training loss: [0.485944134183228], AE loss: [0.27224718779325485], TF loss: [0.21369694452732801] took 36.33464813232422\n",
      "Validation loss EPOCH: [316|1000], validation loss: [0.30776492692530155], AE loss: [0.14108867733739316], TF loss: [0.1666762507520616]\n",
      "Training loss EPOCH: [317|1000], training loss: [0.4837318742647767], AE loss: [0.2701442295219749], TF loss: [0.2135876442771405] took 39.07602286338806\n",
      "Validation loss EPOCH: [317|1000], validation loss: [0.3074968112632632], AE loss: [0.14079313771799207], TF loss: [0.1667036721482873]\n",
      "Training loss EPOCH: [318|1000], training loss: [0.4838571506552398], AE loss: [0.2703098598867655], TF loss: [0.21354729239828885] took 40.622278928756714\n",
      "Validation loss EPOCH: [318|1000], validation loss: [0.3071971479803324], AE loss: [0.1410665581934154], TF loss: [0.16613059071823955]\n",
      "Training loss EPOCH: [319|1000], training loss: [0.4859393653459847], AE loss: [0.27236411324702203], TF loss: [0.21357525046914816] took 40.08296298980713\n",
      "Validation loss EPOCH: [319|1000], validation loss: [0.3068814976140857], AE loss: [0.14066329854540527], TF loss: [0.1662181979045272]\n",
      "Training loss EPOCH: [320|1000], training loss: [0.48486908711493015], AE loss: [0.27139532822184265], TF loss: [0.21347376005724072] took 39.96033239364624\n",
      "Validation loss EPOCH: [320|1000], validation loss: [0.30666219536215067], AE loss: [0.14063929836265743], TF loss: [0.16602289956063032]\n",
      "Training loss EPOCH: [321|1000], training loss: [0.483754588291049], AE loss: [0.2704733482096344], TF loss: [0.21328124008141458] took 36.450684785842896\n",
      "Validation loss EPOCH: [321|1000], validation loss: [0.3079483639448881], AE loss: [0.14150936901569366], TF loss: [0.1664389967918396]\n",
      "Training loss EPOCH: [322|1000], training loss: [0.4854145282879472], AE loss: [0.27192385657690465], TF loss: [0.2134906689170748] took 40.89918661117554\n",
      "Validation loss EPOCH: [322|1000], validation loss: [0.30786264315247536], AE loss: [0.14072983828373253], TF loss: [0.16713280696421862]\n",
      "Training loss EPOCH: [323|1000], training loss: [0.48551507852971554], AE loss: [0.2720010669436306], TF loss: [0.2135140118189156] took 37.30652070045471\n",
      "Validation loss EPOCH: [323|1000], validation loss: [0.30796248000115156], AE loss: [0.1413109158165753], TF loss: [0.16665156418457627]\n",
      "Training loss EPOCH: [324|1000], training loss: [0.48684642324224114], AE loss: [0.2735493457876146], TF loss: [0.21329707582481205] took 36.40044093132019\n",
      "Validation loss EPOCH: [324|1000], validation loss: [0.30805739760398865], AE loss: [0.14105596183799207], TF loss: [0.16700143553316593]\n",
      "Training loss EPOCH: [325|1000], training loss: [0.4840199677273631], AE loss: [0.2705982553306967], TF loss: [0.21342171006835997] took 39.380450963974\n",
      "Validation loss EPOCH: [325|1000], validation loss: [0.30843230430036783], AE loss: [0.14134221198037267], TF loss: [0.16709008906036615]\n",
      "Training loss EPOCH: [326|1000], training loss: [0.4845289224758744], AE loss: [0.27107761334627867], TF loss: [0.21345130866393447] took 39.434863805770874\n",
      "Validation loss EPOCH: [326|1000], validation loss: [0.30777856800705194], AE loss: [0.14088870934210718], TF loss: [0.166889859829098]\n",
      "Training loss EPOCH: [327|1000], training loss: [0.48361522471532226], AE loss: [0.2702950621023774], TF loss: [0.21332016494125128] took 39.25849890708923\n",
      "Validation loss EPOCH: [327|1000], validation loss: [0.3082855436950922], AE loss: [0.1412463306915015], TF loss: [0.16703921416774392]\n",
      "Training loss EPOCH: [328|1000], training loss: [0.4848091332241893], AE loss: [0.2715648713055998], TF loss: [0.2132442609872669] took 39.82298183441162\n",
      "Validation loss EPOCH: [328|1000], validation loss: [0.3081193082034588], AE loss: [0.14097188669256866], TF loss: [0.1671474203467369]\n",
      "Training loss EPOCH: [329|1000], training loss: [0.48228699853643775], AE loss: [0.2692598083522171], TF loss: [0.21302719181403518] took 37.01709508895874\n",
      "Validation loss EPOCH: [329|1000], validation loss: [0.308474387973547], AE loss: [0.14134664623998106], TF loss: [0.16712774196639657]\n",
      "Training loss EPOCH: [330|1000], training loss: [0.48483048006892204], AE loss: [0.2716097997035831], TF loss: [0.21322067896835506] took 40.916162967681885\n",
      "Validation loss EPOCH: [330|1000], validation loss: [0.3091278877109289], AE loss: [0.14167580124922097], TF loss: [0.1674520862288773]\n",
      "Training loss EPOCH: [331|1000], training loss: [0.48586137732490897], AE loss: [0.272833930561319], TF loss: [0.21302744722925127] took 37.904133319854736\n",
      "Validation loss EPOCH: [331|1000], validation loss: [0.3079967349767685], AE loss: [0.14085898851044476], TF loss: [0.16713774530217052]\n",
      "Training loss EPOCH: [332|1000], training loss: [0.4816304421983659], AE loss: [0.26856955024413764], TF loss: [0.21306089218705893] took 38.58867383003235\n",
      "Validation loss EPOCH: [332|1000], validation loss: [0.30845327116549015], AE loss: [0.14176208013668656], TF loss: [0.16669119242578745]\n",
      "Training loss EPOCH: [333|1000], training loss: [0.4836511402390897], AE loss: [0.27076726290397346], TF loss: [0.21288388036191463] took 35.473026514053345\n",
      "Validation loss EPOCH: [333|1000], validation loss: [0.30793962348252535], AE loss: [0.14119825046509504], TF loss: [0.16674137488007545]\n",
      "Training loss EPOCH: [334|1000], training loss: [0.4839613069780171], AE loss: [0.2711427775211632], TF loss: [0.21281853038817644] took 39.9565532207489\n",
      "Validation loss EPOCH: [334|1000], validation loss: [0.30722904205322266], AE loss: [0.14140760153532028], TF loss: [0.16582144098356366]\n",
      "Training loss EPOCH: [335|1000], training loss: [0.48320769099518657], AE loss: [0.27027276321314275], TF loss: [0.21293492801487446] took 38.42022943496704\n",
      "Validation loss EPOCH: [335|1000], validation loss: [0.3086252175271511], AE loss: [0.14160724682733417], TF loss: [0.1670179720968008]\n",
      "Training loss EPOCH: [336|1000], training loss: [0.48322299076244235], AE loss: [0.27028148039244115], TF loss: [0.2129415103700012] took 42.88917398452759\n",
      "Validation loss EPOCH: [336|1000], validation loss: [0.30851549096405506], AE loss: [0.14148785057477653], TF loss: [0.16702764108777046]\n",
      "Training loss EPOCH: [337|1000], training loss: [0.4823872265405953], AE loss: [0.26937889168038964], TF loss: [0.2130083367228508] took 38.83112144470215\n",
      "Validation loss EPOCH: [337|1000], validation loss: [0.30823059286922216], AE loss: [0.14131570514291525], TF loss: [0.16691488958895206]\n",
      "Training loss EPOCH: [338|1000], training loss: [0.4836527146399021], AE loss: [0.27068182663060725], TF loss: [0.21297088847495615] took 39.97947812080383\n",
      "Validation loss EPOCH: [338|1000], validation loss: [0.3078763885423541], AE loss: [0.1410376988351345], TF loss: [0.1668386901728809]\n",
      "Training loss EPOCH: [339|1000], training loss: [0.48344752844423056], AE loss: [0.2707021611277014], TF loss: [0.2127453659195453] took 35.05047559738159\n",
      "Validation loss EPOCH: [339|1000], validation loss: [0.30925416946411133], AE loss: [0.141824095742777], TF loss: [0.1674300730228424]\n",
      "Training loss EPOCH: [340|1000], training loss: [0.4845618032850325], AE loss: [0.27181953145191073], TF loss: [0.21274227323010564] took 40.60464000701904\n",
      "Validation loss EPOCH: [340|1000], validation loss: [0.3076234720647335], AE loss: [0.1411261244211346], TF loss: [0.16649734787642956]\n",
      "Training loss EPOCH: [341|1000], training loss: [0.4849066222086549], AE loss: [0.2721323703881353], TF loss: [0.21277425298467278] took 38.534722328186035\n",
      "Validation loss EPOCH: [341|1000], validation loss: [0.3076792489737272], AE loss: [0.1408028374426067], TF loss: [0.16687641106545925]\n",
      "Training loss EPOCH: [342|1000], training loss: [0.48209158331155777], AE loss: [0.26924233487807214], TF loss: [0.21284924913197756] took 39.854244232177734\n",
      "Validation loss EPOCH: [342|1000], validation loss: [0.30827336199581623], AE loss: [0.14132223860360682], TF loss: [0.16695112502202392]\n",
      "Training loss EPOCH: [343|1000], training loss: [0.48154115257784724], AE loss: [0.26883079670369625], TF loss: [0.21271035308018327] took 36.00035333633423\n",
      "Validation loss EPOCH: [343|1000], validation loss: [0.3084018798545003], AE loss: [0.14154372178018093], TF loss: [0.16685815760865808]\n",
      "Training loss EPOCH: [344|1000], training loss: [0.4829093120060861], AE loss: [0.27044697431847453], TF loss: [0.21246233745478094] took 38.13380312919617\n",
      "Validation loss EPOCH: [344|1000], validation loss: [0.3091227523982525], AE loss: [0.14168647793121636], TF loss: [0.16743627237156034]\n",
      "Training loss EPOCH: [345|1000], training loss: [0.48036270355805755], AE loss: [0.2678930340334773], TF loss: [0.21246966952458024] took 37.35349416732788\n",
      "Validation loss EPOCH: [345|1000], validation loss: [0.30873847380280495], AE loss: [0.14177932031452656], TF loss: [0.16695915162563324]\n",
      "Training loss EPOCH: [346|1000], training loss: [0.48518338706344366], AE loss: [0.27265119832009077], TF loss: [0.21253218757919967] took 38.80453824996948\n",
      "Validation loss EPOCH: [346|1000], validation loss: [0.30823459941893816], AE loss: [0.14115088526159525], TF loss: [0.16708371322602034]\n",
      "Training loss EPOCH: [347|1000], training loss: [0.48029455449432135], AE loss: [0.2675892279949039], TF loss: [0.21270532626658678] took 40.717976331710815\n",
      "Validation loss EPOCH: [347|1000], validation loss: [0.30863208789378405], AE loss: [0.14144773385487497], TF loss: [0.16718435287475586]\n",
      "Training loss EPOCH: [348|1000], training loss: [0.4823986878618598], AE loss: [0.27005771454423666], TF loss: [0.21234097448177636] took 35.38526391983032\n",
      "Validation loss EPOCH: [348|1000], validation loss: [0.3086830582469702], AE loss: [0.14128849911503494], TF loss: [0.16739455983042717]\n",
      "Training loss EPOCH: [349|1000], training loss: [0.48217535531148314], AE loss: [0.2697874456644058], TF loss: [0.2123879089485854] took 37.503886461257935\n",
      "Validation loss EPOCH: [349|1000], validation loss: [0.30784277711063623], AE loss: [0.14075100142508745], TF loss: [0.16709177754819393]\n",
      "Training loss EPOCH: [350|1000], training loss: [0.48118456779047847], AE loss: [0.26865760586224496], TF loss: [0.21252696053124964] took 38.0810546875\n",
      "Validation loss EPOCH: [350|1000], validation loss: [0.30916763469576836], AE loss: [0.1420989939942956], TF loss: [0.16706864070147276]\n",
      "Training loss EPOCH: [351|1000], training loss: [0.4818386435508728], AE loss: [0.2694634373765439], TF loss: [0.21237520640715957] took 38.70682430267334\n",
      "Validation loss EPOCH: [351|1000], validation loss: [0.3094938164576888], AE loss: [0.14147401903755963], TF loss: [0.1680197981186211]\n",
      "Training loss EPOCH: [352|1000], training loss: [0.4833302483893931], AE loss: [0.2710360437631607], TF loss: [0.2122942057903856] took 39.6788432598114\n",
      "Validation loss EPOCH: [352|1000], validation loss: [0.3085596840828657], AE loss: [0.14104749890975654], TF loss: [0.16751218354329467]\n",
      "Training loss EPOCH: [353|1000], training loss: [0.480127468239516], AE loss: [0.2677815081551671], TF loss: [0.21234595961868763] took 39.922847032547\n",
      "Validation loss EPOCH: [353|1000], validation loss: [0.30869951844215393], AE loss: [0.14184900000691414], TF loss: [0.16685051890090108]\n",
      "Training loss EPOCH: [354|1000], training loss: [0.48293752456083894], AE loss: [0.2706892641726881], TF loss: [0.21224825992248952] took 41.23847222328186\n",
      "Validation loss EPOCH: [354|1000], validation loss: [0.30809623561799526], AE loss: [0.1410183438565582], TF loss: [0.167077892459929]\n",
      "Training loss EPOCH: [355|1000], training loss: [0.4822313180193305], AE loss: [0.2701389701105654], TF loss: [0.21209234884008765] took 38.21276044845581\n",
      "Validation loss EPOCH: [355|1000], validation loss: [0.3099743155762553], AE loss: [0.1417386019602418], TF loss: [0.1682357145473361]\n",
      "Training loss EPOCH: [356|1000], training loss: [0.48039041878655553], AE loss: [0.26818141737021506], TF loss: [0.21220900234766304] took 40.177122592926025\n",
      "Validation loss EPOCH: [356|1000], validation loss: [0.3096078308299184], AE loss: [0.14162306720390916], TF loss: [0.16798476362600923]\n",
      "Training loss EPOCH: [357|1000], training loss: [0.48012987431138754], AE loss: [0.2679623747244477], TF loss: [0.21216749865561724] took 38.26499605178833\n",
      "Validation loss EPOCH: [357|1000], validation loss: [0.308613745495677], AE loss: [0.14168663672171533], TF loss: [0.16692711040377617]\n",
      "Training loss EPOCH: [358|1000], training loss: [0.4801325863227248], AE loss: [0.26798246847465634], TF loss: [0.21215011831372976] took 38.2030770778656\n",
      "Validation loss EPOCH: [358|1000], validation loss: [0.30864529870450497], AE loss: [0.1414055300410837], TF loss: [0.16723976656794548]\n",
      "Training loss EPOCH: [359|1000], training loss: [0.48034235555678606], AE loss: [0.2682846176903695], TF loss: [0.2120577374007553] took 39.268012046813965\n",
      "Validation loss EPOCH: [359|1000], validation loss: [0.308276679366827], AE loss: [0.14153114426881075], TF loss: [0.16674553509801626]\n",
      "Training loss EPOCH: [360|1000], training loss: [0.4803146137855947], AE loss: [0.26828683260828257], TF loss: [0.21202778373844922] took 39.76869344711304\n",
      "Validation loss EPOCH: [360|1000], validation loss: [0.3100551590323448], AE loss: [0.14179517305456102], TF loss: [0.16825999086722732]\n",
      "Training loss EPOCH: [361|1000], training loss: [0.4849491151981056], AE loss: [0.2729647122323513], TF loss: [0.2119844036642462] took 40.67784833908081\n",
      "Validation loss EPOCH: [361|1000], validation loss: [0.30880087334662676], AE loss: [0.14167751790955663], TF loss: [0.167123356834054]\n",
      "Training loss EPOCH: [362|1000], training loss: [0.48007327411323786], AE loss: [0.26800244324840605], TF loss: [0.21207083202898502] took 38.92265224456787\n",
      "Validation loss EPOCH: [362|1000], validation loss: [0.30909791123121977], AE loss: [0.14140477497130632], TF loss: [0.16769313253462315]\n",
      "Training loss EPOCH: [363|1000], training loss: [0.4834014596417546], AE loss: [0.27136871591210365], TF loss: [0.21203274372965097] took 40.79503512382507\n",
      "Validation loss EPOCH: [363|1000], validation loss: [0.3075364585965872], AE loss: [0.14088455261662602], TF loss: [0.1666519083082676]\n",
      "Training loss EPOCH: [364|1000], training loss: [0.48127418104559183], AE loss: [0.26929064258001745], TF loss: [0.21198354032821953] took 37.38962006568909\n",
      "Validation loss EPOCH: [364|1000], validation loss: [0.30894249957054853], AE loss: [0.14135429519228637], TF loss: [0.16758820693939924]\n",
      "Training loss EPOCH: [365|1000], training loss: [0.47831424651667476], AE loss: [0.266515658935532], TF loss: [0.211798585485667] took 39.5314884185791\n",
      "Validation loss EPOCH: [365|1000], validation loss: [0.3082548761740327], AE loss: [0.14152711862698197], TF loss: [0.16672775568440557]\n",
      "Training loss EPOCH: [366|1000], training loss: [0.47918280214071274], AE loss: [0.26737267803400755], TF loss: [0.21181012457236648] took 36.17398238182068\n",
      "Validation loss EPOCH: [366|1000], validation loss: [0.309639492072165], AE loss: [0.14148213574662805], TF loss: [0.16815735725685954]\n",
      "Training loss EPOCH: [367|1000], training loss: [0.48045374592766166], AE loss: [0.2686141631565988], TF loss: [0.21183958183974028] took 38.26529812812805\n",
      "Validation loss EPOCH: [367|1000], validation loss: [0.3102592034265399], AE loss: [0.14156896295025945], TF loss: [0.1686902428045869]\n",
      "Training loss EPOCH: [368|1000], training loss: [0.48132872488349676], AE loss: [0.26948228967376053], TF loss: [0.21184643520973623] took 38.33336019515991\n",
      "Validation loss EPOCH: [368|1000], validation loss: [0.30932359863072634], AE loss: [0.14131998363882303], TF loss: [0.1680036117322743]\n",
      "Training loss EPOCH: [369|1000], training loss: [0.48146467842161655], AE loss: [0.2693764134310186], TF loss: [0.2120882635936141] took 37.68289232254028\n",
      "Validation loss EPOCH: [369|1000], validation loss: [0.30963812209665775], AE loss: [0.14177076634950936], TF loss: [0.16786735272035003]\n",
      "Training loss EPOCH: [370|1000], training loss: [0.4782128296792507], AE loss: [0.2665084407199174], TF loss: [0.2117043868638575] took 40.898279666900635\n",
      "Validation loss EPOCH: [370|1000], validation loss: [0.3091181516647339], AE loss: [0.141569311497733], TF loss: [0.1675488380715251]\n",
      "Training loss EPOCH: [371|1000], training loss: [0.4844148741103709], AE loss: [0.272666007746011], TF loss: [0.21174886566586792] took 35.90199875831604\n",
      "Validation loss EPOCH: [371|1000], validation loss: [0.3080090507864952], AE loss: [0.14108269638381898], TF loss: [0.16692635277286172]\n",
      "Training loss EPOCH: [372|1000], training loss: [0.4790841634385288], AE loss: [0.26719367876648903], TF loss: [0.21189048700034618] took 38.95791935920715\n",
      "Validation loss EPOCH: [372|1000], validation loss: [0.3091116603463888], AE loss: [0.14152679173275828], TF loss: [0.16758486907929182]\n",
      "Training loss EPOCH: [373|1000], training loss: [0.4815351441502571], AE loss: [0.26986168744042516], TF loss: [0.2116734564770013] took 39.140899658203125\n",
      "Validation loss EPOCH: [373|1000], validation loss: [0.3087254362180829], AE loss: [0.14133701915852726], TF loss: [0.16738841822370887]\n",
      "Training loss EPOCH: [374|1000], training loss: [0.4782676286995411], AE loss: [0.2664304869249463], TF loss: [0.2118371392134577] took 40.601621866226196\n",
      "Validation loss EPOCH: [374|1000], validation loss: [0.30918974801898], AE loss: [0.1416280586272478], TF loss: [0.16756169218569994]\n",
      "Training loss EPOCH: [375|1000], training loss: [0.4838028778322041], AE loss: [0.2722855331376195], TF loss: [0.2115173451602459] took 37.52459144592285\n",
      "Validation loss EPOCH: [375|1000], validation loss: [0.30795386899262667], AE loss: [0.1399779631756246], TF loss: [0.16797590721398592]\n",
      "Training loss EPOCH: [376|1000], training loss: [0.4818278905004263], AE loss: [0.2701245970092714], TF loss: [0.21170329325832427] took 37.42947435379028\n",
      "Validation loss EPOCH: [376|1000], validation loss: [0.30955936945974827], AE loss: [0.1423728142399341], TF loss: [0.16718655405566096]\n",
      "Training loss EPOCH: [377|1000], training loss: [0.4805511492304504], AE loss: [0.2689686845988035], TF loss: [0.2115824637003243] took 39.34362602233887\n",
      "Validation loss EPOCH: [377|1000], validation loss: [0.308784450404346], AE loss: [0.14155642967671156], TF loss: [0.1672280253842473]\n",
      "Training loss EPOCH: [378|1000], training loss: [0.48039790987968445], AE loss: [0.2687756458763033], TF loss: [0.2116222649347037] took 40.30616807937622\n",
      "Validation loss EPOCH: [378|1000], validation loss: [0.3100057886913419], AE loss: [0.14180328347720206], TF loss: [0.1682025045156479]\n",
      "Training loss EPOCH: [379|1000], training loss: [0.4797744480893016], AE loss: [0.2684455330017954], TF loss: [0.21132891648449004] took 41.20003390312195\n",
      "Validation loss EPOCH: [379|1000], validation loss: [0.30905764177441597], AE loss: [0.14145291363820434], TF loss: [0.16760472813621163]\n",
      "Training loss EPOCH: [380|1000], training loss: [0.4792636036872864], AE loss: [0.2678777636028826], TF loss: [0.21138584217987955] took 40.98192000389099\n",
      "Validation loss EPOCH: [380|1000], validation loss: [0.30921545438468456], AE loss: [0.1412920888978988], TF loss: [0.16792336525395513]\n",
      "Training loss EPOCH: [381|1000], training loss: [0.482416442129761], AE loss: [0.2709672295022756], TF loss: [0.2114492121618241] took 36.809059858322144\n",
      "Validation loss EPOCH: [381|1000], validation loss: [0.3095984710380435], AE loss: [0.14143254538066685], TF loss: [0.16816592402756214]\n",
      "Training loss EPOCH: [382|1000], training loss: [0.47664208244532347], AE loss: [0.2652919215615839], TF loss: [0.2113501608837396] took 37.81741166114807\n",
      "Validation loss EPOCH: [382|1000], validation loss: [0.30964855290949345], AE loss: [0.14168964000418782], TF loss: [0.16795891476795077]\n",
      "Training loss EPOCH: [383|1000], training loss: [0.48298892797902226], AE loss: [0.27167016454041004], TF loss: [0.21131876367144287] took 39.26853823661804\n",
      "Validation loss EPOCH: [383|1000], validation loss: [0.3094967035576701], AE loss: [0.14145845687016845], TF loss: [0.16803824668750167]\n",
      "Training loss EPOCH: [384|1000], training loss: [0.4783203029073775], AE loss: [0.2670706065837294], TF loss: [0.21124969515949488] took 42.47727298736572\n",
      "Validation loss EPOCH: [384|1000], validation loss: [0.30849224235862494], AE loss: [0.14108265773393214], TF loss: [0.16740958439186215]\n",
      "Training loss EPOCH: [385|1000], training loss: [0.4779875944368541], AE loss: [0.26662944932468235], TF loss: [0.21135814697481692] took 38.45928192138672\n",
      "Validation loss EPOCH: [385|1000], validation loss: [0.30937939789146185], AE loss: [0.14161877217702568], TF loss: [0.1677606268785894]\n",
      "Training loss EPOCH: [386|1000], training loss: [0.4814463723450899], AE loss: [0.27019359404221177], TF loss: [0.21125277853570879] took 40.325591802597046\n",
      "Validation loss EPOCH: [386|1000], validation loss: [0.3095811204984784], AE loss: [0.1411136630922556], TF loss: [0.16846746113151312]\n",
      "Training loss EPOCH: [387|1000], training loss: [0.47723352862522006], AE loss: [0.2658173772506416], TF loss: [0.2114161504432559] took 38.316861391067505\n",
      "Validation loss EPOCH: [387|1000], validation loss: [0.30998295824974775], AE loss: [0.14161138073541224], TF loss: [0.16837157681584358]\n",
      "Training loss EPOCH: [388|1000], training loss: [0.4790298263542354], AE loss: [0.2676319743040949], TF loss: [0.21139785228297114] took 38.54612588882446\n",
      "Validation loss EPOCH: [388|1000], validation loss: [0.30882534198462963], AE loss: [0.14108444028533995], TF loss: [0.16774090006947517]\n",
      "Training loss EPOCH: [389|1000], training loss: [0.4771521957591176], AE loss: [0.2658920323010534], TF loss: [0.21126016392372549] took 36.43886089324951\n",
      "Validation loss EPOCH: [389|1000], validation loss: [0.3090920252725482], AE loss: [0.14128083200193942], TF loss: [0.16781119536608458]\n",
      "Training loss EPOCH: [390|1000], training loss: [0.47897934168577194], AE loss: [0.26763674174435437], TF loss: [0.21134260017424822] took 39.918907165527344\n",
      "Validation loss EPOCH: [390|1000], validation loss: [0.30927759036421776], AE loss: [0.14147642208263278], TF loss: [0.16780117014423013]\n",
      "Training loss EPOCH: [391|1000], training loss: [0.4758291966281831], AE loss: [0.26463361782953143], TF loss: [0.21119557647034526] took 38.86457848548889\n",
      "Validation loss EPOCH: [391|1000], validation loss: [0.309300921857357], AE loss: [0.1416519950143993], TF loss: [0.16764892265200615]\n",
      "Training loss EPOCH: [392|1000], training loss: [0.47966795368120074], AE loss: [0.26854289625771344], TF loss: [0.21112505812197924] took 40.066678285598755\n",
      "Validation loss EPOCH: [392|1000], validation loss: [0.30955815501511097], AE loss: [0.14112244127318263], TF loss: [0.16843571374192834]\n",
      "Training loss EPOCH: [393|1000], training loss: [0.47660251520574093], AE loss: [0.2653567334637046], TF loss: [0.21124578570015728] took 36.802327156066895\n",
      "Validation loss EPOCH: [393|1000], validation loss: [0.30976533982902765], AE loss: [0.14211583975702524], TF loss: [0.16764949867501855]\n",
      "Training loss EPOCH: [394|1000], training loss: [0.4818112784996629], AE loss: [0.27078811917454004], TF loss: [0.2110231607221067] took 36.76130962371826\n",
      "Validation loss EPOCH: [394|1000], validation loss: [0.30925265699625015], AE loss: [0.14112667925655842], TF loss: [0.16812597587704659]\n",
      "Training loss EPOCH: [395|1000], training loss: [0.4750227960757911], AE loss: [0.2641081146430224], TF loss: [0.2109146814327687] took 37.37227392196655\n",
      "Validation loss EPOCH: [395|1000], validation loss: [0.30960765294730663], AE loss: [0.14132152334786952], TF loss: [0.1682861316949129]\n",
      "Training loss EPOCH: [396|1000], training loss: [0.4776617707684636], AE loss: [0.26660294411703944], TF loss: [0.21105882665142417] took 37.817813873291016\n",
      "Validation loss EPOCH: [396|1000], validation loss: [0.30975038278847933], AE loss: [0.14115746272727847], TF loss: [0.16859292145818472]\n",
      "Training loss EPOCH: [397|1000], training loss: [0.4786373060196638], AE loss: [0.2677941906731576], TF loss: [0.21084311604499817] took 41.2070426940918\n",
      "Validation loss EPOCH: [397|1000], validation loss: [0.3094638679176569], AE loss: [0.1414323658682406], TF loss: [0.16803149925544858]\n",
      "Training loss EPOCH: [398|1000], training loss: [0.4793837023898959], AE loss: [0.2683997922576964], TF loss: [0.21098390966653824] took 39.77846169471741\n",
      "Validation loss EPOCH: [398|1000], validation loss: [0.31000260822474957], AE loss: [0.14089646167121828], TF loss: [0.16910614678636193]\n",
      "Training loss EPOCH: [399|1000], training loss: [0.47605182277038693], AE loss: [0.26504031382501125], TF loss: [0.21101151127368212] took 39.480849742889404\n",
      "Validation loss EPOCH: [399|1000], validation loss: [0.3087681299075484], AE loss: [0.14153881347738206], TF loss: [0.16722931386902928]\n",
      "Training loss EPOCH: [400|1000], training loss: [0.4778450676240027], AE loss: [0.2668575425632298], TF loss: [0.21098752412945032] took 37.73799395561218\n",
      "Validation loss EPOCH: [400|1000], validation loss: [0.31031749304383993], AE loss: [0.1417799035552889], TF loss: [0.1685375883243978]\n",
      "Training loss EPOCH: [401|1000], training loss: [0.4791320860385895], AE loss: [0.26834975299425423], TF loss: [0.21078233234584332] took 37.44285869598389\n",
      "Validation loss EPOCH: [401|1000], validation loss: [0.30917050410062075], AE loss: [0.1407422919292003], TF loss: [0.16842821147292852]\n",
      "Training loss EPOCH: [402|1000], training loss: [0.4770856979303062], AE loss: [0.26630128594115376], TF loss: [0.21078441245481372] took 41.179192304611206\n",
      "Validation loss EPOCH: [402|1000], validation loss: [0.30942019261419773], AE loss: [0.14151136833243072], TF loss: [0.16790882451459765]\n",
      "Training loss EPOCH: [403|1000], training loss: [0.4753497336059809], AE loss: [0.26464915089309216], TF loss: [0.21070058248005807] took 40.46331167221069\n",
      "Validation loss EPOCH: [403|1000], validation loss: [0.30924660153687], AE loss: [0.14141132892109454], TF loss: [0.16783527471125126]\n",
      "Training loss EPOCH: [404|1000], training loss: [0.47593669407069683], AE loss: [0.26512295519933105], TF loss: [0.21081373910419643] took 40.24495220184326\n",
      "Validation loss EPOCH: [404|1000], validation loss: [0.3087047589942813], AE loss: [0.14153382321819663], TF loss: [0.1671709376387298]\n",
      "Training loss EPOCH: [405|1000], training loss: [0.47721009608358145], AE loss: [0.26656116638332605], TF loss: [0.21064892993308604] took 39.96541619300842\n",
      "Validation loss EPOCH: [405|1000], validation loss: [0.30983870569616556], AE loss: [0.14118118840269744], TF loss: [0.1686575165949762]\n",
      "Training loss EPOCH: [406|1000], training loss: [0.478883134201169], AE loss: [0.2680992102250457], TF loss: [0.21078392351046205] took 38.99526906013489\n",
      "Validation loss EPOCH: [406|1000], validation loss: [0.3086378341540694], AE loss: [0.1411921475082636], TF loss: [0.16744568524882197]\n",
      "Training loss EPOCH: [407|1000], training loss: [0.47591688157990575], AE loss: [0.26518789445981383], TF loss: [0.21072898618876934] took 36.95521783828735\n",
      "Validation loss EPOCH: [407|1000], validation loss: [0.3101534200832248], AE loss: [0.14100695494562387], TF loss: [0.16914646560326219]\n",
      "Training loss EPOCH: [408|1000], training loss: [0.47687840834259987], AE loss: [0.26601203181780875], TF loss: [0.21086637768894434] took 40.94336009025574\n",
      "Validation loss EPOCH: [408|1000], validation loss: [0.31025801599025726], AE loss: [0.14115428575314581], TF loss: [0.1691037300042808]\n",
      "Training loss EPOCH: [409|1000], training loss: [0.4778489824384451], AE loss: [0.2671663227956742], TF loss: [0.21068266336806118] took 36.53672790527344\n",
      "Validation loss EPOCH: [409|1000], validation loss: [0.30915454775094986], AE loss: [0.14113566046580672], TF loss: [0.1680188849568367]\n",
      "Training loss EPOCH: [410|1000], training loss: [0.47457578172907233], AE loss: [0.26381484931334853], TF loss: [0.21076093218289316] took 39.67251133918762\n",
      "Validation loss EPOCH: [410|1000], validation loss: [0.3099060030654073], AE loss: [0.14124895120039582], TF loss: [0.16865705326199532]\n",
      "Training loss EPOCH: [411|1000], training loss: [0.47634250530973077], AE loss: [0.26596296834759414], TF loss: [0.21037953719496727] took 36.57118248939514\n",
      "Validation loss EPOCH: [411|1000], validation loss: [0.30877749994397163], AE loss: [0.14114662841893733], TF loss: [0.16763087315484881]\n",
      "Training loss EPOCH: [412|1000], training loss: [0.48081691563129425], AE loss: [0.2702262925449759], TF loss: [0.21059062331914902] took 37.44644260406494\n",
      "Validation loss EPOCH: [412|1000], validation loss: [0.30927613750100136], AE loss: [0.1413538611959666], TF loss: [0.1679222760722041]\n",
      "Training loss EPOCH: [413|1000], training loss: [0.47507739486172795], AE loss: [0.26436360739171505], TF loss: [0.21071378630585968] took 37.46025514602661\n",
      "Validation loss EPOCH: [413|1000], validation loss: [0.3087359694764018], AE loss: [0.1409892961382866], TF loss: [0.16774667287245393]\n",
      "Training loss EPOCH: [414|1000], training loss: [0.4782253820449114], AE loss: [0.2677803705446422], TF loss: [0.2104450101032853] took 39.46101260185242\n",
      "Validation loss EPOCH: [414|1000], validation loss: [0.3094464037567377], AE loss: [0.1407312627416104], TF loss: [0.16871514404192567]\n",
      "Training loss EPOCH: [415|1000], training loss: [0.4769103773869574], AE loss: [0.2662056421395391], TF loss: [0.21070473361760378] took 36.147905588150024\n",
      "Validation loss EPOCH: [415|1000], validation loss: [0.30834734346717596], AE loss: [0.14078636467456818], TF loss: [0.16756097925826907]\n",
      "Training loss EPOCH: [416|1000], training loss: [0.4768574773333967], AE loss: [0.26614164165221155], TF loss: [0.21071583754383028] took 36.53390836715698\n",
      "Validation loss EPOCH: [416|1000], validation loss: [0.30981795210391283], AE loss: [0.14096685172989964], TF loss: [0.16885110270231962]\n",
      "Training loss EPOCH: [417|1000], training loss: [0.47743776720017195], AE loss: [0.2670124836731702], TF loss: [0.21042528026737273] took 36.20427227020264\n",
      "Validation loss EPOCH: [417|1000], validation loss: [0.30871263053268194], AE loss: [0.14016722654923797], TF loss: [0.16854540491476655]\n",
      "Training loss EPOCH: [418|1000], training loss: [0.4762030905112624], AE loss: [0.26578023307956755], TF loss: [0.2104228565003723] took 40.93478775024414\n",
      "Validation loss EPOCH: [418|1000], validation loss: [0.3095904756337404], AE loss: [0.14109237911179662], TF loss: [0.16849810117855668]\n",
      "Training loss EPOCH: [419|1000], training loss: [0.4759823954664171], AE loss: [0.2656121291220188], TF loss: [0.21037026634439826] took 36.0632529258728\n",
      "Validation loss EPOCH: [419|1000], validation loss: [0.30855380091816187], AE loss: [0.1403289723675698], TF loss: [0.16822482971474528]\n",
      "Training loss EPOCH: [420|1000], training loss: [0.47735532419756055], AE loss: [0.26682486082427204], TF loss: [0.2105304638389498] took 37.34726405143738\n",
      "Validation loss EPOCH: [420|1000], validation loss: [0.30918287578970194], AE loss: [0.14069262240082026], TF loss: [0.1684902529232204]\n",
      "Training loss EPOCH: [421|1000], training loss: [0.4751508133485913], AE loss: [0.2646571951918304], TF loss: [0.21049361932091415] took 42.42334342002869\n",
      "Validation loss EPOCH: [421|1000], validation loss: [0.30971853621304035], AE loss: [0.14106821455061436], TF loss: [0.16865032445639372]\n",
      "Training loss EPOCH: [422|1000], training loss: [0.4761788663454354], AE loss: [0.26579053536988795], TF loss: [0.21038833144120872] took 38.073710203170776\n",
      "Validation loss EPOCH: [422|1000], validation loss: [0.30997826997190714], AE loss: [0.14084400283172727], TF loss: [0.16913426481187344]\n",
      "Training loss EPOCH: [423|1000], training loss: [0.4733320912346244], AE loss: [0.2629916381556541], TF loss: [0.21034045424312353] took 40.5356388092041\n",
      "Validation loss EPOCH: [423|1000], validation loss: [0.3098998162895441], AE loss: [0.14140953170135617], TF loss: [0.16849028738215566]\n",
      "Training loss EPOCH: [424|1000], training loss: [0.4788279286585748], AE loss: [0.26851882855407894], TF loss: [0.21030910243280232] took 39.22542929649353\n",
      "Validation loss EPOCH: [424|1000], validation loss: [0.30954325851053], AE loss: [0.14067803020589054], TF loss: [0.16886523040011525]\n",
      "Training loss EPOCH: [425|1000], training loss: [0.4732376551255584], AE loss: [0.263009448768571], TF loss: [0.21022820775397122] took 38.568687200546265\n",
      "Validation loss EPOCH: [425|1000], validation loss: [0.3090684888884425], AE loss: [0.14128994313068688], TF loss: [0.16777854692190886]\n",
      "Training loss EPOCH: [426|1000], training loss: [0.4819091819226742], AE loss: [0.2715681220870465], TF loss: [0.2103410589043051] took 39.36043334007263\n",
      "Validation loss EPOCH: [426|1000], validation loss: [0.3095061667263508], AE loss: [0.14003320853225887], TF loss: [0.16947296122089028]\n",
      "Training loss EPOCH: [427|1000], training loss: [0.4785843095742166], AE loss: [0.2682908228598535], TF loss: [0.2102934867143631] took 38.07345390319824\n",
      "Validation loss EPOCH: [427|1000], validation loss: [0.3087855977937579], AE loss: [0.1401288916822523], TF loss: [0.16865670448169112]\n",
      "Training loss EPOCH: [428|1000], training loss: [0.47620899556204677], AE loss: [0.2660635760985315], TF loss: [0.21014541829936206] took 38.057255029678345\n",
      "Validation loss EPOCH: [428|1000], validation loss: [0.3098978800699115], AE loss: [0.14123741700313985], TF loss: [0.16866046423092484]\n",
      "Training loss EPOCH: [429|1000], training loss: [0.47419898863881826], AE loss: [0.26399881509132683], TF loss: [0.21020017401315272] took 39.791048765182495\n",
      "Validation loss EPOCH: [429|1000], validation loss: [0.31003695726394653], AE loss: [0.14127378235571086], TF loss: [0.1687631760723889]\n",
      "Training loss EPOCH: [430|1000], training loss: [0.4773281626403332], AE loss: [0.26709276204928756], TF loss: [0.21023539965972304] took 38.48424959182739\n",
      "Validation loss EPOCH: [430|1000], validation loss: [0.309032385237515], AE loss: [0.14042510325089097], TF loss: [0.16860728152096272]\n",
      "Training loss EPOCH: [431|1000], training loss: [0.47222632821649313], AE loss: [0.2621007796842605], TF loss: [0.21012554806657135] took 40.85389828681946\n",
      "Validation loss EPOCH: [431|1000], validation loss: [0.30959329660981894], AE loss: [0.14108893042430282], TF loss: [0.1685043666511774]\n",
      "Training loss EPOCH: [432|1000], training loss: [0.4728463557548821], AE loss: [0.26261181896552444], TF loss: [0.2102345337625593] took 40.66670513153076\n",
      "Validation loss EPOCH: [432|1000], validation loss: [0.3094724966213107], AE loss: [0.14071932598017156], TF loss: [0.16875317227095366]\n",
      "Training loss EPOCH: [433|1000], training loss: [0.47346500027924776], AE loss: [0.2634304752573371], TF loss: [0.21003452385775745] took 40.90959024429321\n",
      "Validation loss EPOCH: [433|1000], validation loss: [0.3097296031191945], AE loss: [0.14075967227108777], TF loss: [0.1689699301496148]\n",
      "Training loss EPOCH: [434|1000], training loss: [0.47304128808900714], AE loss: [0.2628646765369922], TF loss: [0.21017660992220044] took 37.658170223236084\n",
      "Validation loss EPOCH: [434|1000], validation loss: [0.30982552375644445], AE loss: [0.1408131478819996], TF loss: [0.1690123793669045]\n",
      "Training loss EPOCH: [435|1000], training loss: [0.4767806506715715], AE loss: [0.2665736919734627], TF loss: [0.21020695939660072] took 39.33454942703247\n",
      "Validation loss EPOCH: [435|1000], validation loss: [0.3098348071798682], AE loss: [0.14072593743912876], TF loss: [0.16910886857658625]\n",
      "Training loss EPOCH: [436|1000], training loss: [0.4713097922503948], AE loss: [0.2611893794964999], TF loss: [0.2101204099599272] took 39.331305265426636\n",
      "Validation loss EPOCH: [436|1000], validation loss: [0.308940633200109], AE loss: [0.14100259100086987], TF loss: [0.16793803730979562]\n",
      "Training loss EPOCH: [437|1000], training loss: [0.4785433844663203], AE loss: [0.2683621912728995], TF loss: [0.21018119575455785] took 37.593098640441895\n",
      "Validation loss EPOCH: [437|1000], validation loss: [0.3096787529066205], AE loss: [0.14089396293275058], TF loss: [0.16878479020670056]\n",
      "Training loss EPOCH: [438|1000], training loss: [0.47578229382634163], AE loss: [0.2657023244537413], TF loss: [0.2100799698382616] took 36.405153036117554\n",
      "Validation loss EPOCH: [438|1000], validation loss: [0.31060687731951475], AE loss: [0.14071987965144217], TF loss: [0.1698869983665645]\n",
      "Training loss EPOCH: [439|1000], training loss: [0.4752389513887465], AE loss: [0.26525080390274525], TF loss: [0.2099881456233561] took 41.49985122680664\n",
      "Validation loss EPOCH: [439|1000], validation loss: [0.3085000542923808], AE loss: [0.14054573304019868], TF loss: [0.16795432101935148]\n",
      "Training loss EPOCH: [440|1000], training loss: [0.4733662656508386], AE loss: [0.26317104301415384], TF loss: [0.2101952221710235] took 39.31955933570862\n",
      "Validation loss EPOCH: [440|1000], validation loss: [0.3094639703631401], AE loss: [0.1412016914691776], TF loss: [0.16826227819547057]\n",
      "Training loss EPOCH: [441|1000], training loss: [0.4722826858051121], AE loss: [0.2622046696487814], TF loss: [0.21007801382802427] took 39.34364557266235\n",
      "Validation loss EPOCH: [441|1000], validation loss: [0.31019266601651907], AE loss: [0.14099017204716802], TF loss: [0.16920248977839947]\n",
      "Training loss EPOCH: [442|1000], training loss: [0.47312195412814617], AE loss: [0.26309369783848524], TF loss: [0.2100282572209835] took 39.61294174194336\n",
      "Validation loss EPOCH: [442|1000], validation loss: [0.3098989212885499], AE loss: [0.14110761159099638], TF loss: [0.16879130993038416]\n",
      "Training loss EPOCH: [443|1000], training loss: [0.47461183462291956], AE loss: [0.2646315065212548], TF loss: [0.2099803308956325] took 37.77254366874695\n",
      "Validation loss EPOCH: [443|1000], validation loss: [0.3098079627379775], AE loss: [0.140912767034024], TF loss: [0.16889519523829222]\n",
      "Training loss EPOCH: [444|1000], training loss: [0.47480549616739154], AE loss: [0.2649693409912288], TF loss: [0.20983615284785628] took 36.84077739715576\n",
      "Validation loss EPOCH: [444|1000], validation loss: [0.30891393311321735], AE loss: [0.14038450340740383], TF loss: [0.1685294327326119]\n",
      "Training loss EPOCH: [445|1000], training loss: [0.47494875406846404], AE loss: [0.26503289793618023], TF loss: [0.20991585403680801] took 39.74710488319397\n",
      "Validation loss EPOCH: [445|1000], validation loss: [0.3087047915905714], AE loss: [0.14000773918814957], TF loss: [0.1686970521695912]\n",
      "Training loss EPOCH: [446|1000], training loss: [0.47268119966611266], AE loss: [0.2628113008104265], TF loss: [0.20986989908851683] took 38.92302131652832\n",
      "Validation loss EPOCH: [446|1000], validation loss: [0.3088750457391143], AE loss: [0.1408632250968367], TF loss: [0.16801181947812438]\n",
      "Training loss EPOCH: [447|1000], training loss: [0.4716506418772042], AE loss: [0.2618817393667996], TF loss: [0.2097689020447433] took 40.4788978099823\n",
      "Validation loss EPOCH: [447|1000], validation loss: [0.3092000335454941], AE loss: [0.1407551693264395], TF loss: [0.16844486398622394]\n",
      "Training loss EPOCH: [448|1000], training loss: [0.4750337926670909], AE loss: [0.265280953142792], TF loss: [0.20975284138694406] took 39.469905853271484\n",
      "Validation loss EPOCH: [448|1000], validation loss: [0.3101256974041462], AE loss: [0.141123304143548], TF loss: [0.16900239046663046]\n",
      "Training loss EPOCH: [449|1000], training loss: [0.4771213592030108], AE loss: [0.2671889553312212], TF loss: [0.20993240317329764] took 38.57186698913574\n",
      "Validation loss EPOCH: [449|1000], validation loss: [0.3083869833499193], AE loss: [0.14015216543339193], TF loss: [0.16823481675237417]\n",
      "Training loss EPOCH: [450|1000], training loss: [0.47094160318374634], AE loss: [0.261121756862849], TF loss: [0.20981984538957477] took 39.81644034385681\n",
      "Validation loss EPOCH: [450|1000], validation loss: [0.3102278131991625], AE loss: [0.14104641415178776], TF loss: [0.16918140277266502]\n",
      "Training loss EPOCH: [451|1000], training loss: [0.47163592698052526], AE loss: [0.26182534894905984], TF loss: [0.20981057896278799] took 40.63001108169556\n",
      "Validation loss EPOCH: [451|1000], validation loss: [0.3098807418718934], AE loss: [0.14071267400868237], TF loss: [0.16916806483641267]\n",
      "Training loss EPOCH: [452|1000], training loss: [0.4722802662290633], AE loss: [0.26274212286807597], TF loss: [0.2095381438266486] took 37.13577842712402\n",
      "Validation loss EPOCH: [452|1000], validation loss: [0.30988447461277246], AE loss: [0.1412030872888863], TF loss: [0.16868138778954744]\n",
      "Training loss EPOCH: [453|1000], training loss: [0.47478277841582894], AE loss: [0.2650730402674526], TF loss: [0.20970973721705377] took 41.57397961616516\n",
      "Validation loss EPOCH: [453|1000], validation loss: [0.30975430365651846], AE loss: [0.14082618057727814], TF loss: [0.16892812307924032]\n",
      "Training loss EPOCH: [454|1000], training loss: [0.47259578853845596], AE loss: [0.2627541469410062], TF loss: [0.20984164136461914] took 37.71083188056946\n",
      "Validation loss EPOCH: [454|1000], validation loss: [0.30979691632092], AE loss: [0.14070308045484126], TF loss: [0.16909383703023195]\n",
      "Training loss EPOCH: [455|1000], training loss: [0.4770737662911415], AE loss: [0.2672488787211478], TF loss: [0.2098248852416873] took 36.038461685180664\n",
      "Validation loss EPOCH: [455|1000], validation loss: [0.30918858759105206], AE loss: [0.14072341355495155], TF loss: [0.16846517473459244]\n",
      "Training loss EPOCH: [456|1000], training loss: [0.47003540955483913], AE loss: [0.26033821306191385], TF loss: [0.20969719742424786] took 39.11914396286011\n",
      "Validation loss EPOCH: [456|1000], validation loss: [0.30925220251083374], AE loss: [0.14076331839896739], TF loss: [0.1684888838790357]\n",
      "Training loss EPOCH: [457|1000], training loss: [0.47504482278600335], AE loss: [0.26544843474403024], TF loss: [0.20959638874046504] took 34.7811279296875\n",
      "Validation loss EPOCH: [457|1000], validation loss: [0.3107358533889055], AE loss: [0.1411086351145059], TF loss: [0.16962721850723028]\n",
      "Training loss EPOCH: [458|1000], training loss: [0.47356941271573305], AE loss: [0.2639793169219047], TF loss: [0.20959009625948966] took 32.4694299697876\n",
      "Validation loss EPOCH: [458|1000], validation loss: [0.31098135374486446], AE loss: [0.14132404956035316], TF loss: [0.16965730534866452]\n",
      "Training loss EPOCH: [459|1000], training loss: [0.4808709556236863], AE loss: [0.27142465114593506], TF loss: [0.20944630354642868] took 38.891459465026855\n",
      "Validation loss EPOCH: [459|1000], validation loss: [0.30876761209219694], AE loss: [0.13986268523149192], TF loss: [0.16890492709353566]\n",
      "Training loss EPOCH: [460|1000], training loss: [0.4730586213991046], AE loss: [0.263593286043033], TF loss: [0.20946533838286996] took 33.706421852111816\n",
      "Validation loss EPOCH: [460|1000], validation loss: [0.3096935451030731], AE loss: [0.14026310574263334], TF loss: [0.16943043982610106]\n",
      "Training loss EPOCH: [461|1000], training loss: [0.47174398275092244], AE loss: [0.26213494688272476], TF loss: [0.2096090349368751] took 35.22109842300415\n",
      "Validation loss EPOCH: [461|1000], validation loss: [0.30951880384236574], AE loss: [0.14087377744726837], TF loss: [0.16864502942189574]\n",
      "Training loss EPOCH: [462|1000], training loss: [0.4747863579541445], AE loss: [0.26518390933051705], TF loss: [0.2096024490892887] took 35.064926862716675\n",
      "Validation loss EPOCH: [462|1000], validation loss: [0.30999394599348307], AE loss: [0.14030071278102696], TF loss: [0.16969323391094804]\n",
      "Training loss EPOCH: [463|1000], training loss: [0.4723813058808446], AE loss: [0.26289739343337715], TF loss: [0.2094839159399271] took 34.588196992874146\n",
      "Validation loss EPOCH: [463|1000], validation loss: [0.3101553274318576], AE loss: [0.1409150182735175], TF loss: [0.16924030799418688]\n",
      "Training loss EPOCH: [464|1000], training loss: [0.47227016231045127], AE loss: [0.26289127790369093], TF loss: [0.20937888277694583] took 33.1998233795166\n",
      "Validation loss EPOCH: [464|1000], validation loss: [0.30934135615825653], AE loss: [0.14051046245731413], TF loss: [0.16883089486509562]\n",
      "Training loss EPOCH: [465|1000], training loss: [0.47258460940793157], AE loss: [0.26326553453691304], TF loss: [0.2093190737068653] took 35.53611373901367\n",
      "Validation loss EPOCH: [465|1000], validation loss: [0.31031937152147293], AE loss: [0.1409429565537721], TF loss: [0.1693764147348702]\n",
      "Training loss EPOCH: [466|1000], training loss: [0.47602863470092416], AE loss: [0.2665447285398841], TF loss: [0.20948390662670135] took 34.036500215530396\n",
      "Validation loss EPOCH: [466|1000], validation loss: [0.3084169030189514], AE loss: [0.14066679100506008], TF loss: [0.16775011317804456]\n",
      "Training loss EPOCH: [467|1000], training loss: [0.4723348179832101], AE loss: [0.2628743096720427], TF loss: [0.20946050970815122] took 32.238287925720215\n",
      "Validation loss EPOCH: [467|1000], validation loss: [0.30923791509121656], AE loss: [0.1407925810199231], TF loss: [0.1684453310444951]\n",
      "Training loss EPOCH: [468|1000], training loss: [0.472679746337235], AE loss: [0.263288103742525], TF loss: [0.20939164399169385] took 34.7674720287323\n",
      "Validation loss EPOCH: [468|1000], validation loss: [0.3092729263007641], AE loss: [0.1406401633284986], TF loss: [0.1686327662318945]\n",
      "Training loss EPOCH: [469|1000], training loss: [0.46983047015964985], AE loss: [0.2604380417615175], TF loss: [0.20939243119210005] took 31.74103808403015\n",
      "Validation loss EPOCH: [469|1000], validation loss: [0.30968397203832865], AE loss: [0.1407701966818422], TF loss: [0.16891377791762352]\n",
      "Training loss EPOCH: [470|1000], training loss: [0.4749982384964824], AE loss: [0.2655573580414057], TF loss: [0.20944087952375412] took 30.48012661933899\n",
      "Validation loss EPOCH: [470|1000], validation loss: [0.30931842885911465], AE loss: [0.14010352781042457], TF loss: [0.16921490244567394]\n",
      "Training loss EPOCH: [471|1000], training loss: [0.4738516132347286], AE loss: [0.2642944601830095], TF loss: [0.20955715258605778] took 32.34471011161804\n",
      "Validation loss EPOCH: [471|1000], validation loss: [0.3094957023859024], AE loss: [0.14054219471290708], TF loss: [0.16895350674167275]\n",
      "Training loss EPOCH: [472|1000], training loss: [0.47226939955726266], AE loss: [0.2629542334470898], TF loss: [0.20931516587734222] took 31.478160619735718\n",
      "Validation loss EPOCH: [472|1000], validation loss: [0.31021170038729906], AE loss: [0.14055442670360208], TF loss: [0.1696572732180357]\n",
      "Training loss EPOCH: [473|1000], training loss: [0.4713671561330557], AE loss: [0.2619454776868224], TF loss: [0.20942168240435421] took 29.45282554626465\n",
      "Validation loss EPOCH: [473|1000], validation loss: [0.3094482058659196], AE loss: [0.1407442861236632], TF loss: [0.1687039202079177]\n",
      "Training loss EPOCH: [474|1000], training loss: [0.47723537031561136], AE loss: [0.26783925760537386], TF loss: [0.20939611410722136] took 31.42902946472168\n",
      "Validation loss EPOCH: [474|1000], validation loss: [0.3102277824655175], AE loss: [0.14090473670512438], TF loss: [0.16932304250076413]\n",
      "Training loss EPOCH: [475|1000], training loss: [0.4752230178564787], AE loss: [0.26580171287059784], TF loss: [0.2094213063828647] took 31.249208688735962\n",
      "Validation loss EPOCH: [475|1000], validation loss: [0.31019423622637987], AE loss: [0.14079399779438972], TF loss: [0.169400236569345]\n",
      "Training loss EPOCH: [476|1000], training loss: [0.47070897510275245], AE loss: [0.26138159981928766], TF loss: [0.209327376447618] took 34.68134045600891\n",
      "Validation loss EPOCH: [476|1000], validation loss: [0.30928464513272047], AE loss: [0.14091804204508662], TF loss: [0.16836660215631127]\n",
      "Training loss EPOCH: [477|1000], training loss: [0.4751079585403204], AE loss: [0.2658610241487622], TF loss: [0.2092469350900501] took 31.66632342338562\n",
      "Validation loss EPOCH: [477|1000], validation loss: [0.30890895146876574], AE loss: [0.14014460239559412], TF loss: [0.1687643495388329]\n",
      "Training loss EPOCH: [478|1000], training loss: [0.46938289189711213], AE loss: [0.26004960923455656], TF loss: [0.20933328312821686] took 30.085663080215454\n",
      "Validation loss EPOCH: [478|1000], validation loss: [0.31025733705610037], AE loss: [0.14111224887892604], TF loss: [0.16914508817717433]\n",
      "Training loss EPOCH: [479|1000], training loss: [0.47365439170971513], AE loss: [0.264281636569649], TF loss: [0.20937275560572743] took 33.04839205741882\n",
      "Validation loss EPOCH: [479|1000], validation loss: [0.3096033800393343], AE loss: [0.14077756134793162], TF loss: [0.16882581962272525]\n",
      "Training loss EPOCH: [480|1000], training loss: [0.47347455378621817], AE loss: [0.2642069726716727], TF loss: [0.2092675839085132] took 33.39640402793884\n",
      "Validation loss EPOCH: [480|1000], validation loss: [0.30942155700176954], AE loss: [0.1402196262497455], TF loss: [0.16920192912220955]\n",
      "Training loss EPOCH: [481|1000], training loss: [0.46960760839283466], AE loss: [0.2604486152995378], TF loss: [0.20915899309329689] took 33.56085777282715\n",
      "Validation loss EPOCH: [481|1000], validation loss: [0.3095636507496238], AE loss: [0.14070560573600233], TF loss: [0.16885804617777467]\n",
      "Training loss EPOCH: [482|1000], training loss: [0.47376957163214684], AE loss: [0.26468136813491583], TF loss: [0.2090882018674165] took 31.3746817111969\n",
      "Validation loss EPOCH: [482|1000], validation loss: [0.3090177634730935], AE loss: [0.14074087236076593], TF loss: [0.16827689250931144]\n",
      "Training loss EPOCH: [483|1000], training loss: [0.4699855069629848], AE loss: [0.26074707927182317], TF loss: [0.20923843001946807] took 28.75982356071472\n",
      "Validation loss EPOCH: [483|1000], validation loss: [0.3093556249514222], AE loss: [0.14019579836167395], TF loss: [0.16915982961654663]\n",
      "Training loss EPOCH: [484|1000], training loss: [0.4742593038827181], AE loss: [0.265229586744681], TF loss: [0.20902971713803709] took 30.53234887123108\n",
      "Validation loss EPOCH: [484|1000], validation loss: [0.30975965689867735], AE loss: [0.14076860388740897], TF loss: [0.1689910520799458]\n",
      "Training loss EPOCH: [485|1000], training loss: [0.46818903367966413], AE loss: [0.25905937631614506], TF loss: [0.20912965899333358] took 30.367965698242188\n",
      "Validation loss EPOCH: [485|1000], validation loss: [0.3100410886108875], AE loss: [0.1410020086914301], TF loss: [0.16903907991945744]\n",
      "Training loss EPOCH: [486|1000], training loss: [0.47659960435703397], AE loss: [0.2673735972493887], TF loss: [0.20922600803896785] took 30.3151638507843\n",
      "Validation loss EPOCH: [486|1000], validation loss: [0.30942676588892937], AE loss: [0.14085444249212742], TF loss: [0.16857232293114066]\n",
      "Training loss EPOCH: [487|1000], training loss: [0.4716211403720081], AE loss: [0.2628023633733392], TF loss: [0.20881877839565277] took 30.654536724090576\n",
      "Validation loss EPOCH: [487|1000], validation loss: [0.3095735860988498], AE loss: [0.1407070979475975], TF loss: [0.16886648861691356]\n",
      "Training loss EPOCH: [488|1000], training loss: [0.4690840062685311], AE loss: [0.2599668735638261], TF loss: [0.20911713293753564] took 28.69563889503479\n",
      "Validation loss EPOCH: [488|1000], validation loss: [0.3091938365250826], AE loss: [0.1408823374658823], TF loss: [0.168311501853168]\n",
      "Training loss EPOCH: [489|1000], training loss: [0.4753818432800472], AE loss: [0.26624698587693274], TF loss: [0.20913485647179186] took 32.42294359207153\n",
      "Validation loss EPOCH: [489|1000], validation loss: [0.30952814780175686], AE loss: [0.14080189750529826], TF loss: [0.16872624726966023]\n",
      "Training loss EPOCH: [490|1000], training loss: [0.47247790498659015], AE loss: [0.2634253252763301], TF loss: [0.20905257808044553] took 33.848313331604004\n",
      "Validation loss EPOCH: [490|1000], validation loss: [0.3092771749943495], AE loss: [0.14009910775348544], TF loss: [0.1691780681721866]\n",
      "Training loss EPOCH: [491|1000], training loss: [0.4694798714481294], AE loss: [0.26028750045225024], TF loss: [0.2091923700645566] took 31.325294494628906\n",
      "Validation loss EPOCH: [491|1000], validation loss: [0.31012783385813236], AE loss: [0.14095934526994824], TF loss: [0.1691684890538454]\n",
      "Training loss EPOCH: [492|1000], training loss: [0.4710645447485149], AE loss: [0.261818214552477], TF loss: [0.20924632949754596] took 27.40093469619751\n",
      "Validation loss EPOCH: [492|1000], validation loss: [0.3109168643131852], AE loss: [0.14100720826536417], TF loss: [0.16990965604782104]\n",
      "Training loss EPOCH: [493|1000], training loss: [0.4727642862126231], AE loss: [0.2638539387844503], TF loss: [0.2089103462640196] took 30.8322331905365\n",
      "Validation loss EPOCH: [493|1000], validation loss: [0.3100142637267709], AE loss: [0.14072137465700507], TF loss: [0.16929289186373353]\n",
      "Training loss EPOCH: [494|1000], training loss: [0.4686310198158026], AE loss: [0.2596284276805818], TF loss: [0.20900259260088205] took 33.671656131744385\n",
      "Validation loss EPOCH: [494|1000], validation loss: [0.31081866659224033], AE loss: [0.14110960345715284], TF loss: [0.16970906173810363]\n",
      "Training loss EPOCH: [495|1000], training loss: [0.47127213329076767], AE loss: [0.2622862958814949], TF loss: [0.2089858390390873] took 29.55593204498291\n",
      "Validation loss EPOCH: [495|1000], validation loss: [0.3109939368441701], AE loss: [0.14096531318500638], TF loss: [0.17002862319350243]\n",
      "Training loss EPOCH: [496|1000], training loss: [0.4669553777202964], AE loss: [0.25801638956181705], TF loss: [0.20893898699432611] took 31.239630460739136\n",
      "Validation loss EPOCH: [496|1000], validation loss: [0.31066923681646585], AE loss: [0.1410553513560444], TF loss: [0.16961388615891337]\n",
      "Training loss EPOCH: [497|1000], training loss: [0.4680554266087711], AE loss: [0.2590068685822189], TF loss: [0.20904855942353606] took 33.60015606880188\n",
      "Validation loss EPOCH: [497|1000], validation loss: [0.3100089989602566], AE loss: [0.14051196817308664], TF loss: [0.16949703264981508]\n",
      "Training loss EPOCH: [498|1000], training loss: [0.478820214048028], AE loss: [0.26984881376847625], TF loss: [0.2089714033063501] took 31.547897577285767\n",
      "Validation loss EPOCH: [498|1000], validation loss: [0.31038142275065184], AE loss: [0.140561479376629], TF loss: [0.16981994360685349]\n",
      "Training loss EPOCH: [499|1000], training loss: [0.4704610938206315], AE loss: [0.26164267025887966], TF loss: [0.20881842402741313] took 30.341269969940186\n",
      "Validation loss EPOCH: [499|1000], validation loss: [0.30996288917958736], AE loss: [0.14047350944019854], TF loss: [0.16948938090354204]\n",
      "Training loss EPOCH: [500|1000], training loss: [0.46745369024574757], AE loss: [0.2586890198290348], TF loss: [0.20876467158086598] took 32.817209005355835\n",
      "Validation loss EPOCH: [500|1000], validation loss: [0.30962655786424875], AE loss: [0.14073626068420708], TF loss: [0.16889029601588845]\n",
      "Training loss EPOCH: [501|1000], training loss: [0.47395110549405217], AE loss: [0.2650220284704119], TF loss: [0.20892907702364028] took 31.190220832824707\n",
      "Validation loss EPOCH: [501|1000], validation loss: [0.3096111863851547], AE loss: [0.14099003979936242], TF loss: [0.16862114984542131]\n",
      "Training loss EPOCH: [502|1000], training loss: [0.46929613081738353], AE loss: [0.26044488581828773], TF loss: [0.2088512482587248] took 31.454317808151245\n",
      "Validation loss EPOCH: [502|1000], validation loss: [0.3101592278108001], AE loss: [0.14109428552910686], TF loss: [0.1690649427473545]\n",
      "Training loss EPOCH: [503|1000], training loss: [0.47304617427289486], AE loss: [0.26426570024341345], TF loss: [0.20878047589212656] took 30.98430633544922\n",
      "Validation loss EPOCH: [503|1000], validation loss: [0.3107965821400285], AE loss: [0.140599949285388], TF loss: [0.17019663657993078]\n",
      "Training loss EPOCH: [504|1000], training loss: [0.4764966117218137], AE loss: [0.26757621485739946], TF loss: [0.20892039872705936] took 31.695888996124268\n",
      "Validation loss EPOCH: [504|1000], validation loss: [0.31127240136265755], AE loss: [0.1407593018375337], TF loss: [0.17051309905946255]\n",
      "Training loss EPOCH: [505|1000], training loss: [0.47253987193107605], AE loss: [0.26348106493242085], TF loss: [0.20905880583450198] took 30.629782915115356\n",
      "Validation loss EPOCH: [505|1000], validation loss: [0.3095540041103959], AE loss: [0.14098349562846124], TF loss: [0.16857050685212016]\n",
      "Training loss EPOCH: [506|1000], training loss: [0.47199773835018277], AE loss: [0.2632099473848939], TF loss: [0.20878779352642596] took 33.67843818664551\n",
      "Validation loss EPOCH: [506|1000], validation loss: [0.311262059956789], AE loss: [0.14129007956944406], TF loss: [0.16997197922319174]\n",
      "Training loss EPOCH: [507|1000], training loss: [0.4667666736058891], AE loss: [0.2579641391057521], TF loss: [0.20880253496579826] took 31.42952561378479\n",
      "Validation loss EPOCH: [507|1000], validation loss: [0.31043598148971796], AE loss: [0.14092877670191228], TF loss: [0.16950720734894276]\n",
      "Training loss EPOCH: [508|1000], training loss: [0.46989017771556973], AE loss: [0.26113270688802004], TF loss: [0.20875747269019485] took 29.9518723487854\n",
      "Validation loss EPOCH: [508|1000], validation loss: [0.30974619649350643], AE loss: [0.14047583448700607], TF loss: [0.16927036503329873]\n",
      "Training loss EPOCH: [509|1000], training loss: [0.4688415681011975], AE loss: [0.2600964007433504], TF loss: [0.20874516805633903] took 32.29613780975342\n",
      "Validation loss EPOCH: [509|1000], validation loss: [0.3112413715571165], AE loss: [0.14113644743338227], TF loss: [0.1701049255207181]\n",
      "Training loss EPOCH: [510|1000], training loss: [0.47427972266450524], AE loss: [0.26536377100273967], TF loss: [0.20891595003195107] took 31.493489503860474\n",
      "Validation loss EPOCH: [510|1000], validation loss: [0.30982314702123404], AE loss: [0.14070501131936908], TF loss: [0.16911813709884882]\n",
      "Training loss EPOCH: [511|1000], training loss: [0.4713653102517128], AE loss: [0.26239795656874776], TF loss: [0.20896735251881182] took 32.02377533912659\n",
      "Validation loss EPOCH: [511|1000], validation loss: [0.3097805203869939], AE loss: [0.1405795190948993], TF loss: [0.16920100757852197]\n",
      "Training loss EPOCH: [512|1000], training loss: [0.47095190128311515], AE loss: [0.2623960976488888], TF loss: [0.20855580433271825] took 31.014931440353394\n",
      "Validation loss EPOCH: [512|1000], validation loss: [0.3102515675127506], AE loss: [0.14082364016212523], TF loss: [0.16942792665213346]\n",
      "Training loss EPOCH: [513|1000], training loss: [0.46810884680598974], AE loss: [0.2593351975083351], TF loss: [0.20877364999614656] took 33.46376895904541\n",
      "Validation loss EPOCH: [513|1000], validation loss: [0.3095717756077647], AE loss: [0.1411626930348575], TF loss: [0.1684090825729072]\n",
      "Training loss EPOCH: [514|1000], training loss: [0.47572883032262325], AE loss: [0.2669112849980593], TF loss: [0.20881754579022527] took 32.752460956573486\n",
      "Validation loss EPOCH: [514|1000], validation loss: [0.3098899722099304], AE loss: [0.14046785328537226], TF loss: [0.16942211845889688]\n",
      "Training loss EPOCH: [515|1000], training loss: [0.46894861850887537], AE loss: [0.26017997693270445], TF loss: [0.20876864227466285] took 30.657788515090942\n",
      "Validation loss EPOCH: [515|1000], validation loss: [0.31019625160843134], AE loss: [0.14087716001085937], TF loss: [0.16931908810511231]\n",
      "Training loss EPOCH: [516|1000], training loss: [0.4666790124028921], AE loss: [0.2580195511691272], TF loss: [0.20865946263074875] took 30.125129461288452\n",
      "Validation loss EPOCH: [516|1000], validation loss: [0.3097042068839073], AE loss: [0.14091496379114687], TF loss: [0.16878924379125237]\n",
      "Training loss EPOCH: [517|1000], training loss: [0.47341193864122033], AE loss: [0.2648030954878777], TF loss: [0.20860884292051196] took 32.715781688690186\n",
      "Validation loss EPOCH: [517|1000], validation loss: [0.3107822872698307], AE loss: [0.14090232318267226], TF loss: [0.16987996269017458]\n",
      "Training loss EPOCH: [518|1000], training loss: [0.47361489618197083], AE loss: [0.26491337874904275], TF loss: [0.20870151789858937] took 32.97132754325867\n",
      "Validation loss EPOCH: [518|1000], validation loss: [0.3109439192339778], AE loss: [0.14063308015465736], TF loss: [0.1703108404763043]\n",
      "Training loss EPOCH: [519|1000], training loss: [0.47046420257538557], AE loss: [0.26181008690036833], TF loss: [0.2086541154421866] took 28.420591115951538\n",
      "Validation loss EPOCH: [519|1000], validation loss: [0.3101511625573039], AE loss: [0.14061706652864814], TF loss: [0.16953409695997834]\n",
      "Training loss EPOCH: [520|1000], training loss: [0.46915941359475255], AE loss: [0.2606580520514399], TF loss: [0.2085013589821756] took 29.222647666931152\n",
      "Validation loss EPOCH: [520|1000], validation loss: [0.3116074148565531], AE loss: [0.14076397195458412], TF loss: [0.17084344383329153]\n",
      "Training loss EPOCH: [521|1000], training loss: [0.46760781202465296], AE loss: [0.2590246780309826], TF loss: [0.208583134226501] took 29.712599754333496\n",
      "Validation loss EPOCH: [521|1000], validation loss: [0.3103850884363055], AE loss: [0.1410809496883303], TF loss: [0.169304134324193]\n",
      "Training loss EPOCH: [522|1000], training loss: [0.4703129483386874], AE loss: [0.26167124416679144], TF loss: [0.2086417048703879] took 32.33946394920349\n",
      "Validation loss EPOCH: [522|1000], validation loss: [0.3105798829346895], AE loss: [0.14079885999672115], TF loss: [0.16978102270513773]\n",
      "Training loss EPOCH: [523|1000], training loss: [0.4693662687204778], AE loss: [0.26084624347276986], TF loss: [0.20852002687752247] took 32.784289836883545\n",
      "Validation loss EPOCH: [523|1000], validation loss: [0.3100086534395814], AE loss: [0.14085008576512337], TF loss: [0.1691585648804903]\n",
      "Training loss EPOCH: [524|1000], training loss: [0.47119587659835815], AE loss: [0.2626913725398481], TF loss: [0.20850450336001813] took 32.15373659133911\n",
      "Validation loss EPOCH: [524|1000], validation loss: [0.31015657633543015], AE loss: [0.14051815122365952], TF loss: [0.16963842697441578]\n",
      "Training loss EPOCH: [525|1000], training loss: [0.46704151667654514], AE loss: [0.2585562481544912], TF loss: [0.20848526852205396] took 29.73419499397278\n",
      "Validation loss EPOCH: [525|1000], validation loss: [0.3100939569994807], AE loss: [0.14045988558791578], TF loss: [0.16963407257571816]\n",
      "Training loss EPOCH: [526|1000], training loss: [0.47598196333274245], AE loss: [0.26736940955743194], TF loss: [0.20861255610361695] took 30.939849376678467\n",
      "Validation loss EPOCH: [526|1000], validation loss: [0.31021547596901655], AE loss: [0.14069924713112414], TF loss: [0.16951622953638434]\n",
      "Training loss EPOCH: [527|1000], training loss: [0.47495165932923555], AE loss: [0.2666398868896067], TF loss: [0.20831177290529013] took 35.611950397491455\n",
      "Validation loss EPOCH: [527|1000], validation loss: [0.31098373234272003], AE loss: [0.14073405065573752], TF loss: [0.17024968145415187]\n",
      "Training loss EPOCH: [528|1000], training loss: [0.46853427216410637], AE loss: [0.2599352740217], TF loss: [0.208598998375237] took 33.05537033081055\n",
      "Validation loss EPOCH: [528|1000], validation loss: [0.31042488291859627], AE loss: [0.14091495890170336], TF loss: [0.16950992168858647]\n",
      "Training loss EPOCH: [529|1000], training loss: [0.4670153702609241], AE loss: [0.2584267824422568], TF loss: [0.20858858805149794] took 31.48828887939453\n",
      "Validation loss EPOCH: [529|1000], validation loss: [0.31092014349997044], AE loss: [0.14106628042645752], TF loss: [0.1698538651689887]\n",
      "Training loss EPOCH: [530|1000], training loss: [0.46890829829499125], AE loss: [0.26042631012387574], TF loss: [0.20848198840394616] took 31.104345321655273\n",
      "Validation loss EPOCH: [530|1000], validation loss: [0.3097593020647764], AE loss: [0.14052184531465173], TF loss: [0.1692374567501247]\n",
      "Training loss EPOCH: [531|1000], training loss: [0.4700630120933056], AE loss: [0.2616037130355835], TF loss: [0.20845929672941566] took 29.55017113685608\n",
      "Validation loss EPOCH: [531|1000], validation loss: [0.309765444137156], AE loss: [0.1413094240706414], TF loss: [0.1684560189023614]\n",
      "Training loss EPOCH: [532|1000], training loss: [0.4717737645842135], AE loss: [0.2632686044089496], TF loss: [0.20850516040809453] took 29.02026343345642\n",
      "Validation loss EPOCH: [532|1000], validation loss: [0.31088546477258205], AE loss: [0.1410274407826364], TF loss: [0.16985802492126822]\n",
      "Training loss EPOCH: [533|1000], training loss: [0.4653840162791312], AE loss: [0.2569048742298037], TF loss: [0.20847914065234363] took 29.531388759613037\n",
      "Validation loss EPOCH: [533|1000], validation loss: [0.3099707067012787], AE loss: [0.1409397292882204], TF loss: [0.16903097555041313]\n",
      "Training loss EPOCH: [534|1000], training loss: [0.4704035581089556], AE loss: [0.26195812528021634], TF loss: [0.20844543166458607] took 34.36927652359009\n",
      "Validation loss EPOCH: [534|1000], validation loss: [0.30985244177281857], AE loss: [0.14093732088804245], TF loss: [0.16891511902213097]\n",
      "Training loss EPOCH: [535|1000], training loss: [0.46699704648926854], AE loss: [0.2583394085522741], TF loss: [0.2086576372385025] took 31.484724521636963\n",
      "Validation loss EPOCH: [535|1000], validation loss: [0.31027793791145086], AE loss: [0.1414536179509014], TF loss: [0.16882432019338012]\n",
      "Training loss EPOCH: [536|1000], training loss: [0.4741270011290908], AE loss: [0.265702520031482], TF loss: [0.20842448016628623] took 34.06695890426636\n",
      "Validation loss EPOCH: [536|1000], validation loss: [0.31025111861526966], AE loss: [0.14048507763072848], TF loss: [0.1697660437785089]\n",
      "Training loss EPOCH: [537|1000], training loss: [0.46826328663155437], AE loss: [0.2598993603605777], TF loss: [0.2083639265038073] took 33.276386737823486\n",
      "Validation loss EPOCH: [537|1000], validation loss: [0.31117709167301655], AE loss: [0.1414429370779544], TF loss: [0.16973415296524763]\n",
      "Training loss EPOCH: [538|1000], training loss: [0.46862158086150885], AE loss: [0.26018698373809457], TF loss: [0.20843459689058363] took 30.93559432029724\n",
      "Validation loss EPOCH: [538|1000], validation loss: [0.3101536426693201], AE loss: [0.14083142392337322], TF loss: [0.16932221641764045]\n",
      "Training loss EPOCH: [539|1000], training loss: [0.4700126270763576], AE loss: [0.2615906922146678], TF loss: [0.20842193393036723] took 31.651623725891113\n",
      "Validation loss EPOCH: [539|1000], validation loss: [0.31038626842200756], AE loss: [0.14068057644180954], TF loss: [0.1697056945413351]\n",
      "Training loss EPOCH: [540|1000], training loss: [0.4651485914364457], AE loss: [0.25674624531529844], TF loss: [0.20840234798379242] took 33.15503168106079\n",
      "Validation loss EPOCH: [540|1000], validation loss: [0.3102419478818774], AE loss: [0.14121521590277553], TF loss: [0.16902673011645675]\n",
      "Training loss EPOCH: [541|1000], training loss: [0.4733146554790437], AE loss: [0.26498413854278624], TF loss: [0.20833051740191877] took 30.803731441497803\n",
      "Validation loss EPOCH: [541|1000], validation loss: [0.31059201154857874], AE loss: [0.1414372818544507], TF loss: [0.16915472922846675]\n",
      "Training loss EPOCH: [542|1000], training loss: [0.47064572386443615], AE loss: [0.26236306107603014], TF loss: [0.20828266465105116] took 29.395026206970215\n",
      "Validation loss EPOCH: [542|1000], validation loss: [0.3109317710623145], AE loss: [0.14095489075407386], TF loss: [0.16997688123956323]\n",
      "Training loss EPOCH: [543|1000], training loss: [0.46878780238330364], AE loss: [0.2603123257867992], TF loss: [0.2084754784591496] took 31.43901491165161\n",
      "Validation loss EPOCH: [543|1000], validation loss: [0.3107293965294957], AE loss: [0.14095246023498476], TF loss: [0.1697769332677126]\n",
      "Training loss EPOCH: [544|1000], training loss: [0.46531687257811427], AE loss: [0.2569145339075476], TF loss: [0.20840233797207475] took 30.907933712005615\n",
      "Validation loss EPOCH: [544|1000], validation loss: [0.31033937726169825], AE loss: [0.14108409616164863], TF loss: [0.16925528552383184]\n",
      "Training loss EPOCH: [545|1000], training loss: [0.46593102160841227], AE loss: [0.25771041098050773], TF loss: [0.20822061132639647] took 33.69344758987427\n",
      "Validation loss EPOCH: [545|1000], validation loss: [0.3105143653228879], AE loss: [0.14104623929597437], TF loss: [0.16946812672540545]\n",
      "Training loss EPOCH: [546|1000], training loss: [0.4680243832990527], AE loss: [0.2598120388574898], TF loss: [0.20821234281174839] took 31.176884174346924\n",
      "Validation loss EPOCH: [546|1000], validation loss: [0.3103879941627383], AE loss: [0.1411835120525211], TF loss: [0.1692044846713543]\n",
      "Training loss EPOCH: [547|1000], training loss: [0.4735194044187665], AE loss: [0.2653780756518245], TF loss: [0.20814132946543396] took 32.78368592262268\n",
      "Validation loss EPOCH: [547|1000], validation loss: [0.3098076153546572], AE loss: [0.14046453218907118], TF loss: [0.16934308502823114]\n",
      "Training loss EPOCH: [548|1000], training loss: [0.46817849995568395], AE loss: [0.25992823182605207], TF loss: [0.20825026906095445] took 32.82002258300781\n",
      "Validation loss EPOCH: [548|1000], validation loss: [0.3116075461730361], AE loss: [0.14108967664651573], TF loss: [0.1705178744159639]\n",
      "Training loss EPOCH: [549|1000], training loss: [0.46511844638735056], AE loss: [0.25688674324192107], TF loss: [0.2082317043095827] took 32.57913017272949\n",
      "Validation loss EPOCH: [549|1000], validation loss: [0.3117822064086795], AE loss: [0.14153235824778676], TF loss: [0.1702498449012637]\n",
      "Training loss EPOCH: [550|1000], training loss: [0.4703564625233412], AE loss: [0.26205991744063795], TF loss: [0.20829654508270323] took 30.343793630599976\n",
      "Validation loss EPOCH: [550|1000], validation loss: [0.3090580264106393], AE loss: [0.14037259249016643], TF loss: [0.168685432523489]\n",
      "Training loss EPOCH: [551|1000], training loss: [0.47174046421423554], AE loss: [0.2633373092394322], TF loss: [0.2084031538106501] took 26.7247211933136\n",
      "Validation loss EPOCH: [551|1000], validation loss: [0.310386348515749], AE loss: [0.14080459717661142], TF loss: [0.16958175133913755]\n",
      "Training loss EPOCH: [552|1000], training loss: [0.46804961655288935], AE loss: [0.2597497326787561], TF loss: [0.20829988620243967] took 27.522003173828125\n",
      "Validation loss EPOCH: [552|1000], validation loss: [0.3106828071177006], AE loss: [0.14117229240946472], TF loss: [0.16951051261276007]\n",
      "Training loss EPOCH: [553|1000], training loss: [0.46439258474856615], AE loss: [0.25623207236640155], TF loss: [0.2081605144776404] took 26.2475368976593\n",
      "Validation loss EPOCH: [553|1000], validation loss: [0.31125205010175705], AE loss: [0.14127177349291742], TF loss: [0.16998027777299285]\n",
      "Training loss EPOCH: [554|1000], training loss: [0.46882975893095136], AE loss: [0.26086185965687037], TF loss: [0.20796790020540357] took 25.643290519714355\n",
      "Validation loss EPOCH: [554|1000], validation loss: [0.3116429131478071], AE loss: [0.1414032205939293], TF loss: [0.17023968929424882]\n",
      "Training loss EPOCH: [555|1000], training loss: [0.47077582916244864], AE loss: [0.2624962483532727], TF loss: [0.20827958011068404] took 28.210265398025513\n",
      "Validation loss EPOCH: [555|1000], validation loss: [0.3094812324270606], AE loss: [0.1398344684857875], TF loss: [0.16964676324278116]\n",
      "Training loss EPOCH: [556|1000], training loss: [0.4725881852209568], AE loss: [0.2643854047637433], TF loss: [0.20820278045721352] took 27.35094165802002\n",
      "Validation loss EPOCH: [556|1000], validation loss: [0.31089180801063776], AE loss: [0.14072642754763365], TF loss: [0.17016537906602025]\n",
      "Training loss EPOCH: [557|1000], training loss: [0.4693288621492684], AE loss: [0.26109721907414496], TF loss: [0.208231644006446] took 29.522502660751343\n",
      "Validation loss EPOCH: [557|1000], validation loss: [0.31084727961570024], AE loss: [0.1409824825823307], TF loss: [0.16986479749903083]\n",
      "Training loss EPOCH: [558|1000], training loss: [0.4718077671714127], AE loss: [0.26374258007854223], TF loss: [0.20806518546305597] took 26.30726432800293\n",
      "Validation loss EPOCH: [558|1000], validation loss: [0.3098014649003744], AE loss: [0.13948603253811598], TF loss: [0.170315433293581]\n",
      "Training loss EPOCH: [559|1000], training loss: [0.4720505829900503], AE loss: [0.263767346739769], TF loss: [0.20828323531895876] took 24.10746121406555\n",
      "Validation loss EPOCH: [559|1000], validation loss: [0.3110789302736521], AE loss: [0.1415283523965627], TF loss: [0.16955057764425874]\n",
      "Training loss EPOCH: [560|1000], training loss: [0.4698883858509362], AE loss: [0.26162581192329526], TF loss: [0.20826257509179413] took 27.23825454711914\n",
      "Validation loss EPOCH: [560|1000], validation loss: [0.3107840334996581], AE loss: [0.1410892561543733], TF loss: [0.16969477804377675]\n",
      "Training loss EPOCH: [561|1000], training loss: [0.46803184412419796], AE loss: [0.2598770083859563], TF loss: [0.20815483550541103] took 27.641369819641113\n",
      "Validation loss EPOCH: [561|1000], validation loss: [0.31095711700618267], AE loss: [0.14136567153036594], TF loss: [0.16959144780412316]\n",
      "Training loss EPOCH: [562|1000], training loss: [0.47047297889366746], AE loss: [0.2625575789716095], TF loss: [0.20791540015488863] took 25.432201385498047\n",
      "Validation loss EPOCH: [562|1000], validation loss: [0.3113714503124356], AE loss: [0.1411817369516939], TF loss: [0.17018971405923367]\n",
      "Training loss EPOCH: [563|1000], training loss: [0.46734307054430246], AE loss: [0.25947634014301], TF loss: [0.20786673040129244] took 30.771396160125732\n",
      "Validation loss EPOCH: [563|1000], validation loss: [0.3110229093581438], AE loss: [0.14149720896966755], TF loss: [0.1695257001556456]\n",
      "Training loss EPOCH: [564|1000], training loss: [0.4701780630275607], AE loss: [0.2621722090989351], TF loss: [0.20800585462711751] took 31.383304357528687\n",
      "Validation loss EPOCH: [564|1000], validation loss: [0.31045911833643913], AE loss: [0.14088114304468036], TF loss: [0.16957797575742006]\n",
      "Training loss EPOCH: [565|1000], training loss: [0.4720800118520856], AE loss: [0.26413596561178565], TF loss: [0.20794404484331608] took 28.319520950317383\n",
      "Validation loss EPOCH: [565|1000], validation loss: [0.310631450265646], AE loss: [0.1409601978957653], TF loss: [0.16967125609517097]\n",
      "Training loss EPOCH: [566|1000], training loss: [0.47089376067742705], AE loss: [0.26290923124179244], TF loss: [0.2079845299012959] took 22.40305471420288\n",
      "Validation loss EPOCH: [566|1000], validation loss: [0.30943088233470917], AE loss: [0.14032948901876807], TF loss: [0.16910139191895723]\n",
      "Training loss EPOCH: [567|1000], training loss: [0.4732211413793266], AE loss: [0.2650903237517923], TF loss: [0.20813081716187298] took 28.099557161331177\n",
      "Validation loss EPOCH: [567|1000], validation loss: [0.31114330142736435], AE loss: [0.14123849268071353], TF loss: [0.16990480525419116]\n",
      "Training loss EPOCH: [568|1000], training loss: [0.4678073045797646], AE loss: [0.25966487149707973], TF loss: [0.20814243098720908] took 30.639349222183228\n",
      "Validation loss EPOCH: [568|1000], validation loss: [0.3110393835231662], AE loss: [0.14143044664524496], TF loss: [0.16960893711075187]\n",
      "Training loss EPOCH: [569|1000], training loss: [0.47401644941419363], AE loss: [0.2659298414364457], TF loss: [0.20808660797774792] took 28.945899486541748\n",
      "Validation loss EPOCH: [569|1000], validation loss: [0.3100734381005168], AE loss: [0.14067444717511535], TF loss: [0.16939899045974016]\n",
      "Training loss EPOCH: [570|1000], training loss: [0.4693571492098272], AE loss: [0.2613357922527939], TF loss: [0.20802135905250907] took 29.233609676361084\n",
      "Validation loss EPOCH: [570|1000], validation loss: [0.3101274287328124], AE loss: [0.14124528784304857], TF loss: [0.16888214042410254]\n",
      "Training loss EPOCH: [571|1000], training loss: [0.4675139463506639], AE loss: [0.2594819087535143], TF loss: [0.20803203666582704] took 24.916822910308838\n",
      "Validation loss EPOCH: [571|1000], validation loss: [0.3110010540112853], AE loss: [0.14130754489451647], TF loss: [0.1696935063228011]\n",
      "Training loss EPOCH: [572|1000], training loss: [0.4767173873260617], AE loss: [0.26868172688409686], TF loss: [0.20803566160611808] took 26.37246060371399\n",
      "Validation loss EPOCH: [572|1000], validation loss: [0.31078433617949486], AE loss: [0.14053955907002091], TF loss: [0.17024477943778038]\n",
      "Training loss EPOCH: [573|1000], training loss: [0.47432044241577387], AE loss: [0.26649704831652343], TF loss: [0.20782339456491172] took 26.851582527160645\n",
      "Validation loss EPOCH: [573|1000], validation loss: [0.30929554253816605], AE loss: [0.14028790383599699], TF loss: [0.169007639400661]\n",
      "Training loss EPOCH: [574|1000], training loss: [0.4719614088535309], AE loss: [0.26389557658694685], TF loss: [0.20806583133526146] took 30.975595951080322\n",
      "Validation loss EPOCH: [574|1000], validation loss: [0.3101227190345526], AE loss: [0.14079687325283885], TF loss: [0.16932584764435887]\n",
      "Training loss EPOCH: [575|1000], training loss: [0.4674061122350395], AE loss: [0.2594542808365077], TF loss: [0.2079518330283463] took 25.788172483444214\n",
      "Validation loss EPOCH: [575|1000], validation loss: [0.3119156174361706], AE loss: [0.14127803244628012], TF loss: [0.17063758615404367]\n",
      "Training loss EPOCH: [576|1000], training loss: [0.46612546872347593], AE loss: [0.2582821808755398], TF loss: [0.20784328901208937] took 23.234692096710205\n",
      "Validation loss EPOCH: [576|1000], validation loss: [0.31260022427886724], AE loss: [0.141407661838457], TF loss: [0.17119256360456347]\n",
      "Training loss EPOCH: [577|1000], training loss: [0.46964180935174227], AE loss: [0.26178805041126907], TF loss: [0.20785375917330384] took 26.01179552078247\n",
      "Validation loss EPOCH: [577|1000], validation loss: [0.3110657297074795], AE loss: [0.1407841369509697], TF loss: [0.1702815955504775]\n",
      "Training loss EPOCH: [578|1000], training loss: [0.4690062222070992], AE loss: [0.26106065860949457], TF loss: [0.20794556173495948] took 27.485299110412598\n",
      "Validation loss EPOCH: [578|1000], validation loss: [0.3123224126175046], AE loss: [0.14122621226124465], TF loss: [0.17109620198607445]\n",
      "Training loss EPOCH: [579|1000], training loss: [0.470230667386204], AE loss: [0.2623335642274469], TF loss: [0.2078971043229103] took 27.760005712509155\n",
      "Validation loss EPOCH: [579|1000], validation loss: [0.3110300777480006], AE loss: [0.141066083451733], TF loss: [0.1699639898724854]\n",
      "Training loss EPOCH: [580|1000], training loss: [0.4701319541782141], AE loss: [0.26220009033568203], TF loss: [0.2079318652395159] took 23.910887956619263\n",
      "Validation loss EPOCH: [580|1000], validation loss: [0.31080155819654465], AE loss: [0.14085973845794797], TF loss: [0.1699418188072741]\n",
      "Training loss EPOCH: [581|1000], training loss: [0.47130960458889604], AE loss: [0.26349235512316227], TF loss: [0.20781725039705634] took 26.032539129257202\n",
      "Validation loss EPOCH: [581|1000], validation loss: [0.31131555419415236], AE loss: [0.14138237852603197], TF loss: [0.16993317659944296]\n",
      "Training loss EPOCH: [582|1000], training loss: [0.4736356595531106], AE loss: [0.2658566674217582], TF loss: [0.2077789909671992] took 28.515291929244995\n",
      "Validation loss EPOCH: [582|1000], validation loss: [0.31059037800878286], AE loss: [0.14019155455753207], TF loss: [0.1703988229855895]\n",
      "Training loss EPOCH: [583|1000], training loss: [0.46603104285895824], AE loss: [0.2582039316184819], TF loss: [0.20782710891216993] took 29.22146224975586\n",
      "Validation loss EPOCH: [583|1000], validation loss: [0.3109531197696924], AE loss: [0.14159825816750526], TF loss: [0.16935486532747746]\n",
      "Training loss EPOCH: [584|1000], training loss: [0.4692001906223595], AE loss: [0.26141760451719165], TF loss: [0.2077825868036598] took 25.97535014152527\n",
      "Validation loss EPOCH: [584|1000], validation loss: [0.31090698298066854], AE loss: [0.1412821200210601], TF loss: [0.16962486412376165]\n",
      "Training loss EPOCH: [585|1000], training loss: [0.470895666629076], AE loss: [0.2631010743789375], TF loss: [0.20779459201730788] took 27.765681266784668\n",
      "Validation loss EPOCH: [585|1000], validation loss: [0.3112222757190466], AE loss: [0.14131439244374633], TF loss: [0.16990788793191314]\n",
      "Training loss EPOCH: [586|1000], training loss: [0.46829678397625685], AE loss: [0.2605631914921105], TF loss: [0.20773359248414636] took 22.894325256347656\n",
      "Validation loss EPOCH: [586|1000], validation loss: [0.31144877057522535], AE loss: [0.14151985244825482], TF loss: [0.16992891672998667]\n",
      "Training loss EPOCH: [587|1000], training loss: [0.46660425467416644], AE loss: [0.2589851417578757], TF loss: [0.20761911431327462] took 22.21264123916626\n",
      "Validation loss EPOCH: [587|1000], validation loss: [0.3109990395605564], AE loss: [0.1413448106031865], TF loss: [0.16965422732755542]\n",
      "Training loss EPOCH: [588|1000], training loss: [0.4682297511026263], AE loss: [0.26034793350845575], TF loss: [0.20788181596435606] took 27.531012773513794\n",
      "Validation loss EPOCH: [588|1000], validation loss: [0.3110237717628479], AE loss: [0.1414892349857837], TF loss: [0.16953454120084643]\n",
      "Training loss EPOCH: [589|1000], training loss: [0.4715426443144679], AE loss: [0.2637115241959691], TF loss: [0.2078311201184988] took 25.40718173980713\n",
      "Validation loss EPOCH: [589|1000], validation loss: [0.311067002825439], AE loss: [0.14097600686363876], TF loss: [0.17009099666029215]\n",
      "Training loss EPOCH: [590|1000], training loss: [0.4724361216649413], AE loss: [0.2646782170049846], TF loss: [0.2077579058241099] took 25.43119525909424\n",
      "Validation loss EPOCH: [590|1000], validation loss: [0.3113963007926941], AE loss: [0.14103273581713438], TF loss: [0.170363565441221]\n",
      "Training loss EPOCH: [591|1000], training loss: [0.4688732442446053], AE loss: [0.2610127246007323], TF loss: [0.20786051684990525] took 26.907591819763184\n",
      "Validation loss EPOCH: [591|1000], validation loss: [0.31035515759140253], AE loss: [0.14115786575712264], TF loss: [0.1691972929984331]\n",
      "Training loss EPOCH: [592|1000], training loss: [0.4665740425698459], AE loss: [0.25874721072614193], TF loss: [0.20782683184370399] took 24.07146453857422\n",
      "Validation loss EPOCH: [592|1000], validation loss: [0.3104901905171573], AE loss: [0.14105445984750986], TF loss: [0.16943573206663132]\n",
      "Training loss EPOCH: [593|1000], training loss: [0.4697172739543021], AE loss: [0.26185459503903985], TF loss: [0.20786267961375415] took 26.18707847595215\n",
      "Validation loss EPOCH: [593|1000], validation loss: [0.3108561672270298], AE loss: [0.14100725669413805], TF loss: [0.16984891053289175]\n",
      "Training loss EPOCH: [594|1000], training loss: [0.4670861386694014], AE loss: [0.2591508061159402], TF loss: [0.20793533022515476] took 27.91088581085205\n",
      "Validation loss EPOCH: [594|1000], validation loss: [0.3099195286631584], AE loss: [0.1413711525965482], TF loss: [0.168548374902457]\n",
      "Training loss EPOCH: [595|1000], training loss: [0.46720022335648537], AE loss: [0.2595864227041602], TF loss: [0.20761379948817194] took 27.19710922241211\n",
      "Validation loss EPOCH: [595|1000], validation loss: [0.31157299131155014], AE loss: [0.14101669727824628], TF loss: [0.1705562938004732]\n",
      "Training loss EPOCH: [596|1000], training loss: [0.4652913063764572], AE loss: [0.2576023070141673], TF loss: [0.2076889993622899] took 25.541188716888428\n",
      "Validation loss EPOCH: [596|1000], validation loss: [0.3113808445632458], AE loss: [0.14114083675667644], TF loss: [0.17024000827223063]\n",
      "Training loss EPOCH: [597|1000], training loss: [0.4654833092354238], AE loss: [0.25781952729448676], TF loss: [0.20766378217376769] took 24.599348545074463\n",
      "Validation loss EPOCH: [597|1000], validation loss: [0.3113314136862755], AE loss: [0.1412716149352491], TF loss: [0.1700597987510264]\n",
      "Training loss EPOCH: [598|1000], training loss: [0.47060010954737663], AE loss: [0.2628931568469852], TF loss: [0.20770695409737527] took 24.877942085266113\n",
      "Validation loss EPOCH: [598|1000], validation loss: [0.31120413169264793], AE loss: [0.14155184081755579], TF loss: [0.16965229529887438]\n",
      "Training loss EPOCH: [599|1000], training loss: [0.46620452776551247], AE loss: [0.25861428189091384], TF loss: [0.20759024610742927] took 26.639031171798706\n",
      "Validation loss EPOCH: [599|1000], validation loss: [0.31120096147060394], AE loss: [0.14122686814516783], TF loss: [0.16997409099712968]\n",
      "Training loss EPOCH: [600|1000], training loss: [0.46920181158930063], AE loss: [0.26138932746835053], TF loss: [0.2078124820254743] took 23.95969581604004\n",
      "Validation loss EPOCH: [600|1000], validation loss: [0.31135575380176306], AE loss: [0.14122376590967178], TF loss: [0.17013198882341385]\n",
      "Training loss EPOCH: [601|1000], training loss: [0.46677432442083955], AE loss: [0.25899608549661934], TF loss: [0.20777823985554278] took 29.62560534477234\n",
      "Validation loss EPOCH: [601|1000], validation loss: [0.31070401426404715], AE loss: [0.14128874754533172], TF loss: [0.16941526485607028]\n",
      "Training loss EPOCH: [602|1000], training loss: [0.4705426534637809], AE loss: [0.26306536654010415], TF loss: [0.20747728552669287] took 26.00524401664734\n",
      "Validation loss EPOCH: [602|1000], validation loss: [0.3114466341212392], AE loss: [0.14093785430304706], TF loss: [0.17050878005102277]\n",
      "Training loss EPOCH: [603|1000], training loss: [0.46628075558692217], AE loss: [0.2586946689989418], TF loss: [0.2075860865879804] took 31.537370920181274\n",
      "Validation loss EPOCH: [603|1000], validation loss: [0.3118277881294489], AE loss: [0.14143477194011211], TF loss: [0.17039301618933678]\n",
      "Training loss EPOCH: [604|1000], training loss: [0.4723017024807632], AE loss: [0.26474897051230073], TF loss: [0.20755273196846247] took 29.827906608581543\n",
      "Validation loss EPOCH: [604|1000], validation loss: [0.3122993428260088], AE loss: [0.14160221605561674], TF loss: [0.17069712560623884]\n",
      "Training loss EPOCH: [605|1000], training loss: [0.4685688903555274], AE loss: [0.2610265731345862], TF loss: [0.20754231791943312] took 26.92452335357666\n",
      "Validation loss EPOCH: [605|1000], validation loss: [0.3109125690534711], AE loss: [0.14091680059209466], TF loss: [0.16999576846137643]\n",
      "Training loss EPOCH: [606|1000], training loss: [0.46666030678898096], AE loss: [0.2589925560168922], TF loss: [0.20766775030642748] took 23.629569053649902\n",
      "Validation loss EPOCH: [606|1000], validation loss: [0.3110726401209831], AE loss: [0.1414976790547371], TF loss: [0.16957496060058475]\n",
      "Training loss EPOCH: [607|1000], training loss: [0.4655617941170931], AE loss: [0.25796483433805406], TF loss: [0.20759695954620838] took 26.710965394973755\n",
      "Validation loss EPOCH: [607|1000], validation loss: [0.3112024627625942], AE loss: [0.14130506780929863], TF loss: [0.1698973961174488]\n",
      "Training loss EPOCH: [608|1000], training loss: [0.47023283410817385], AE loss: [0.2627127873711288], TF loss: [0.20752004603855312] took 29.001038789749146\n",
      "Validation loss EPOCH: [608|1000], validation loss: [0.3120091902092099], AE loss: [0.1411358560435474], TF loss: [0.1708733355626464]\n",
      "Training loss EPOCH: [609|1000], training loss: [0.465495090931654], AE loss: [0.25791177758947015], TF loss: [0.20758331520482898] took 31.587910413742065\n",
      "Validation loss EPOCH: [609|1000], validation loss: [0.31079062074422836], AE loss: [0.14127830090001225], TF loss: [0.16951231891289353]\n",
      "Training loss EPOCH: [610|1000], training loss: [0.46664534881711006], AE loss: [0.25898976856842637], TF loss: [0.20765557908453047] took 27.279601335525513\n",
      "Validation loss EPOCH: [610|1000], validation loss: [0.31109498627483845], AE loss: [0.14095828775316477], TF loss: [0.17013669665902853]\n",
      "Training loss EPOCH: [611|1000], training loss: [0.4652268593199551], AE loss: [0.2576252440921962], TF loss: [0.20760161988437176] took 28.646372318267822\n",
      "Validation loss EPOCH: [611|1000], validation loss: [0.31173074059188366], AE loss: [0.141520157456398], TF loss: [0.17021058406680822]\n",
      "Training loss EPOCH: [612|1000], training loss: [0.47043214505538344], AE loss: [0.26277795527130365], TF loss: [0.20765418861992657] took 30.793104648590088\n",
      "Validation loss EPOCH: [612|1000], validation loss: [0.3109615631401539], AE loss: [0.14079976500943303], TF loss: [0.17016179906204343]\n",
      "Training loss EPOCH: [613|1000], training loss: [0.46790901059284806], AE loss: [0.2603340852074325], TF loss: [0.207574927713722] took 26.439244031906128\n",
      "Validation loss EPOCH: [613|1000], validation loss: [0.3115357207134366], AE loss: [0.14125824347138405], TF loss: [0.17027747724205256]\n",
      "Training loss EPOCH: [614|1000], training loss: [0.4754707948304713], AE loss: [0.2679723787587136], TF loss: [0.20749841700308025] took 24.91314125061035\n",
      "Validation loss EPOCH: [614|1000], validation loss: [0.31026738602668047], AE loss: [0.1406012016814202], TF loss: [0.16966618737205863]\n",
      "Training loss EPOCH: [615|1000], training loss: [0.4648548373952508], AE loss: [0.2572896759957075], TF loss: [0.2075651630293578] took 27.404256582260132\n",
      "Validation loss EPOCH: [615|1000], validation loss: [0.3109013130888343], AE loss: [0.1409430920612067], TF loss: [0.16995822452008724]\n",
      "Training loss EPOCH: [616|1000], training loss: [0.4665974681265652], AE loss: [0.25924690067768097], TF loss: [0.20735056698322296] took 28.396154165267944\n",
      "Validation loss EPOCH: [616|1000], validation loss: [0.310658966191113], AE loss: [0.14117177901789546], TF loss: [0.16948718903586268]\n",
      "Training loss EPOCH: [617|1000], training loss: [0.46828833874315023], AE loss: [0.26071319938637316], TF loss: [0.2075751421507448] took 29.355555534362793\n",
      "Validation loss EPOCH: [617|1000], validation loss: [0.3113518925383687], AE loss: [0.1407288450282067], TF loss: [0.17062305146828294]\n",
      "Training loss EPOCH: [618|1000], training loss: [0.4659653645940125], AE loss: [0.2586097060702741], TF loss: [0.20735565875656903] took 27.42604088783264\n",
      "Validation loss EPOCH: [618|1000], validation loss: [0.31120993569493294], AE loss: [0.14108162629418075], TF loss: [0.17012831149622798]\n",
      "Training loss EPOCH: [619|1000], training loss: [0.46525201573967934], AE loss: [0.2577782613225281], TF loss: [0.20747375511564314] took 28.57779097557068\n",
      "Validation loss EPOCH: [619|1000], validation loss: [0.3109580911695957], AE loss: [0.1413492343854159], TF loss: [0.16960885701701045]\n",
      "Training loss EPOCH: [620|1000], training loss: [0.46863091876730323], AE loss: [0.26122830528765917], TF loss: [0.2074026104528457] took 23.6346116065979\n",
      "Validation loss EPOCH: [620|1000], validation loss: [0.31175874918699265], AE loss: [0.1411523623391986], TF loss: [0.17060638777911663]\n",
      "Training loss EPOCH: [621|1000], training loss: [0.46407361421734095], AE loss: [0.2567831831984222], TF loss: [0.20729043195024133] took 29.006033897399902\n",
      "Validation loss EPOCH: [621|1000], validation loss: [0.31115979701280594], AE loss: [0.14110043086111546], TF loss: [0.17005936428904533]\n",
      "Training loss EPOCH: [622|1000], training loss: [0.4649062044918537], AE loss: [0.25749083585105836], TF loss: [0.2074153705034405] took 30.03366732597351\n",
      "Validation loss EPOCH: [622|1000], validation loss: [0.31180810928344727], AE loss: [0.14132683025673032], TF loss: [0.17048128275200725]\n",
      "Training loss EPOCH: [623|1000], training loss: [0.4694869560189545], AE loss: [0.2620788549538702], TF loss: [0.2074081003665924] took 25.559823036193848\n",
      "Validation loss EPOCH: [623|1000], validation loss: [0.3110453747212887], AE loss: [0.14010124118067324], TF loss: [0.17094413610175252]\n",
      "Training loss EPOCH: [624|1000], training loss: [0.4676452944986522], AE loss: [0.2601540805771947], TF loss: [0.20749121555127203] took 27.153070211410522\n",
      "Validation loss EPOCH: [624|1000], validation loss: [0.3113812431693077], AE loss: [0.1412679385393858], TF loss: [0.1701133050955832]\n",
      "Training loss EPOCH: [625|1000], training loss: [0.4638476390391588], AE loss: [0.25662048789672554], TF loss: [0.20722715114243329] took 25.432389497756958\n",
      "Validation loss EPOCH: [625|1000], validation loss: [0.3116661570966244], AE loss: [0.14115322940051556], TF loss: [0.17051293328404427]\n",
      "Training loss EPOCH: [626|1000], training loss: [0.46501604560762644], AE loss: [0.2574854262638837], TF loss: [0.20753061887808144] took 25.92775058746338\n",
      "Validation loss EPOCH: [626|1000], validation loss: [0.3120070304721594], AE loss: [0.14147809147834778], TF loss: [0.17052893992513418]\n",
      "Training loss EPOCH: [627|1000], training loss: [0.46557599771767855], AE loss: [0.2583354702219367], TF loss: [0.2072405272629112] took 27.067323684692383\n",
      "Validation loss EPOCH: [627|1000], validation loss: [0.3115809289738536], AE loss: [0.14124983828514814], TF loss: [0.1703310920856893]\n",
      "Training loss EPOCH: [628|1000], training loss: [0.46397768519818783], AE loss: [0.25665874569676816], TF loss: [0.20731893950141966] took 24.468042850494385\n",
      "Validation loss EPOCH: [628|1000], validation loss: [0.3122047884389758], AE loss: [0.14148765266872942], TF loss: [0.17071713646873832]\n",
      "Training loss EPOCH: [629|1000], training loss: [0.47191674541682005], AE loss: [0.2645441456697881], TF loss: [0.20737260137684643] took 26.11649250984192\n",
      "Validation loss EPOCH: [629|1000], validation loss: [0.31214360799640417], AE loss: [0.14099748386070132], TF loss: [0.171146125998348]\n",
      "Training loss EPOCH: [630|1000], training loss: [0.47215026430785656], AE loss: [0.26486109802499413], TF loss: [0.20728916442021728] took 27.283387899398804\n",
      "Validation loss EPOCH: [630|1000], validation loss: [0.31096510868519545], AE loss: [0.14085111767053604], TF loss: [0.17011399241164327]\n",
      "Training loss EPOCH: [631|1000], training loss: [0.4657826432958245], AE loss: [0.2585213726852089], TF loss: [0.20726127084344625] took 30.319108724594116\n",
      "Validation loss EPOCH: [631|1000], validation loss: [0.31189912650734186], AE loss: [0.14127818238921463], TF loss: [0.17062094155699015]\n",
      "Training loss EPOCH: [632|1000], training loss: [0.466964740306139], AE loss: [0.25964858289808035], TF loss: [0.2073161567095667] took 24.20990014076233\n",
      "Validation loss EPOCH: [632|1000], validation loss: [0.3119317898526788], AE loss: [0.14139991765841842], TF loss: [0.1705318703316152]\n",
      "Training loss EPOCH: [633|1000], training loss: [0.4645555536262691], AE loss: [0.25720095564611256], TF loss: [0.2073545977473259] took 26.17551302909851\n",
      "Validation loss EPOCH: [633|1000], validation loss: [0.3116919919848442], AE loss: [0.14108042884618044], TF loss: [0.17061156267300248]\n",
      "Training loss EPOCH: [634|1000], training loss: [0.46594557352364063], AE loss: [0.2587044769898057], TF loss: [0.20724109699949622] took 28.272956609725952\n",
      "Validation loss EPOCH: [634|1000], validation loss: [0.3110007159411907], AE loss: [0.14067479246295989], TF loss: [0.17032592231407762]\n",
      "Training loss EPOCH: [635|1000], training loss: [0.46681245556101203], AE loss: [0.2592657033819705], TF loss: [0.2075467521790415] took 27.620176076889038\n",
      "Validation loss EPOCH: [635|1000], validation loss: [0.31150601152330637], AE loss: [0.14134378894232213], TF loss: [0.17016222281381488]\n",
      "Training loss EPOCH: [636|1000], training loss: [0.46365730511024594], AE loss: [0.2565752756781876], TF loss: [0.20708202826790512] took 25.7039053440094\n",
      "Validation loss EPOCH: [636|1000], validation loss: [0.31142961140722036], AE loss: [0.1411210340447724], TF loss: [0.17030857922509313]\n",
      "Training loss EPOCH: [637|1000], training loss: [0.466217827051878], AE loss: [0.2589423574972898], TF loss: [0.20727546978741884] took 29.100205421447754\n",
      "Validation loss EPOCH: [637|1000], validation loss: [0.3121686754748225], AE loss: [0.14132147561758757], TF loss: [0.17084720265120268]\n",
      "Training loss EPOCH: [638|1000], training loss: [0.4659087476320565], AE loss: [0.25869542988948524], TF loss: [0.20721331797540188] took 26.512086868286133\n",
      "Validation loss EPOCH: [638|1000], validation loss: [0.31167725939303637], AE loss: [0.14183160522952676], TF loss: [0.1698456541635096]\n",
      "Training loss EPOCH: [639|1000], training loss: [0.4661945244297385], AE loss: [0.25882728211581707], TF loss: [0.20736724277958274] took 25.220350742340088\n",
      "Validation loss EPOCH: [639|1000], validation loss: [0.31162714678794146], AE loss: [0.14136105705983937], TF loss: [0.17026608856394887]\n",
      "Training loss EPOCH: [640|1000], training loss: [0.4630627571605146], AE loss: [0.2557607749477029], TF loss: [0.20730198314413428] took 26.52353835105896\n",
      "Validation loss EPOCH: [640|1000], validation loss: [0.31089456751942635], AE loss: [0.14139592717401683], TF loss: [0.16949864150956273]\n",
      "Training loss EPOCH: [641|1000], training loss: [0.4646924785338342], AE loss: [0.2574129025451839], TF loss: [0.20727957552298903] took 24.184934854507446\n",
      "Validation loss EPOCH: [641|1000], validation loss: [0.31173095013946295], AE loss: [0.1414212086237967], TF loss: [0.17030974244698882]\n",
      "Training loss EPOCH: [642|1000], training loss: [0.47071134205907583], AE loss: [0.26350557105615735], TF loss: [0.20720577146857977] took 26.540822505950928\n",
      "Validation loss EPOCH: [642|1000], validation loss: [0.3122341763228178], AE loss: [0.14163630176335573], TF loss: [0.1705978773534298]\n",
      "Training loss EPOCH: [643|1000], training loss: [0.46661070408299565], AE loss: [0.25940394890494645], TF loss: [0.20720675284974277] took 27.525585174560547\n",
      "Validation loss EPOCH: [643|1000], validation loss: [0.31086009461432695], AE loss: [0.14129107957705855], TF loss: [0.16956901736557484]\n",
      "Training loss EPOCH: [644|1000], training loss: [0.47001329297199845], AE loss: [0.2627558836247772], TF loss: [0.20725741190835834] took 29.39929723739624\n",
      "Validation loss EPOCH: [644|1000], validation loss: [0.31153787951916456], AE loss: [0.1410221578553319], TF loss: [0.17051572632044554]\n",
      "Training loss EPOCH: [645|1000], training loss: [0.4652301692403853], AE loss: [0.2580954311415553], TF loss: [0.2071347392629832] took 29.198974609375\n",
      "Validation loss EPOCH: [645|1000], validation loss: [0.3123055072501302], AE loss: [0.1417371309362352], TF loss: [0.17056837677955627]\n",
      "Training loss EPOCH: [646|1000], training loss: [0.4642378445714712], AE loss: [0.2569788168184459], TF loss: [0.20725902658887208] took 27.037317752838135\n",
      "Validation loss EPOCH: [646|1000], validation loss: [0.3111817631870508], AE loss: [0.14134940225630999], TF loss: [0.16983236046507955]\n",
      "Training loss EPOCH: [647|1000], training loss: [0.46599739138036966], AE loss: [0.25874204305000603], TF loss: [0.20725534786470234] took 31.36203932762146\n",
      "Validation loss EPOCH: [647|1000], validation loss: [0.31272018048912287], AE loss: [0.14167098165489733], TF loss: [0.1710491981357336]\n",
      "Training loss EPOCH: [648|1000], training loss: [0.4629433359950781], AE loss: [0.2558726577553898], TF loss: [0.207070677774027] took 25.6290180683136\n",
      "Validation loss EPOCH: [648|1000], validation loss: [0.311584890820086], AE loss: [0.141349887708202], TF loss: [0.17023500287905335]\n",
      "Training loss EPOCH: [649|1000], training loss: [0.4682462872005999], AE loss: [0.26090330071747303], TF loss: [0.20734298508614302] took 27.791552305221558\n",
      "Validation loss EPOCH: [649|1000], validation loss: [0.31201982498168945], AE loss: [0.1416461574845016], TF loss: [0.17037366703152657]\n",
      "Training loss EPOCH: [650|1000], training loss: [0.4669292992912233], AE loss: [0.25980147533118725], TF loss: [0.2071278253570199] took 31.800994634628296\n",
      "Validation loss EPOCH: [650|1000], validation loss: [0.3117571026086807], AE loss: [0.14137514610774815], TF loss: [0.17038195673376322]\n",
      "Training loss EPOCH: [651|1000], training loss: [0.4639990380965173], AE loss: [0.2569171153008938], TF loss: [0.20708192139863968] took 28.177302598953247\n",
      "Validation loss EPOCH: [651|1000], validation loss: [0.3122273376211524], AE loss: [0.14123017061501741], TF loss: [0.17099716886878014]\n",
      "Training loss EPOCH: [652|1000], training loss: [0.46369335148483515], AE loss: [0.2564968045335263], TF loss: [0.20719654695130885] took 23.48490881919861\n",
      "Validation loss EPOCH: [652|1000], validation loss: [0.3119596755132079], AE loss: [0.14150904468260705], TF loss: [0.1704506310634315]\n",
      "Training loss EPOCH: [653|1000], training loss: [0.4621994378976524], AE loss: [0.2552755563519895], TF loss: [0.2069238794501871] took 25.901716470718384\n",
      "Validation loss EPOCH: [653|1000], validation loss: [0.3111868994310498], AE loss: [0.14187209215015173], TF loss: [0.16931480634957552]\n",
      "Training loss EPOCH: [654|1000], training loss: [0.4667253461666405], AE loss: [0.2598018981516361], TF loss: [0.20692344894632697] took 27.204816579818726\n",
      "Validation loss EPOCH: [654|1000], validation loss: [0.3121157567948103], AE loss: [0.14140479150228202], TF loss: [0.17071096505969763]\n",
      "Training loss EPOCH: [655|1000], training loss: [0.4633925026282668], AE loss: [0.2561895758844912], TF loss: [0.20720292767509818] took 27.029140949249268\n",
      "Validation loss EPOCH: [655|1000], validation loss: [0.3110499521717429], AE loss: [0.14135548891499639], TF loss: [0.16969446325674653]\n",
      "Training loss EPOCH: [656|1000], training loss: [0.46484437584877014], AE loss: [0.2577189572621137], TF loss: [0.2071254183538258] took 30.111526489257812\n",
      "Validation loss EPOCH: [656|1000], validation loss: [0.31068777944892645], AE loss: [0.14117054478265345], TF loss: [0.16951723396778107]\n",
      "Training loss EPOCH: [657|1000], training loss: [0.4638656643219292], AE loss: [0.25689425482414663], TF loss: [0.2069714074023068] took 24.60064148902893\n",
      "Validation loss EPOCH: [657|1000], validation loss: [0.31218019779771566], AE loss: [0.14150515315122902], TF loss: [0.1706750439479947]\n",
      "Training loss EPOCH: [658|1000], training loss: [0.46219383692368865], AE loss: [0.2551822201348841], TF loss: [0.20701161632314324] took 23.38415002822876\n",
      "Validation loss EPOCH: [658|1000], validation loss: [0.31212963443249464], AE loss: [0.1414765203371644], TF loss: [0.1706531122326851]\n",
      "Training loss EPOCH: [659|1000], training loss: [0.4692043489776552], AE loss: [0.2623134385794401], TF loss: [0.20689091202802956] took 24.936989307403564\n",
      "Validation loss EPOCH: [659|1000], validation loss: [0.31144522968679667], AE loss: [0.14134410303086042], TF loss: [0.1701011280529201]\n",
      "Training loss EPOCH: [660|1000], training loss: [0.46628282964229584], AE loss: [0.25908880843780935], TF loss: [0.2071940212044865] took 26.836325645446777\n",
      "Validation loss EPOCH: [660|1000], validation loss: [0.31136370077729225], AE loss: [0.14123373292386532], TF loss: [0.17012996785342693]\n",
      "Training loss EPOCH: [661|1000], training loss: [0.4669094579294324], AE loss: [0.25969550595618784], TF loss: [0.20721395406872034] took 30.69571590423584\n",
      "Validation loss EPOCH: [661|1000], validation loss: [0.31092657055705786], AE loss: [0.13993150042369962], TF loss: [0.17099507013335824]\n",
      "Training loss EPOCH: [662|1000], training loss: [0.4699339047074318], AE loss: [0.26275374204851687], TF loss: [0.20718016219325364] took 25.441447973251343\n",
      "Validation loss EPOCH: [662|1000], validation loss: [0.3116712151095271], AE loss: [0.14131302642636], TF loss: [0.17035818845033646]\n",
      "Training loss EPOCH: [663|1000], training loss: [0.46366904536262155], AE loss: [0.2565371145028621], TF loss: [0.20713193155825138] took 29.99188232421875\n",
      "Validation loss EPOCH: [663|1000], validation loss: [0.31192182656377554], AE loss: [0.14146181079559028], TF loss: [0.17046001553535461]\n",
      "Training loss EPOCH: [664|1000], training loss: [0.46490804059430957], AE loss: [0.257821001810953], TF loss: [0.2070870369207114] took 28.042543172836304\n",
      "Validation loss EPOCH: [664|1000], validation loss: [0.3122522868216038], AE loss: [0.14168933243490756], TF loss: [0.1705629569478333]\n",
      "Training loss EPOCH: [665|1000], training loss: [0.463752721901983], AE loss: [0.2565668155439198], TF loss: [0.20718590752221644] took 31.063377380371094\n",
      "Validation loss EPOCH: [665|1000], validation loss: [0.31136250775307417], AE loss: [0.1415831025224179], TF loss: [0.16977940872311592]\n",
      "Training loss EPOCH: [666|1000], training loss: [0.46281339740380645], AE loss: [0.256019490538165], TF loss: [0.2067939075641334] took 25.50504446029663\n",
      "Validation loss EPOCH: [666|1000], validation loss: [0.31238185428082943], AE loss: [0.14160532574169338], TF loss: [0.1707765287719667]\n",
      "Training loss EPOCH: [667|1000], training loss: [0.46269392035901546], AE loss: [0.2558337012305856], TF loss: [0.20686022168956697] took 23.947332620620728\n",
      "Validation loss EPOCH: [667|1000], validation loss: [0.3114898903295398], AE loss: [0.14155810023657978], TF loss: [0.16993178706616163]\n",
      "Training loss EPOCH: [668|1000], training loss: [0.4662124919705093], AE loss: [0.25919276126660407], TF loss: [0.20701972930692136] took 28.737727880477905\n",
      "Validation loss EPOCH: [668|1000], validation loss: [0.31192174553871155], AE loss: [0.14135698042809963], TF loss: [0.17056476883590221]\n",
      "Training loss EPOCH: [669|1000], training loss: [0.46202890342101455], AE loss: [0.2549854468088597], TF loss: [0.2070434580091387] took 28.068275690078735\n",
      "Validation loss EPOCH: [669|1000], validation loss: [0.31179292034357786], AE loss: [0.14162393985316157], TF loss: [0.17016898142173886]\n",
      "Training loss EPOCH: [670|1000], training loss: [0.4651065790094435], AE loss: [0.2580475003924221], TF loss: [0.20705907861702144] took 27.455769777297974\n",
      "Validation loss EPOCH: [670|1000], validation loss: [0.3122771978378296], AE loss: [0.14145872183144093], TF loss: [0.17081847367808223]\n",
      "Training loss EPOCH: [671|1000], training loss: [0.4646431030705571], AE loss: [0.2574764359742403], TF loss: [0.2071666659321636] took 30.681220293045044\n",
      "Validation loss EPOCH: [671|1000], validation loss: [0.31354791298508644], AE loss: [0.14145739166997373], TF loss: [0.1720905234105885]\n",
      "Training loss EPOCH: [672|1000], training loss: [0.46270843455567956], AE loss: [0.25580148259177804], TF loss: [0.20690695219673216] took 23.925666570663452\n",
      "Validation loss EPOCH: [672|1000], validation loss: [0.3113103061914444], AE loss: [0.1415359629318118], TF loss: [0.16977434000000358]\n",
      "Training loss EPOCH: [673|1000], training loss: [0.46404038928449154], AE loss: [0.25728570437058806], TF loss: [0.20675468700937927] took 27.09512495994568\n",
      "Validation loss EPOCH: [673|1000], validation loss: [0.31152784917503595], AE loss: [0.1411813364829868], TF loss: [0.17034651013091207]\n",
      "Training loss EPOCH: [674|1000], training loss: [0.46108978847041726], AE loss: [0.25423397636041045], TF loss: [0.20685580954886973] took 26.259352445602417\n",
      "Validation loss EPOCH: [674|1000], validation loss: [0.31214063707739115], AE loss: [0.14166462537832558], TF loss: [0.17047601006925106]\n",
      "Training loss EPOCH: [675|1000], training loss: [0.4699363708496094], AE loss: [0.2629947839304805], TF loss: [0.20694158342666924] took 30.595951080322266\n",
      "Validation loss EPOCH: [675|1000], validation loss: [0.3120740195736289], AE loss: [0.141443713568151], TF loss: [0.17063030181452632]\n",
      "Training loss EPOCH: [676|1000], training loss: [0.46695455722510815], AE loss: [0.26002734969370067], TF loss: [0.20692720566876233] took 28.192289113998413\n",
      "Validation loss EPOCH: [676|1000], validation loss: [0.31185713317245245], AE loss: [0.14137391769327223], TF loss: [0.17048321524634957]\n",
      "Training loss EPOCH: [677|1000], training loss: [0.46437320252880454], AE loss: [0.25736430124379694], TF loss: [0.20700889988802373] took 30.70460057258606\n",
      "Validation loss EPOCH: [677|1000], validation loss: [0.31254309695214033], AE loss: [0.14194418140687048], TF loss: [0.17059891810640693]\n",
      "Training loss EPOCH: [678|1000], training loss: [0.4663188373669982], AE loss: [0.2594844338018447], TF loss: [0.20683440566062927] took 22.50536036491394\n",
      "Validation loss EPOCH: [678|1000], validation loss: [0.31211212649941444], AE loss: [0.14145039673894644], TF loss: [0.17066172696650028]\n",
      "Training loss EPOCH: [679|1000], training loss: [0.4637907389551401], AE loss: [0.2569050984457135], TF loss: [0.2068856388796121] took 23.64480686187744\n",
      "Validation loss EPOCH: [679|1000], validation loss: [0.31197383999824524], AE loss: [0.14146162359975278], TF loss: [0.17051221570000052]\n",
      "Training loss EPOCH: [680|1000], training loss: [0.46863689459860325], AE loss: [0.2620010774116963], TF loss: [0.20663581253029406] took 26.0367431640625\n",
      "Validation loss EPOCH: [680|1000], validation loss: [0.3105706935748458], AE loss: [0.1401862078346312], TF loss: [0.1703844852745533]\n",
      "Training loss EPOCH: [681|1000], training loss: [0.46504787215963006], AE loss: [0.25828825775533915], TF loss: [0.2067596153356135] took 26.792714595794678\n",
      "Validation loss EPOCH: [681|1000], validation loss: [0.31113211158663034], AE loss: [0.1414090497419238], TF loss: [0.16972306231036782]\n",
      "Training loss EPOCH: [682|1000], training loss: [0.46677188389003277], AE loss: [0.25991297676227987], TF loss: [0.2068589066620916] took 33.5705783367157\n",
      "Validation loss EPOCH: [682|1000], validation loss: [0.31205212604254484], AE loss: [0.14100827206857502], TF loss: [0.17104385467246175]\n",
      "Training loss EPOCH: [683|1000], training loss: [0.46278395550325513], AE loss: [0.25589128979481757], TF loss: [0.206892664777115] took 29.68411159515381\n",
      "Validation loss EPOCH: [683|1000], validation loss: [0.31227010767906904], AE loss: [0.14191710273735225], TF loss: [0.17035300564020872]\n",
      "Training loss EPOCH: [684|1000], training loss: [0.4615679127164185], AE loss: [0.25475547346286476], TF loss: [0.20681243971921504] took 32.46874499320984\n",
      "Validation loss EPOCH: [684|1000], validation loss: [0.31187385506927967], AE loss: [0.14175316831097007], TF loss: [0.1701206867583096]\n",
      "Training loss EPOCH: [685|1000], training loss: [0.4663197146728635], AE loss: [0.2596086310222745], TF loss: [0.20671108574606478] took 34.68684983253479\n",
      "Validation loss EPOCH: [685|1000], validation loss: [0.3118789792060852], AE loss: [0.14153598807752132], TF loss: [0.17034299252554774]\n",
      "Training loss EPOCH: [686|1000], training loss: [0.4642381281591952], AE loss: [0.25730642094276845], TF loss: [0.20693170558661222] took 31.367088556289673\n",
      "Validation loss EPOCH: [686|1000], validation loss: [0.312666580080986], AE loss: [0.14198071043938398], TF loss: [0.17068586824461818]\n",
      "Training loss EPOCH: [687|1000], training loss: [0.462302072905004], AE loss: [0.2555715749040246], TF loss: [0.20673049963079393] took 33.323333740234375\n",
      "Validation loss EPOCH: [687|1000], validation loss: [0.31212727073580027], AE loss: [0.14170052716508508], TF loss: [0.17042674450203776]\n",
      "Training loss EPOCH: [688|1000], training loss: [0.46582888858392835], AE loss: [0.25885946652852], TF loss: [0.20696942135691643] took 33.528021812438965\n",
      "Validation loss EPOCH: [688|1000], validation loss: [0.3123651100322604], AE loss: [0.14211510797031224], TF loss: [0.17025000229477882]\n",
      "Training loss EPOCH: [689|1000], training loss: [0.4605952207930386], AE loss: [0.25384829891845584], TF loss: [0.2067469225730747] took 33.8553831577301\n",
      "Validation loss EPOCH: [689|1000], validation loss: [0.31331877410411835], AE loss: [0.1422345326282084], TF loss: [0.1710842400789261]\n",
      "Training loss EPOCH: [690|1000], training loss: [0.46379293920472264], AE loss: [0.25707223103381693], TF loss: [0.20672071096487343] took 34.0778603553772\n",
      "Validation loss EPOCH: [690|1000], validation loss: [0.3123936802148819], AE loss: [0.14188941498287022], TF loss: [0.17050426732748747]\n",
      "Training loss EPOCH: [691|1000], training loss: [0.464344663079828], AE loss: [0.2574284679722041], TF loss: [0.20691619534045458] took 31.05575656890869\n",
      "Validation loss EPOCH: [691|1000], validation loss: [0.3124752324074507], AE loss: [0.1416876243893057], TF loss: [0.1707876087166369]\n",
      "Training loss EPOCH: [692|1000], training loss: [0.4629232343286276], AE loss: [0.25608823844231665], TF loss: [0.20683499379083514] took 32.25559210777283\n",
      "Validation loss EPOCH: [692|1000], validation loss: [0.3117405418306589], AE loss: [0.14175350521691144], TF loss: [0.16998703638091683]\n",
      "Training loss EPOCH: [693|1000], training loss: [0.4658124749548733], AE loss: [0.2590035500470549], TF loss: [0.2068089246749878] took 32.985471963882446\n",
      "Validation loss EPOCH: [693|1000], validation loss: [0.3116768402978778], AE loss: [0.14131305390037596], TF loss: [0.17036378756165504]\n",
      "Training loss EPOCH: [694|1000], training loss: [0.4625105168670416], AE loss: [0.2557659351732582], TF loss: [0.2067445816937834] took 26.867297649383545\n",
      "Validation loss EPOCH: [694|1000], validation loss: [0.31207428127527237], AE loss: [0.14170412626117468], TF loss: [0.17037015315145254]\n",
      "Training loss EPOCH: [695|1000], training loss: [0.4660204933024943], AE loss: [0.25922988587990403], TF loss: [0.20679060742259026] took 31.003106117248535\n",
      "Validation loss EPOCH: [695|1000], validation loss: [0.3115063952282071], AE loss: [0.14124336605891585], TF loss: [0.17026303289458156]\n",
      "Training loss EPOCH: [696|1000], training loss: [0.46048028534278274], AE loss: [0.2539241260383278], TF loss: [0.20655616000294685] took 32.81100416183472\n",
      "Validation loss EPOCH: [696|1000], validation loss: [0.3125952109694481], AE loss: [0.14206380071118474], TF loss: [0.17053140932694077]\n",
      "Training loss EPOCH: [697|1000], training loss: [0.46136943995952606], AE loss: [0.25471672299318016], TF loss: [0.20665271556936204] took 33.45923733711243\n",
      "Validation loss EPOCH: [697|1000], validation loss: [0.3121985401958227], AE loss: [0.14176470530219376], TF loss: [0.17043383372947574]\n",
      "Training loss EPOCH: [698|1000], training loss: [0.4675291357561946], AE loss: [0.2607283622492105], TF loss: [0.20680077280849218] took 32.23392152786255\n",
      "Validation loss EPOCH: [698|1000], validation loss: [0.3124675378203392], AE loss: [0.14178109262138605], TF loss: [0.170686446595937]\n",
      "Training loss EPOCH: [699|1000], training loss: [0.46080535277724266], AE loss: [0.2539023451972753], TF loss: [0.20690301060676575] took 32.079448223114014\n",
      "Validation loss EPOCH: [699|1000], validation loss: [0.31257213186472654], AE loss: [0.14203517837449908], TF loss: [0.17053695116192102]\n",
      "Training loss EPOCH: [700|1000], training loss: [0.4627660755068064], AE loss: [0.25611513829790056], TF loss: [0.20665093581192195] took 35.394707918167114\n",
      "Validation loss EPOCH: [700|1000], validation loss: [0.31062226463109255], AE loss: [0.14143453701399267], TF loss: [0.16918772365897894]\n",
      "Training loss EPOCH: [701|1000], training loss: [0.4653522497974336], AE loss: [0.25885737990029156], TF loss: [0.20649487059563398] took 29.72869610786438\n",
      "Validation loss EPOCH: [701|1000], validation loss: [0.3121003732085228], AE loss: [0.141583927674219], TF loss: [0.17051644809544086]\n",
      "Training loss EPOCH: [702|1000], training loss: [0.46292969351634383], AE loss: [0.25641952245496213], TF loss: [0.20651016989722848] took 34.20600724220276\n",
      "Validation loss EPOCH: [702|1000], validation loss: [0.3130298722535372], AE loss: [0.14195007435046136], TF loss: [0.17107979906722903]\n",
      "Training loss EPOCH: [703|1000], training loss: [0.4606434884481132], AE loss: [0.25407024566084146], TF loss: [0.2065732441842556] took 33.76760721206665\n",
      "Validation loss EPOCH: [703|1000], validation loss: [0.31223688554018736], AE loss: [0.1416261533740908], TF loss: [0.17061073379591107]\n",
      "Training loss EPOCH: [704|1000], training loss: [0.4619331047870219], AE loss: [0.25525024230591953], TF loss: [0.20668286108411849] took 33.615610122680664\n",
      "Validation loss EPOCH: [704|1000], validation loss: [0.3124156314879656], AE loss: [0.14162679202854633], TF loss: [0.1707888413220644]\n",
      "Training loss EPOCH: [705|1000], training loss: [0.4614767315797508], AE loss: [0.25482725724577904], TF loss: [0.20664947456680238] took 32.961241722106934\n",
      "Validation loss EPOCH: [705|1000], validation loss: [0.3116834191605449], AE loss: [0.14198213210329413], TF loss: [0.16970128705725074]\n",
      "Training loss EPOCH: [706|1000], training loss: [0.46707748156040907], AE loss: [0.26023423089645803], TF loss: [0.20684325066395104] took 27.327693462371826\n",
      "Validation loss EPOCH: [706|1000], validation loss: [0.310877176001668], AE loss: [0.1412955462001264], TF loss: [0.16958162747323513]\n",
      "Training loss EPOCH: [707|1000], training loss: [0.4657763368450105], AE loss: [0.2589283043053001], TF loss: [0.2068480341695249] took 30.64935302734375\n",
      "Validation loss EPOCH: [707|1000], validation loss: [0.31257285084575415], AE loss: [0.14161719987168908], TF loss: [0.17095565237104893]\n",
      "Training loss EPOCH: [708|1000], training loss: [0.4612531722523272], AE loss: [0.25459165102802217], TF loss: [0.20666152122430503] took 33.650561809539795\n",
      "Validation loss EPOCH: [708|1000], validation loss: [0.3135246578603983], AE loss: [0.1422537483740598], TF loss: [0.171270911116153]\n",
      "Training loss EPOCH: [709|1000], training loss: [0.45998772932216525], AE loss: [0.25327963032759726], TF loss: [0.20670809922739863] took 33.70134234428406\n",
      "Validation loss EPOCH: [709|1000], validation loss: [0.3133070347830653], AE loss: [0.14206997421570122], TF loss: [0.17123706173151731]\n",
      "Training loss EPOCH: [710|1000], training loss: [0.46257547568529844], AE loss: [0.2559068170376122], TF loss: [0.2066686579491943] took 32.23951697349548\n",
      "Validation loss EPOCH: [710|1000], validation loss: [0.31283481419086456], AE loss: [0.14209297578781843], TF loss: [0.17074183793738484]\n",
      "Training loss EPOCH: [711|1000], training loss: [0.461418769787997], AE loss: [0.25475445855408907], TF loss: [0.2066643110010773] took 36.06994986534119\n",
      "Validation loss EPOCH: [711|1000], validation loss: [0.31198407895863056], AE loss: [0.14164176327176392], TF loss: [0.17034231591969728]\n",
      "Training loss EPOCH: [712|1000], training loss: [0.4612280633300543], AE loss: [0.25473204511217773], TF loss: [0.20649601891636848] took 31.14892601966858\n",
      "Validation loss EPOCH: [712|1000], validation loss: [0.3130228975787759], AE loss: [0.14223354775458574], TF loss: [0.17078934516757727]\n",
      "Training loss EPOCH: [713|1000], training loss: [0.4660536851733923], AE loss: [0.25951265380717814], TF loss: [0.20654103346168995] took 33.23526096343994\n",
      "Validation loss EPOCH: [713|1000], validation loss: [0.3109839800745249], AE loss: [0.14076973893679678], TF loss: [0.17021424509584904]\n",
      "Training loss EPOCH: [714|1000], training loss: [0.4638027776964009], AE loss: [0.2571196062490344], TF loss: [0.20668317284435034] took 30.577945709228516\n",
      "Validation loss EPOCH: [714|1000], validation loss: [0.3131289929151535], AE loss: [0.1420548283495009], TF loss: [0.17107416922226548]\n",
      "Training loss EPOCH: [715|1000], training loss: [0.45963163999840617], AE loss: [0.2529462440870702], TF loss: [0.20668539684265852] took 34.414090156555176\n",
      "Validation loss EPOCH: [715|1000], validation loss: [0.31282697059214115], AE loss: [0.1421001658309251], TF loss: [0.1707268077880144]\n",
      "Training loss EPOCH: [716|1000], training loss: [0.4669379545375705], AE loss: [0.26025234814733267], TF loss: [0.20668560592457652] took 29.706074476242065\n",
      "Validation loss EPOCH: [716|1000], validation loss: [0.3109726160764694], AE loss: [0.1414645325858146], TF loss: [0.1695080790668726]\n",
      "Training loss EPOCH: [717|1000], training loss: [0.4594216081313789], AE loss: [0.25286829588003457], TF loss: [0.20655331178568304] took 28.342252016067505\n",
      "Validation loss EPOCH: [717|1000], validation loss: [0.3122211880981922], AE loss: [0.1420448434073478], TF loss: [0.17017634259536862]\n",
      "Training loss EPOCH: [718|1000], training loss: [0.4613507860340178], AE loss: [0.2547718519344926], TF loss: [0.20657893479801714] took 32.045092821121216\n",
      "Validation loss EPOCH: [718|1000], validation loss: [0.3121660379692912], AE loss: [0.14192173164337873], TF loss: [0.1702443091198802]\n",
      "Training loss EPOCH: [719|1000], training loss: [0.466772030107677], AE loss: [0.2604363919235766], TF loss: [0.20633563701994717] took 35.2331109046936\n",
      "Validation loss EPOCH: [719|1000], validation loss: [0.3124481290578842], AE loss: [0.14167831279337406], TF loss: [0.17076981626451015]\n",
      "Training loss EPOCH: [720|1000], training loss: [0.4641577899456024], AE loss: [0.25757718202658], TF loss: [0.20658060582354665] took 33.73800539970398\n",
      "Validation loss EPOCH: [720|1000], validation loss: [0.3121187137439847], AE loss: [0.1414257944561541], TF loss: [0.17069291789084673]\n",
      "Training loss EPOCH: [721|1000], training loss: [0.46077924221754074], AE loss: [0.25419483915902674], TF loss: [0.20658440166153014] took 31.999678373336792\n",
      "Validation loss EPOCH: [721|1000], validation loss: [0.3135239388793707], AE loss: [0.14252878911793232], TF loss: [0.17099514789879322]\n",
      "Training loss EPOCH: [722|1000], training loss: [0.4597459938377142], AE loss: [0.2533611203543842], TF loss: [0.20638487418182194] took 33.22277855873108\n",
      "Validation loss EPOCH: [722|1000], validation loss: [0.3126604314893484], AE loss: [0.14231318840757012], TF loss: [0.1703472463414073]\n",
      "Training loss EPOCH: [723|1000], training loss: [0.4677935093641281], AE loss: [0.2613212135620415], TF loss: [0.2064722974319011] took 33.76797962188721\n",
      "Validation loss EPOCH: [723|1000], validation loss: [0.3119747005403042], AE loss: [0.14191137719899416], TF loss: [0.1700633247382939]\n",
      "Training loss EPOCH: [724|1000], training loss: [0.4596071681007743], AE loss: [0.25321808154694736], TF loss: [0.20638908469118178] took 31.475279092788696\n",
      "Validation loss EPOCH: [724|1000], validation loss: [0.31290596071630716], AE loss: [0.141613443614915], TF loss: [0.17129251919686794]\n",
      "Training loss EPOCH: [725|1000], training loss: [0.46000591246411204], AE loss: [0.2534468637313694], TF loss: [0.2065590478014201] took 31.92181968688965\n",
      "Validation loss EPOCH: [725|1000], validation loss: [0.3121742196381092], AE loss: [0.14184972643852234], TF loss: [0.17032448947429657]\n",
      "Training loss EPOCH: [726|1000], training loss: [0.46123107662424445], AE loss: [0.25491114472970366], TF loss: [0.20631993422284722] took 31.891135692596436\n",
      "Validation loss EPOCH: [726|1000], validation loss: [0.31250923685729504], AE loss: [0.14194953651167452], TF loss: [0.170559698715806]\n",
      "Training loss EPOCH: [727|1000], training loss: [0.46220050379633904], AE loss: [0.25569369178265333], TF loss: [0.20650681271217763] took 31.077067136764526\n",
      "Validation loss EPOCH: [727|1000], validation loss: [0.3132875869050622], AE loss: [0.14255723962560296], TF loss: [0.1707303486764431]\n",
      "Training loss EPOCH: [728|1000], training loss: [0.4641377544030547], AE loss: [0.25754736363887787], TF loss: [0.20659039076417685] took 31.016809701919556\n",
      "Validation loss EPOCH: [728|1000], validation loss: [0.31133758276700974], AE loss: [0.14159766002558172], TF loss: [0.1697399253025651]\n",
      "Training loss EPOCH: [729|1000], training loss: [0.4654292445629835], AE loss: [0.2589163100346923], TF loss: [0.20651293569244444] took 31.92744517326355\n",
      "Validation loss EPOCH: [729|1000], validation loss: [0.31222251895815134], AE loss: [0.1417639555875212], TF loss: [0.17045856220647693]\n",
      "Training loss EPOCH: [730|1000], training loss: [0.4622219502925873], AE loss: [0.2555996240116656], TF loss: [0.20662232697941363] took 30.89142155647278\n",
      "Validation loss EPOCH: [730|1000], validation loss: [0.31221022363752127], AE loss: [0.14177142665721476], TF loss: [0.17043879721313715]\n",
      "Training loss EPOCH: [731|1000], training loss: [0.46244233194738626], AE loss: [0.25600749580189586], TF loss: [0.20643483684398234] took 32.24729013442993\n",
      "Validation loss EPOCH: [731|1000], validation loss: [0.312787807546556], AE loss: [0.1417213857639581], TF loss: [0.17106642248108983]\n",
      "Training loss EPOCH: [732|1000], training loss: [0.461540705524385], AE loss: [0.2552705709822476], TF loss: [0.2062701340764761] took 32.43974804878235\n",
      "Validation loss EPOCH: [732|1000], validation loss: [0.31282139103859663], AE loss: [0.14213968580588698], TF loss: [0.17068170150741935]\n",
      "Training loss EPOCH: [733|1000], training loss: [0.4617007742635906], AE loss: [0.25543822324834764], TF loss: [0.20626255217939615] took 32.92242622375488\n",
      "Validation loss EPOCH: [733|1000], validation loss: [0.31198916491121054], AE loss: [0.1414156393148005], TF loss: [0.17057352466508746]\n",
      "Training loss EPOCH: [734|1000], training loss: [0.4602676294744015], AE loss: [0.25374314677901566], TF loss: [0.20652448548935354] took 30.015355348587036\n",
      "Validation loss EPOCH: [734|1000], validation loss: [0.312257363460958], AE loss: [0.14211398782208562], TF loss: [0.17014337424188852]\n",
      "Training loss EPOCH: [735|1000], training loss: [0.45937265176326036], AE loss: [0.2529405190143734], TF loss: [0.20643213135190308] took 33.52692794799805\n",
      "Validation loss EPOCH: [735|1000], validation loss: [0.31289255805313587], AE loss: [0.14217458735220134], TF loss: [0.17071796767413616]\n",
      "Training loss EPOCH: [736|1000], training loss: [0.4608197812922299], AE loss: [0.25443171081133187], TF loss: [0.20638807117938995] took 22.685036420822144\n",
      "Validation loss EPOCH: [736|1000], validation loss: [0.3124590739607811], AE loss: [0.1420749262906611], TF loss: [0.17038414673879743]\n",
      "Training loss EPOCH: [737|1000], training loss: [0.4589822464622557], AE loss: [0.2525137693155557], TF loss: [0.20646847621537745] took 28.19224762916565\n",
      "Validation loss EPOCH: [737|1000], validation loss: [0.3123399242758751], AE loss: [0.1419132798910141], TF loss: [0.170426644384861]\n",
      "Training loss EPOCH: [738|1000], training loss: [0.46274349745362997], AE loss: [0.256524957716465], TF loss: [0.20621854159981012] took 27.694546699523926\n",
      "Validation loss EPOCH: [738|1000], validation loss: [0.3127143234014511], AE loss: [0.14164892910048366], TF loss: [0.17106539057567716]\n",
      "Training loss EPOCH: [739|1000], training loss: [0.45981068443506956], AE loss: [0.25335870822891593], TF loss: [0.206451975973323] took 32.8355188369751\n",
      "Validation loss EPOCH: [739|1000], validation loss: [0.3137867162004113], AE loss: [0.14241897594183683], TF loss: [0.17136773699894547]\n",
      "Training loss EPOCH: [740|1000], training loss: [0.4602080141194165], AE loss: [0.2537138743791729], TF loss: [0.2064941395074129] took 24.775838136672974\n",
      "Validation loss EPOCH: [740|1000], validation loss: [0.3133959285914898], AE loss: [0.1424162546172738], TF loss: [0.17097967583686113]\n",
      "Training loss EPOCH: [741|1000], training loss: [0.46380660450086], AE loss: [0.25747033837251365], TF loss: [0.2063362654298544] took 27.260672569274902\n",
      "Validation loss EPOCH: [741|1000], validation loss: [0.31206893268972635], AE loss: [0.1416173055768013], TF loss: [0.17045162338763475]\n",
      "Training loss EPOCH: [742|1000], training loss: [0.46393914660438895], AE loss: [0.2575090897735208], TF loss: [0.20643005962483585] took 26.29314136505127\n",
      "Validation loss EPOCH: [742|1000], validation loss: [0.311697531491518], AE loss: [0.1417611592914909], TF loss: [0.1699363742955029]\n",
      "Training loss EPOCH: [743|1000], training loss: [0.45911161368712783], AE loss: [0.25257428642362356], TF loss: [0.20653732679784298] took 30.11140251159668\n",
      "Validation loss EPOCH: [743|1000], validation loss: [0.31219118647277355], AE loss: [0.14230786100961268], TF loss: [0.16988332476466894]\n",
      "Training loss EPOCH: [744|1000], training loss: [0.461056936532259], AE loss: [0.2545950124040246], TF loss: [0.20646192389540374] took 25.730367422103882\n",
      "Validation loss EPOCH: [744|1000], validation loss: [0.31170686427503824], AE loss: [0.1421529061626643], TF loss: [0.16955395648255944]\n",
      "Training loss EPOCH: [745|1000], training loss: [0.46044711535796523], AE loss: [0.25413582590408623], TF loss: [0.2063112915493548] took 27.685045957565308\n",
      "Validation loss EPOCH: [745|1000], validation loss: [0.3130457978695631], AE loss: [0.1425292412750423], TF loss: [0.17051655426621437]\n",
      "Training loss EPOCH: [746|1000], training loss: [0.45928235398605466], AE loss: [0.25287775276228786], TF loss: [0.20640460448339581] took 26.83983016014099\n",
      "Validation loss EPOCH: [746|1000], validation loss: [0.31305922009050846], AE loss: [0.14229529281146824], TF loss: [0.17076392797753215]\n",
      "Training loss EPOCH: [747|1000], training loss: [0.46163206174969673], AE loss: [0.2552579347975552], TF loss: [0.2063741299789399] took 23.779926776885986\n",
      "Validation loss EPOCH: [747|1000], validation loss: [0.3119830237701535], AE loss: [0.1412047550547868], TF loss: [0.17077826941385865]\n",
      "Training loss EPOCH: [748|1000], training loss: [0.46249427972361445], AE loss: [0.25616047508083284], TF loss: [0.20633380394428968] took 27.8667049407959\n",
      "Validation loss EPOCH: [748|1000], validation loss: [0.31328344717621803], AE loss: [0.14234325243160129], TF loss: [0.17094019381329417]\n",
      "Training loss EPOCH: [749|1000], training loss: [0.46087825996801257], AE loss: [0.2545478062238544], TF loss: [0.20633045420981944] took 25.843891859054565\n",
      "Validation loss EPOCH: [749|1000], validation loss: [0.31254344526678324], AE loss: [0.14228423917666078], TF loss: [0.17025920655578375]\n",
      "Training loss EPOCH: [750|1000], training loss: [0.45996182737872005], AE loss: [0.25372662697918713], TF loss: [0.20623519970104098] took 28.49604368209839\n",
      "Validation loss EPOCH: [750|1000], validation loss: [0.3129459982737899], AE loss: [0.1422694695647806], TF loss: [0.1706765266135335]\n",
      "Training loss EPOCH: [751|1000], training loss: [0.4578255647793412], AE loss: [0.25156379537656903], TF loss: [0.2062617684714496] took 30.358383178710938\n",
      "Validation loss EPOCH: [751|1000], validation loss: [0.3132703276351094], AE loss: [0.14210573304444551], TF loss: [0.17116459645330906]\n",
      "Training loss EPOCH: [752|1000], training loss: [0.4603297272697091], AE loss: [0.25421714736148715], TF loss: [0.20611257827840745] took 27.348362684249878\n",
      "Validation loss EPOCH: [752|1000], validation loss: [0.3139581996947527], AE loss: [0.14242825051769614], TF loss: [0.1715299505740404]\n",
      "Training loss EPOCH: [753|1000], training loss: [0.46126570785418153], AE loss: [0.25480814231559634], TF loss: [0.20645756274461746] took 26.746505737304688\n",
      "Validation loss EPOCH: [753|1000], validation loss: [0.31309088226407766], AE loss: [0.14224850269965827], TF loss: [0.1708423807285726]\n",
      "Training loss EPOCH: [754|1000], training loss: [0.45827465457841754], AE loss: [0.25191120081581175], TF loss: [0.2063634532969445] took 27.110225677490234\n",
      "Validation loss EPOCH: [754|1000], validation loss: [0.31318789906799793], AE loss: [0.14245720976032317], TF loss: [0.17073068814352155]\n",
      "Training loss EPOCH: [755|1000], training loss: [0.46090018190443516], AE loss: [0.25448699574917555], TF loss: [0.20641318545676768] took 17.391236782073975\n",
      "Validation loss EPOCH: [755|1000], validation loss: [0.3130715359002352], AE loss: [0.14234865549951792], TF loss: [0.17072287993505597]\n",
      "Training loss EPOCH: [756|1000], training loss: [0.46058367285877466], AE loss: [0.25422459631226957], TF loss: [0.2063590781763196] took 27.90052890777588\n",
      "Validation loss EPOCH: [756|1000], validation loss: [0.3132839733734727], AE loss: [0.14225443149916828], TF loss: [0.17102954490110278]\n",
      "Training loss EPOCH: [757|1000], training loss: [0.46134262811392546], AE loss: [0.2550634378567338], TF loss: [0.20627919025719166] took 30.020073652267456\n",
      "Validation loss EPOCH: [757|1000], validation loss: [0.31286293361335993], AE loss: [0.14182986598461866], TF loss: [0.17103306762874126]\n",
      "Training loss EPOCH: [758|1000], training loss: [0.46008876664564013], AE loss: [0.2538740518502891], TF loss: [0.2062147157266736] took 27.568034887313843\n",
      "Validation loss EPOCH: [758|1000], validation loss: [0.3126883842051029], AE loss: [0.1423037052154541], TF loss: [0.1703846794553101]\n",
      "Training loss EPOCH: [759|1000], training loss: [0.45898225205019116], AE loss: [0.25299095176160336], TF loss: [0.20599130191840231] took 31.060312747955322\n",
      "Validation loss EPOCH: [759|1000], validation loss: [0.312866042368114], AE loss: [0.14214577758684754], TF loss: [0.1707202666439116]\n",
      "Training loss EPOCH: [760|1000], training loss: [0.4630084913223982], AE loss: [0.25680481223389506], TF loss: [0.20620367699302733] took 29.444264888763428\n",
      "Validation loss EPOCH: [760|1000], validation loss: [0.3132680458948016], AE loss: [0.14206090080551803], TF loss: [0.1712071462534368]\n",
      "Training loss EPOCH: [761|1000], training loss: [0.4594446485862136], AE loss: [0.2532844494562596], TF loss: [0.2061601986642927] took 26.79264259338379\n",
      "Validation loss EPOCH: [761|1000], validation loss: [0.31341034453362226], AE loss: [0.1426781713962555], TF loss: [0.1707321717403829]\n",
      "Training loss EPOCH: [762|1000], training loss: [0.45771171525120735], AE loss: [0.25161197036504745], TF loss: [0.20609974209219217] took 26.85098886489868\n",
      "Validation loss EPOCH: [762|1000], validation loss: [0.31261427234858274], AE loss: [0.1427044034935534], TF loss: [0.16990987164899707]\n",
      "Training loss EPOCH: [763|1000], training loss: [0.4601454851217568], AE loss: [0.2538935572374612], TF loss: [0.20625192788429558] took 28.840160608291626\n",
      "Validation loss EPOCH: [763|1000], validation loss: [0.31382524501532316], AE loss: [0.14312934502959251], TF loss: [0.17069590091705322]\n",
      "Training loss EPOCH: [764|1000], training loss: [0.4658965333364904], AE loss: [0.2596285413019359], TF loss: [0.20626799506135285] took 26.62190341949463\n",
      "Validation loss EPOCH: [764|1000], validation loss: [0.3129229908809066], AE loss: [0.14198148343712091], TF loss: [0.17094150371849537]\n",
      "Training loss EPOCH: [765|1000], training loss: [0.4620414939709008], AE loss: [0.2556076862383634], TF loss: [0.20643380866385996] took 24.693007230758667\n",
      "Validation loss EPOCH: [765|1000], validation loss: [0.3128711236640811], AE loss: [0.14192625624127686], TF loss: [0.1709448671899736]\n",
      "Training loss EPOCH: [766|1000], training loss: [0.4583697132766247], AE loss: [0.2522992016747594], TF loss: [0.2060705132316798] took 25.035504579544067\n",
      "Validation loss EPOCH: [766|1000], validation loss: [0.3117589522153139], AE loss: [0.14215149846859276], TF loss: [0.16960745817050338]\n",
      "Training loss EPOCH: [767|1000], training loss: [0.45932271191850305], AE loss: [0.2531121913343668], TF loss: [0.20621052011847496] took 26.926098108291626\n",
      "Validation loss EPOCH: [767|1000], validation loss: [0.31282278895378113], AE loss: [0.14248678274452686], TF loss: [0.17033600574359298]\n",
      "Training loss EPOCH: [768|1000], training loss: [0.4618591475300491], AE loss: [0.2556708299089223], TF loss: [0.2061883183196187] took 27.68719172477722\n",
      "Validation loss EPOCH: [768|1000], validation loss: [0.3132209740579128], AE loss: [0.142533119302243], TF loss: [0.17068785708397627]\n",
      "Training loss EPOCH: [769|1000], training loss: [0.45806140545755625], AE loss: [0.2519309720955789], TF loss: [0.20613043010234833] took 27.8543541431427\n",
      "Validation loss EPOCH: [769|1000], validation loss: [0.3120060823857784], AE loss: [0.14212897373363376], TF loss: [0.16987711284309626]\n",
      "Training loss EPOCH: [770|1000], training loss: [0.460755858104676], AE loss: [0.25467178598046303], TF loss: [0.2060840732883662] took 19.94028401374817\n",
      "Validation loss EPOCH: [770|1000], validation loss: [0.3126739701256156], AE loss: [0.14237357093952596], TF loss: [0.170300398953259]\n",
      "Training loss EPOCH: [771|1000], training loss: [0.45739306369796395], AE loss: [0.25123076420277357], TF loss: [0.20616229833103716] took 25.917280673980713\n",
      "Validation loss EPOCH: [771|1000], validation loss: [0.31347736809402704], AE loss: [0.14231431973166764], TF loss: [0.17116304766386747]\n",
      "Training loss EPOCH: [772|1000], training loss: [0.45931539544835687], AE loss: [0.25326900905929506], TF loss: [0.2060463863890618] took 27.868462085723877\n",
      "Validation loss EPOCH: [772|1000], validation loss: [0.3146586688235402], AE loss: [0.14301296370103955], TF loss: [0.17164570558816195]\n",
      "Training loss EPOCH: [773|1000], training loss: [0.4636576557531953], AE loss: [0.2572958366945386], TF loss: [0.20636182045564055] took 29.52974772453308\n",
      "Validation loss EPOCH: [773|1000], validation loss: [0.3129121717065573], AE loss: [0.1419935803860426], TF loss: [0.17091858759522438]\n",
      "Training loss EPOCH: [774|1000], training loss: [0.46105233300477266], AE loss: [0.2548190273810178], TF loss: [0.20623330515809357] took 29.1643488407135\n",
      "Validation loss EPOCH: [774|1000], validation loss: [0.31260482408106327], AE loss: [0.14194954372942448], TF loss: [0.1706552803516388]\n",
      "Training loss EPOCH: [775|1000], training loss: [0.46097898855805397], AE loss: [0.2548895631916821], TF loss: [0.20608942466787994] took 22.176131010055542\n",
      "Validation loss EPOCH: [775|1000], validation loss: [0.3133948212489486], AE loss: [0.14165966655127704], TF loss: [0.17173515539616346]\n",
      "Training loss EPOCH: [776|1000], training loss: [0.4578248136676848], AE loss: [0.25161321531049907], TF loss: [0.2062116013839841] took 32.480979204177856\n",
      "Validation loss EPOCH: [776|1000], validation loss: [0.3127915319055319], AE loss: [0.1423427378758788], TF loss: [0.1704487963579595]\n",
      "Training loss EPOCH: [777|1000], training loss: [0.45676813181489706], AE loss: [0.250643047504127], TF loss: [0.20612508244812489] took 27.505290031433105\n",
      "Validation loss EPOCH: [777|1000], validation loss: [0.31364484038203955], AE loss: [0.14294248539954424], TF loss: [0.17070236010476947]\n",
      "Training loss EPOCH: [778|1000], training loss: [0.46057512797415257], AE loss: [0.2545293353032321], TF loss: [0.2060457926709205] took 30.786085605621338\n",
      "Validation loss EPOCH: [778|1000], validation loss: [0.31222482211887836], AE loss: [0.14188803220167756], TF loss: [0.17033678852021694]\n",
      "Training loss EPOCH: [779|1000], training loss: [0.46223574550822377], AE loss: [0.25635028746910393], TF loss: [0.20588545710779727] took 28.61004114151001\n",
      "Validation loss EPOCH: [779|1000], validation loss: [0.31329988595098257], AE loss: [0.14242173545062542], TF loss: [0.17087815050035715]\n",
      "Training loss EPOCH: [780|1000], training loss: [0.45861034374684095], AE loss: [0.2525043261703104], TF loss: [0.20610601548105478] took 28.503774642944336\n",
      "Validation loss EPOCH: [780|1000], validation loss: [0.3130619414150715], AE loss: [0.1428231995087117], TF loss: [0.170238739810884]\n",
      "Training loss EPOCH: [781|1000], training loss: [0.4583642086945474], AE loss: [0.2522206457797438], TF loss: [0.2061435617506504] took 25.592253923416138\n",
      "Validation loss EPOCH: [781|1000], validation loss: [0.3133799880743027], AE loss: [0.1423916204366833], TF loss: [0.1709883688017726]\n",
      "Training loss EPOCH: [782|1000], training loss: [0.46026144409552217], AE loss: [0.25407707574777305], TF loss: [0.20618437067605555] took 25.942784070968628\n",
      "Validation loss EPOCH: [782|1000], validation loss: [0.31304823607206345], AE loss: [0.14249743008986115], TF loss: [0.17055080784484744]\n",
      "Training loss EPOCH: [783|1000], training loss: [0.4584890971891582], AE loss: [0.2523104050196707], TF loss: [0.2061786912381649] took 27.859926462173462\n",
      "Validation loss EPOCH: [783|1000], validation loss: [0.3126355195418], AE loss: [0.14239318389445543], TF loss: [0.17024233331903815]\n",
      "Training loss EPOCH: [784|1000], training loss: [0.4608698170632124], AE loss: [0.2547783008776605], TF loss: [0.20609151502139866] took 28.96419644355774\n",
      "Validation loss EPOCH: [784|1000], validation loss: [0.31186947133392096], AE loss: [0.14117716602049768], TF loss: [0.17069230461493134]\n",
      "Training loss EPOCH: [785|1000], training loss: [0.45882643293589354], AE loss: [0.2527500798460096], TF loss: [0.20607635471969843] took 28.84174156188965\n",
      "Validation loss EPOCH: [785|1000], validation loss: [0.3128176750615239], AE loss: [0.14255554764531553], TF loss: [0.17026212578639388]\n",
      "Training loss EPOCH: [786|1000], training loss: [0.4609921583905816], AE loss: [0.25498478417284787], TF loss: [0.2060073735192418] took 25.454637050628662\n",
      "Validation loss EPOCH: [786|1000], validation loss: [0.31354164611548185], AE loss: [0.14281984162516892], TF loss: [0.17072180612012744]\n",
      "Training loss EPOCH: [787|1000], training loss: [0.4628269369713962], AE loss: [0.256827007047832], TF loss: [0.2059999315533787] took 23.70832109451294\n",
      "Validation loss EPOCH: [787|1000], validation loss: [0.31295608170330524], AE loss: [0.14204025687649846], TF loss: [0.17091582529246807]\n",
      "Training loss EPOCH: [788|1000], training loss: [0.4568813042715192], AE loss: [0.25084116333164275], TF loss: [0.20604014047421515] took 25.643322944641113\n",
      "Validation loss EPOCH: [788|1000], validation loss: [0.3128598900511861], AE loss: [0.1423974414356053], TF loss: [0.17046244721859694]\n",
      "Training loss EPOCH: [789|1000], training loss: [0.4646225399337709], AE loss: [0.2583828307688236], TF loss: [0.20623970846645534] took 22.59279203414917\n",
      "Validation loss EPOCH: [789|1000], validation loss: [0.3129653884097934], AE loss: [0.1419282655697316], TF loss: [0.17103712167590857]\n",
      "Training loss EPOCH: [790|1000], training loss: [0.4595821048133075], AE loss: [0.2534753321669996], TF loss: [0.20610677357763052] took 29.357275247573853\n",
      "Validation loss EPOCH: [790|1000], validation loss: [0.31251149624586105], AE loss: [0.14196269470266998], TF loss: [0.17054879805073142]\n",
      "Training loss EPOCH: [791|1000], training loss: [0.4624025053344667], AE loss: [0.2561624846421182], TF loss: [0.2062400197610259] took 29.09938335418701\n",
      "Validation loss EPOCH: [791|1000], validation loss: [0.31269596982747316], AE loss: [0.14196248608641326], TF loss: [0.17073348769918084]\n",
      "Training loss EPOCH: [792|1000], training loss: [0.45980715192854404], AE loss: [0.2538050781004131], TF loss: [0.20600207359530032] took 25.947073221206665\n",
      "Validation loss EPOCH: [792|1000], validation loss: [0.3117457125335932], AE loss: [0.14177074399776757], TF loss: [0.16997496969997883]\n",
      "Training loss EPOCH: [793|1000], training loss: [0.45962606789544225], AE loss: [0.25350927049294114], TF loss: [0.20611679600551724] took 28.31302046775818\n",
      "Validation loss EPOCH: [793|1000], validation loss: [0.3117847675457597], AE loss: [0.14234720636159182], TF loss: [0.16943756071850657]\n",
      "Training loss EPOCH: [794|1000], training loss: [0.45567994890734553], AE loss: [0.2496704903896898], TF loss: [0.2060094540938735] took 27.148767709732056\n",
      "Validation loss EPOCH: [794|1000], validation loss: [0.3131459327414632], AE loss: [0.14271803200244904], TF loss: [0.17042790120467544]\n",
      "Training loss EPOCH: [795|1000], training loss: [0.4637822015210986], AE loss: [0.2577377681154758], TF loss: [0.20604443433694541] took 28.25368332862854\n",
      "Validation loss EPOCH: [795|1000], validation loss: [0.31260661967098713], AE loss: [0.14229539828374982], TF loss: [0.17031122231855989]\n",
      "Training loss EPOCH: [796|1000], training loss: [0.4602668439038098], AE loss: [0.254300779895857], TF loss: [0.20596606354229152] took 28.163262128829956\n",
      "Validation loss EPOCH: [796|1000], validation loss: [0.31202623154968023], AE loss: [0.14233384770341218], TF loss: [0.16969238454476]\n",
      "Training loss EPOCH: [797|1000], training loss: [0.4573289561085403], AE loss: [0.2514537023380399], TF loss: [0.205875254701823] took 27.430708408355713\n",
      "Validation loss EPOCH: [797|1000], validation loss: [0.31325835175812244], AE loss: [0.14287785883061588], TF loss: [0.1703804931603372]\n",
      "Training loss EPOCH: [798|1000], training loss: [0.45585416117683053], AE loss: [0.24989941576495767], TF loss: [0.2059547444805503] took 19.851055145263672\n",
      "Validation loss EPOCH: [798|1000], validation loss: [0.3133844304829836], AE loss: [0.14278656849637628], TF loss: [0.17059786012396216]\n",
      "Training loss EPOCH: [799|1000], training loss: [0.45702011324465275], AE loss: [0.25097421929240227], TF loss: [0.20604589232243598] took 26.345279455184937\n",
      "Validation loss EPOCH: [799|1000], validation loss: [0.3132236786186695], AE loss: [0.14240462239831686], TF loss: [0.1708190548233688]\n",
      "Training loss EPOCH: [800|1000], training loss: [0.4638625686056912], AE loss: [0.257921559503302], TF loss: [0.20594100723974407] took 27.24799084663391\n",
      "Validation loss EPOCH: [800|1000], validation loss: [0.3138884948566556], AE loss: [0.142182583687827], TF loss: [0.1717059100046754]\n",
      "Training loss EPOCH: [801|1000], training loss: [0.45926369493827224], AE loss: [0.2532738542649895], TF loss: [0.20598983927629888] took 27.957638263702393\n",
      "Validation loss EPOCH: [801|1000], validation loss: [0.3134483424946666], AE loss: [0.14270496787503362], TF loss: [0.17074337182566524]\n",
      "Training loss EPOCH: [802|1000], training loss: [0.45750334998592734], AE loss: [0.2514064465649426], TF loss: [0.2060969031881541] took 27.717171669006348\n",
      "Validation loss EPOCH: [802|1000], validation loss: [0.3134744381532073], AE loss: [0.14273512363433838], TF loss: [0.17073931405320764]\n",
      "Training loss EPOCH: [803|1000], training loss: [0.4655674584209919], AE loss: [0.2595796147361398], TF loss: [0.20598784228786826] took 26.144474506378174\n",
      "Validation loss EPOCH: [803|1000], validation loss: [0.3132925797253847], AE loss: [0.14241782296448946], TF loss: [0.17087475396692753]\n",
      "Training loss EPOCH: [804|1000], training loss: [0.4607931235805154], AE loss: [0.25484527717344463], TF loss: [0.20594784524291754] took 23.891031503677368\n",
      "Validation loss EPOCH: [804|1000], validation loss: [0.3132432149723172], AE loss: [0.14250355283729732], TF loss: [0.17073966469615698]\n",
      "Training loss EPOCH: [805|1000], training loss: [0.45600763661786914], AE loss: [0.25008021178655326], TF loss: [0.20592742296867073] took 29.416353225708008\n",
      "Validation loss EPOCH: [805|1000], validation loss: [0.3137547317892313], AE loss: [0.14269566116854548], TF loss: [0.1710590715520084]\n",
      "Training loss EPOCH: [806|1000], training loss: [0.45795146748423576], AE loss: [0.25200889399275184], TF loss: [0.20594257418997586] took 31.22396230697632\n",
      "Validation loss EPOCH: [806|1000], validation loss: [0.31410382967442274], AE loss: [0.14269879111088812], TF loss: [0.1714050373993814]\n",
      "Training loss EPOCH: [807|1000], training loss: [0.45564542384818196], AE loss: [0.24977370142005384], TF loss: [0.2058717212639749] took 29.978516817092896\n",
      "Validation loss EPOCH: [807|1000], validation loss: [0.31365327164530754], AE loss: [0.14300594991073012], TF loss: [0.17064732126891613]\n",
      "Training loss EPOCH: [808|1000], training loss: [0.45659545389935374], AE loss: [0.25076434877701104], TF loss: [0.20583110535517335] took 24.79456877708435\n",
      "Validation loss EPOCH: [808|1000], validation loss: [0.31279594730585814], AE loss: [0.1423574488144368], TF loss: [0.17043849918991327]\n",
      "Training loss EPOCH: [809|1000], training loss: [0.4603382358327508], AE loss: [0.2542937551625073], TF loss: [0.20604447997175157] took 23.704800128936768\n",
      "Validation loss EPOCH: [809|1000], validation loss: [0.31201488617807627], AE loss: [0.14205950358882546], TF loss: [0.16995538398623466]\n",
      "Training loss EPOCH: [810|1000], training loss: [0.4589207633398473], AE loss: [0.2530480513814837], TF loss: [0.20587271149270236] took 25.09259581565857\n",
      "Validation loss EPOCH: [810|1000], validation loss: [0.3132133409380913], AE loss: [0.1428901245817542], TF loss: [0.17032321821898222]\n",
      "Training loss EPOCH: [811|1000], training loss: [0.4569017100147903], AE loss: [0.25110732577741146], TF loss: [0.20579438633285463] took 28.32855486869812\n",
      "Validation loss EPOCH: [811|1000], validation loss: [0.3125881562009454], AE loss: [0.14237616281025112], TF loss: [0.17021199641749263]\n",
      "Training loss EPOCH: [812|1000], training loss: [0.4606430479325354], AE loss: [0.25472900038585067], TF loss: [0.20591404754668474] took 26.92329740524292\n",
      "Validation loss EPOCH: [812|1000], validation loss: [0.31271656788885593], AE loss: [0.14174814731813967], TF loss: [0.1709684212692082]\n",
      "Training loss EPOCH: [813|1000], training loss: [0.4635214149020612], AE loss: [0.25761213689111173], TF loss: [0.20590927684679627] took 31.462649822235107\n",
      "Validation loss EPOCH: [813|1000], validation loss: [0.31321722362190485], AE loss: [0.14245529100298882], TF loss: [0.1707619335502386]\n",
      "Training loss EPOCH: [814|1000], training loss: [0.4561828253790736], AE loss: [0.25024887057952583], TF loss: [0.20593395340256393] took 29.315306425094604\n",
      "Validation loss EPOCH: [814|1000], validation loss: [0.3131404584273696], AE loss: [0.1427773768082261], TF loss: [0.17036307975649834]\n",
      "Training loss EPOCH: [815|1000], training loss: [0.4649011301808059], AE loss: [0.25902619305998087], TF loss: [0.2058749368879944] took 27.852437734603882\n",
      "Validation loss EPOCH: [815|1000], validation loss: [0.3128472529351711], AE loss: [0.14151471410878003], TF loss: [0.17133253626525402]\n",
      "Training loss EPOCH: [816|1000], training loss: [0.45879053184762597], AE loss: [0.25289153517223895], TF loss: [0.20589899690821767] took 26.418009519577026\n",
      "Validation loss EPOCH: [816|1000], validation loss: [0.3136904910206795], AE loss: [0.14273687871173024], TF loss: [0.17095361137762666]\n",
      "Training loss EPOCH: [817|1000], training loss: [0.46542110992595553], AE loss: [0.2596297587733716], TF loss: [0.20579135441221297] took 27.661393642425537\n",
      "Validation loss EPOCH: [817|1000], validation loss: [0.31256670504808426], AE loss: [0.14189052139408886], TF loss: [0.1706761857494712]\n",
      "Training loss EPOCH: [818|1000], training loss: [0.46145039750263095], AE loss: [0.2556103703100234], TF loss: [0.20584002858959138] took 28.329668283462524\n",
      "Validation loss EPOCH: [818|1000], validation loss: [0.3129852693527937], AE loss: [0.14198029576800764], TF loss: [0.17100497102364898]\n",
      "Training loss EPOCH: [819|1000], training loss: [0.4554122914560139], AE loss: [0.24961887509562075], TF loss: [0.2057934170588851] took 28.12544322013855\n",
      "Validation loss EPOCH: [819|1000], validation loss: [0.3136801393702626], AE loss: [0.1424566046334803], TF loss: [0.17122353659942746]\n",
      "Training loss EPOCH: [820|1000], training loss: [0.4545837794430554], AE loss: [0.24890738585963845], TF loss: [0.2056763949804008] took 28.372697830200195\n",
      "Validation loss EPOCH: [820|1000], validation loss: [0.3138478370383382], AE loss: [0.14296258031390607], TF loss: [0.1708852555602789]\n",
      "Training loss EPOCH: [821|1000], training loss: [0.4568321304395795], AE loss: [0.2510569642763585], TF loss: [0.2057751640677452] took 27.989296913146973\n",
      "Validation loss EPOCH: [821|1000], validation loss: [0.31373406387865543], AE loss: [0.14251188724301755], TF loss: [0.17122217547148466]\n",
      "Training loss EPOCH: [822|1000], training loss: [0.45688238460570574], AE loss: [0.25094621861353517], TF loss: [0.20593616738915443] took 24.54462957382202\n",
      "Validation loss EPOCH: [822|1000], validation loss: [0.3144094105809927], AE loss: [0.1427432638593018], TF loss: [0.17166614811867476]\n",
      "Training loss EPOCH: [823|1000], training loss: [0.45710006915032864], AE loss: [0.25135400821454823], TF loss: [0.2057460634969175] took 26.616964101791382\n",
      "Validation loss EPOCH: [823|1000], validation loss: [0.3131279144436121], AE loss: [0.14297111006453633], TF loss: [0.1701568029820919]\n",
      "Training loss EPOCH: [824|1000], training loss: [0.45736232213675976], AE loss: [0.2513540955260396], TF loss: [0.20600822637788951] took 29.46070170402527\n",
      "Validation loss EPOCH: [824|1000], validation loss: [0.3140982426702976], AE loss: [0.1427501959260553], TF loss: [0.17134804371744394]\n",
      "Training loss EPOCH: [825|1000], training loss: [0.4583712690509856], AE loss: [0.25244498811662197], TF loss: [0.20592628163285553] took 29.86491370201111\n",
      "Validation loss EPOCH: [825|1000], validation loss: [0.31456571258604527], AE loss: [0.1434386339969933], TF loss: [0.1711270809173584]\n",
      "Training loss EPOCH: [826|1000], training loss: [0.45797880087047815], AE loss: [0.252074773889035], TF loss: [0.20590402511879802] took 28.299193143844604\n",
      "Validation loss EPOCH: [826|1000], validation loss: [0.3134981719776988], AE loss: [0.14251490077003837], TF loss: [0.17098326981067657]\n",
      "Training loss EPOCH: [827|1000], training loss: [0.4581111646257341], AE loss: [0.25227640802040696], TF loss: [0.20583475846797228] took 28.845035314559937\n",
      "Validation loss EPOCH: [827|1000], validation loss: [0.3133067237213254], AE loss: [0.14265536423772573], TF loss: [0.1706513618119061]\n",
      "Training loss EPOCH: [828|1000], training loss: [0.45564996963366866], AE loss: [0.24980339966714382], TF loss: [0.2058465697336942] took 28.068746328353882\n",
      "Validation loss EPOCH: [828|1000], validation loss: [0.3134314762428403], AE loss: [0.1423730431124568], TF loss: [0.1710584331303835]\n",
      "Training loss EPOCH: [829|1000], training loss: [0.45927640050649643], AE loss: [0.25339996605180204], TF loss: [0.20587643329054117] took 24.416051149368286\n",
      "Validation loss EPOCH: [829|1000], validation loss: [0.3133393358439207], AE loss: [0.14293264830484986], TF loss: [0.17040668660774827]\n",
      "Training loss EPOCH: [830|1000], training loss: [0.4609362939372659], AE loss: [0.2552019786089659], TF loss: [0.20573431882075965] took 26.85674738883972\n",
      "Validation loss EPOCH: [830|1000], validation loss: [0.31316777504980564], AE loss: [0.14175328519195318], TF loss: [0.17141448985785246]\n",
      "Training loss EPOCH: [831|1000], training loss: [0.45634884061291814], AE loss: [0.2506142775528133], TF loss: [0.20573456189595163] took 30.003621816635132\n",
      "Validation loss EPOCH: [831|1000], validation loss: [0.3131113154813647], AE loss: [0.1427201060578227], TF loss: [0.17039121082052588]\n",
      "Training loss EPOCH: [832|1000], training loss: [0.4544508229009807], AE loss: [0.24847542773932219], TF loss: [0.20597539469599724] took 32.25946927070618\n",
      "Validation loss EPOCH: [832|1000], validation loss: [0.31441778503358364], AE loss: [0.14320142520591617], TF loss: [0.17121635982766747]\n",
      "Training loss EPOCH: [833|1000], training loss: [0.45658385567367077], AE loss: [0.2509611321147531], TF loss: [0.20562272216193378] took 25.044546365737915\n",
      "Validation loss EPOCH: [833|1000], validation loss: [0.313548537902534], AE loss: [0.14278994826599956], TF loss: [0.17075859056785703]\n",
      "Training loss EPOCH: [834|1000], training loss: [0.4621008108370006], AE loss: [0.2564259939827025], TF loss: [0.20567481755279005] took 29.03531765937805\n",
      "Validation loss EPOCH: [834|1000], validation loss: [0.31346563156694174], AE loss: [0.14274164685048163], TF loss: [0.17072398262098432]\n",
      "Training loss EPOCH: [835|1000], training loss: [0.45484654139727354], AE loss: [0.24914084561169147], TF loss: [0.20570569764822721] took 27.554993152618408\n",
      "Validation loss EPOCH: [835|1000], validation loss: [0.3141484363004565], AE loss: [0.14331487310118973], TF loss: [0.17083356203511357]\n",
      "Training loss EPOCH: [836|1000], training loss: [0.4551661587320268], AE loss: [0.2494914724957198], TF loss: [0.20567468740046024] took 27.420995950698853\n",
      "Validation loss EPOCH: [836|1000], validation loss: [0.3138119066134095], AE loss: [0.14298756257630885], TF loss: [0.1708243447355926]\n",
      "Training loss EPOCH: [837|1000], training loss: [0.45916332257911563], AE loss: [0.253367830067873], TF loss: [0.20579549227841198] took 31.207659244537354\n",
      "Validation loss EPOCH: [837|1000], validation loss: [0.3147380594164133], AE loss: [0.14296286227181554], TF loss: [0.17177519388496876]\n",
      "Training loss EPOCH: [838|1000], training loss: [0.46135507384315133], AE loss: [0.25553136761300266], TF loss: [0.20582370762713253] took 28.952532052993774\n",
      "Validation loss EPOCH: [838|1000], validation loss: [0.3147800164297223], AE loss: [0.14331574155949056], TF loss: [0.17146427743136883]\n",
      "Training loss EPOCH: [839|1000], training loss: [0.45875167148187757], AE loss: [0.2529325184877962], TF loss: [0.20581915485672653] took 24.00730586051941\n",
      "Validation loss EPOCH: [839|1000], validation loss: [0.31281646993011236], AE loss: [0.1426314904820174], TF loss: [0.17018497828394175]\n",
      "Training loss EPOCH: [840|1000], training loss: [0.4553058329038322], AE loss: [0.24946729862131178], TF loss: [0.20583853544667363] took 31.53948450088501\n",
      "Validation loss EPOCH: [840|1000], validation loss: [0.31333364825695753], AE loss: [0.1427828180603683], TF loss: [0.17055083392187953]\n",
      "Training loss EPOCH: [841|1000], training loss: [0.45835932111367583], AE loss: [0.25262082531116903], TF loss: [0.20573849603533745] took 30.896430253982544\n",
      "Validation loss EPOCH: [841|1000], validation loss: [0.31328810285776854], AE loss: [0.14207762409932911], TF loss: [0.17121047899127007]\n",
      "Training loss EPOCH: [842|1000], training loss: [0.4541381513699889], AE loss: [0.24833078309893608], TF loss: [0.2058073692023754] took 24.377282857894897\n",
      "Validation loss EPOCH: [842|1000], validation loss: [0.3137016147375107], AE loss: [0.14290872123092413], TF loss: [0.17079289350658655]\n",
      "Training loss EPOCH: [843|1000], training loss: [0.4551611808128655], AE loss: [0.2496275515295565], TF loss: [0.20553363068029284] took 29.676697731018066\n",
      "Validation loss EPOCH: [843|1000], validation loss: [0.3138311207294464], AE loss: [0.14334644004702568], TF loss: [0.17048468347638845]\n",
      "Training loss EPOCH: [844|1000], training loss: [0.4575026175007224], AE loss: [0.25177069567143917], TF loss: [0.20573192182928324] took 26.75094437599182\n",
      "Validation loss EPOCH: [844|1000], validation loss: [0.3137527024373412], AE loss: [0.14276649244129658], TF loss: [0.17098621325567365]\n",
      "Training loss EPOCH: [845|1000], training loss: [0.458017461001873], AE loss: [0.25243084551766515], TF loss: [0.20558661315590143] took 23.368657112121582\n",
      "Validation loss EPOCH: [845|1000], validation loss: [0.3143744934350252], AE loss: [0.14288806961849332], TF loss: [0.17148642474785447]\n",
      "Training loss EPOCH: [846|1000], training loss: [0.46084843296557665], AE loss: [0.25505547877401114], TF loss: [0.20579295326024294] took 31.612462520599365\n",
      "Validation loss EPOCH: [846|1000], validation loss: [0.31223366130143404], AE loss: [0.14213013532571495], TF loss: [0.17010352574288845]\n",
      "Training loss EPOCH: [847|1000], training loss: [0.45793813141062856], AE loss: [0.2521795460488647], TF loss: [0.20575858396477997] took 28.423580169677734\n",
      "Validation loss EPOCH: [847|1000], validation loss: [0.3138732397928834], AE loss: [0.14317572279833257], TF loss: [0.17069751862436533]\n",
      "Training loss EPOCH: [848|1000], training loss: [0.4550571455620229], AE loss: [0.24944618390873075], TF loss: [0.20561096258461475] took 27.701345443725586\n",
      "Validation loss EPOCH: [848|1000], validation loss: [0.3134772842749953], AE loss: [0.14279762841761112], TF loss: [0.17067965446040034]\n",
      "Training loss EPOCH: [849|1000], training loss: [0.45585011364892125], AE loss: [0.2500828269403428], TF loss: [0.20576728670857847] took 25.966333150863647\n",
      "Validation loss EPOCH: [849|1000], validation loss: [0.3134670425206423], AE loss: [0.14275223552249372], TF loss: [0.17071480862796307]\n",
      "Training loss EPOCH: [850|1000], training loss: [0.4568409603089094], AE loss: [0.25115190097130835], TF loss: [0.205689060036093] took 27.32690739631653\n",
      "Validation loss EPOCH: [850|1000], validation loss: [0.313809622079134], AE loss: [0.14320355653762817], TF loss: [0.1706060660071671]\n",
      "Training loss EPOCH: [851|1000], training loss: [0.4632135112769902], AE loss: [0.25746338930912316], TF loss: [0.2057501228991896] took 30.803534746170044\n",
      "Validation loss EPOCH: [851|1000], validation loss: [0.31175743229687214], AE loss: [0.14173394488170743], TF loss: [0.1700234841555357]\n",
      "Training loss EPOCH: [852|1000], training loss: [0.45721982792019844], AE loss: [0.2515400086995214], TF loss: [0.20567981875501573] took 26.91964292526245\n",
      "Validation loss EPOCH: [852|1000], validation loss: [0.3130729887634516], AE loss: [0.14272211166098714], TF loss: [0.1703508784994483]\n",
      "Training loss EPOCH: [853|1000], training loss: [0.4578033620491624], AE loss: [0.2521984481718391], TF loss: [0.20560491573996842] took 28.958237409591675\n",
      "Validation loss EPOCH: [853|1000], validation loss: [0.31455140467733145], AE loss: [0.14286547456867993], TF loss: [0.17168593080714345]\n",
      "Training loss EPOCH: [854|1000], training loss: [0.4588043843396008], AE loss: [0.25303677818737924], TF loss: [0.2057676080148667] took 27.04099702835083\n",
      "Validation loss EPOCH: [854|1000], validation loss: [0.31360413786023855], AE loss: [0.14288110798224807], TF loss: [0.17072303220629692]\n",
      "Training loss EPOCH: [855|1000], training loss: [0.45703377248719335], AE loss: [0.2509289856534451], TF loss: [0.2061047877650708] took 30.219173908233643\n",
      "Validation loss EPOCH: [855|1000], validation loss: [0.3136605229228735], AE loss: [0.14283446897752583], TF loss: [0.1708260513842106]\n",
      "Training loss EPOCH: [856|1000], training loss: [0.4556113304570317], AE loss: [0.24982066731899977], TF loss: [0.20579066243954003] took 24.209898710250854\n",
      "Validation loss EPOCH: [856|1000], validation loss: [0.3142810733988881], AE loss: [0.143485595472157], TF loss: [0.1707954746671021]\n",
      "Training loss EPOCH: [857|1000], training loss: [0.45613406226038933], AE loss: [0.2504334496334195], TF loss: [0.20570061285980046] took 26.52252721786499\n",
      "Validation loss EPOCH: [857|1000], validation loss: [0.31404080521315336], AE loss: [0.1431104214861989], TF loss: [0.17093038326129317]\n",
      "Training loss EPOCH: [858|1000], training loss: [0.4554507462307811], AE loss: [0.24978689826093614], TF loss: [0.2056638451758772] took 31.780096769332886\n",
      "Validation loss EPOCH: [858|1000], validation loss: [0.31435559689998627], AE loss: [0.1430113003589213], TF loss: [0.17134429840371013]\n",
      "Training loss EPOCH: [859|1000], training loss: [0.45661667129024863], AE loss: [0.2508990557398647], TF loss: [0.20571761531755328] took 29.612645864486694\n",
      "Validation loss EPOCH: [859|1000], validation loss: [0.3143230201676488], AE loss: [0.14334690291434526], TF loss: [0.1709761181846261]\n",
      "Training loss EPOCH: [860|1000], training loss: [0.4643937097862363], AE loss: [0.2585610272362828], TF loss: [0.2058326832484454] took 28.499363660812378\n",
      "Validation loss EPOCH: [860|1000], validation loss: [0.31414394825696945], AE loss: [0.14248524978756905], TF loss: [0.17165869614109397]\n",
      "Training loss EPOCH: [861|1000], training loss: [0.4538722224533558], AE loss: [0.24822837533429265], TF loss: [0.20564384781755507] took 28.488605737686157\n",
      "Validation loss EPOCH: [861|1000], validation loss: [0.313652410171926], AE loss: [0.14317873097024858], TF loss: [0.17047367990016937]\n",
      "Training loss EPOCH: [862|1000], training loss: [0.45406882790848613], AE loss: [0.24848171626217663], TF loss: [0.20558711071498692] took 29.811331510543823\n",
      "Validation loss EPOCH: [862|1000], validation loss: [0.31457712687551975], AE loss: [0.14331836020573974], TF loss: [0.17125876620411873]\n",
      "Training loss EPOCH: [863|1000], training loss: [0.4565802561119199], AE loss: [0.25095139304175973], TF loss: [0.2056288616731763] took 25.97574520111084\n",
      "Validation loss EPOCH: [863|1000], validation loss: [0.31364675890654325], AE loss: [0.14248079434037209], TF loss: [0.17116596503183246]\n",
      "Training loss EPOCH: [864|1000], training loss: [0.4544074754230678], AE loss: [0.2487897351384163], TF loss: [0.20561774028465152] took 23.755828380584717\n",
      "Validation loss EPOCH: [864|1000], validation loss: [0.3137291269376874], AE loss: [0.1428775293752551], TF loss: [0.17085159802809358]\n",
      "Training loss EPOCH: [865|1000], training loss: [0.46120754908770323], AE loss: [0.25571986474096775], TF loss: [0.20548768248409033] took 29.915053367614746\n",
      "Validation loss EPOCH: [865|1000], validation loss: [0.3138706749305129], AE loss: [0.14248846820555627], TF loss: [0.1713822102174163]\n",
      "Training loss EPOCH: [866|1000], training loss: [0.45351805817335844], AE loss: [0.24802733887918293], TF loss: [0.20549071882851422] took 29.492401361465454\n",
      "Validation loss EPOCH: [866|1000], validation loss: [0.31463787890970707], AE loss: [0.1437336695380509], TF loss: [0.17090420983731747]\n",
      "Training loss EPOCH: [867|1000], training loss: [0.46080576768144965], AE loss: [0.25523110618814826], TF loss: [0.2055746610276401] took 27.889339447021484\n",
      "Validation loss EPOCH: [867|1000], validation loss: [0.3137282496318221], AE loss: [0.14297344884835184], TF loss: [0.17075479915365577]\n",
      "Training loss EPOCH: [868|1000], training loss: [0.45413665333762765], AE loss: [0.248681464465335], TF loss: [0.20545518957078457] took 28.260549545288086\n",
      "Validation loss EPOCH: [868|1000], validation loss: [0.3137606093659997], AE loss: [0.1429569039028138], TF loss: [0.17080370197072625]\n",
      "Training loss EPOCH: [869|1000], training loss: [0.4612296330742538], AE loss: [0.2556706143077463], TF loss: [0.205559017136693] took 22.215025901794434\n",
      "Validation loss EPOCH: [869|1000], validation loss: [0.31330130714923143], AE loss: [0.14259389811195433], TF loss: [0.17070741252973676]\n",
      "Training loss EPOCH: [870|1000], training loss: [0.45454308297485113], AE loss: [0.2489163305144757], TF loss: [0.20562675269320607] took 25.895634651184082\n",
      "Validation loss EPOCH: [870|1000], validation loss: [0.3139555398374796], AE loss: [0.1431860199663788], TF loss: [0.17076951963827014]\n",
      "Training loss EPOCH: [871|1000], training loss: [0.4530439148657024], AE loss: [0.24741705134510994], TF loss: [0.20562686608172953] took 26.281317710876465\n",
      "Validation loss EPOCH: [871|1000], validation loss: [0.31407711561769247], AE loss: [0.14356452878564596], TF loss: [0.17051258590072393]\n",
      "Training loss EPOCH: [872|1000], training loss: [0.45438860123977065], AE loss: [0.24879068019799888], TF loss: [0.20559791941195726] took 26.72677731513977\n",
      "Validation loss EPOCH: [872|1000], validation loss: [0.31481689121574163], AE loss: [0.1433630483224988], TF loss: [0.17145384149625897]\n",
      "Training loss EPOCH: [873|1000], training loss: [0.45514390245079994], AE loss: [0.24943688395433128], TF loss: [0.20570701966062188] took 28.142119884490967\n",
      "Validation loss EPOCH: [873|1000], validation loss: [0.3125928994268179], AE loss: [0.14263718272559345], TF loss: [0.16995571833103895]\n",
      "Training loss EPOCH: [874|1000], training loss: [0.45667486637830734], AE loss: [0.25121319317258894], TF loss: [0.20546167227439582] took 28.284557104110718\n",
      "Validation loss EPOCH: [874|1000], validation loss: [0.31443150248378515], AE loss: [0.14290273748338223], TF loss: [0.1715287659317255]\n",
      "Training loss EPOCH: [875|1000], training loss: [0.45754398172721267], AE loss: [0.2518629743717611], TF loss: [0.20568100758828223] took 31.66476583480835\n",
      "Validation loss EPOCH: [875|1000], validation loss: [0.31409451365470886], AE loss: [0.1428334778174758], TF loss: [0.17126103583723307]\n",
      "Training loss EPOCH: [876|1000], training loss: [0.455876296851784], AE loss: [0.25037259492091835], TF loss: [0.20550369913689792] took 25.845232486724854\n",
      "Validation loss EPOCH: [876|1000], validation loss: [0.31362554151564837], AE loss: [0.1431730235926807], TF loss: [0.17045252118259668]\n",
      "Training loss EPOCH: [877|1000], training loss: [0.4562357044778764], AE loss: [0.25070176972076297], TF loss: [0.20553393196314573] took 28.734343767166138\n",
      "Validation loss EPOCH: [877|1000], validation loss: [0.31305198557674885], AE loss: [0.14276591571979225], TF loss: [0.17028606962412596]\n",
      "Training loss EPOCH: [878|1000], training loss: [0.4521986488252878], AE loss: [0.246997858164832], TF loss: [0.20520078972913325] took 33.48796057701111\n",
      "Validation loss EPOCH: [878|1000], validation loss: [0.314969202503562], AE loss: [0.1432119831442833], TF loss: [0.1717572184279561]\n",
      "Training loss EPOCH: [879|1000], training loss: [0.4542847848497331], AE loss: [0.2487161688040942], TF loss: [0.2055686181411147] took 31.750319719314575\n",
      "Validation loss EPOCH: [879|1000], validation loss: [0.31337022315710783], AE loss: [0.14301929296925664], TF loss: [0.17035093111917377]\n",
      "Training loss EPOCH: [880|1000], training loss: [0.45718629006296396], AE loss: [0.2518470927607268], TF loss: [0.2053391970694065] took 28.531681299209595\n",
      "Validation loss EPOCH: [880|1000], validation loss: [0.31409810297191143], AE loss: [0.1428155256435275], TF loss: [0.1712825777940452]\n",
      "Training loss EPOCH: [881|1000], training loss: [0.45877022249624133], AE loss: [0.25322570046409965], TF loss: [0.20554452342912555] took 31.6541748046875\n",
      "Validation loss EPOCH: [881|1000], validation loss: [0.3128747511655092], AE loss: [0.14228483522310853], TF loss: [0.1705899159424007]\n",
      "Training loss EPOCH: [882|1000], training loss: [0.45415785955265164], AE loss: [0.24855665885843337], TF loss: [0.20560120162554085] took 34.11552667617798\n",
      "Validation loss EPOCH: [882|1000], validation loss: [0.31356282718479633], AE loss: [0.14317977195605636], TF loss: [0.17038305336609483]\n",
      "Training loss EPOCH: [883|1000], training loss: [0.4612076976336539], AE loss: [0.2558435923419893], TF loss: [0.20536410831846297] took 31.46503758430481\n",
      "Validation loss EPOCH: [883|1000], validation loss: [0.31376114021986723], AE loss: [0.14263373892754316], TF loss: [0.17112740315496922]\n",
      "Training loss EPOCH: [884|1000], training loss: [0.45382020343095064], AE loss: [0.24815868050791323], TF loss: [0.20566152106039226] took 28.493297576904297\n",
      "Validation loss EPOCH: [884|1000], validation loss: [0.31481595803052187], AE loss: [0.14319064561277628], TF loss: [0.1716253124177456]\n",
      "Training loss EPOCH: [885|1000], training loss: [0.4575536148622632], AE loss: [0.25229139835573733], TF loss: [0.20526221371255815] took 30.75957942008972\n",
      "Validation loss EPOCH: [885|1000], validation loss: [0.31320503633469343], AE loss: [0.14240423846058547], TF loss: [0.17080079996958375]\n",
      "Training loss EPOCH: [886|1000], training loss: [0.4539502216503024], AE loss: [0.24847634602338076], TF loss: [0.20547387469559908] took 33.62845468521118\n",
      "Validation loss EPOCH: [886|1000], validation loss: [0.3133761351928115], AE loss: [0.14294583955779672], TF loss: [0.17043029563501477]\n",
      "Training loss EPOCH: [887|1000], training loss: [0.46055154921486974], AE loss: [0.2550095017068088], TF loss: [0.20554204960353673] took 29.140443801879883\n",
      "Validation loss EPOCH: [887|1000], validation loss: [0.3136983495205641], AE loss: [0.14278602949343622], TF loss: [0.17091231793165207]\n",
      "Training loss EPOCH: [888|1000], training loss: [0.4559147856198251], AE loss: [0.2505774337332696], TF loss: [0.20533735491335392] took 28.81603980064392\n",
      "Validation loss EPOCH: [888|1000], validation loss: [0.31307578459382057], AE loss: [0.14314305479638278], TF loss: [0.16993272909894586]\n",
      "Training loss EPOCH: [889|1000], training loss: [0.4558456023223698], AE loss: [0.25029603904113173], TF loss: [0.20554956188425422] took 28.00967836380005\n",
      "Validation loss EPOCH: [889|1000], validation loss: [0.3141293600201607], AE loss: [0.14278739225119352], TF loss: [0.17134196544066072]\n",
      "Training loss EPOCH: [890|1000], training loss: [0.4520219899713993], AE loss: [0.2463972398545593], TF loss: [0.20562474941834807] took 23.863577127456665\n",
      "Validation loss EPOCH: [890|1000], validation loss: [0.3135702610015869], AE loss: [0.14315305138006806], TF loss: [0.17041720636188984]\n",
      "Training loss EPOCH: [891|1000], training loss: [0.455444005317986], AE loss: [0.24999073380604386], TF loss: [0.20545327244326472] took 28.37121605873108\n",
      "Validation loss EPOCH: [891|1000], validation loss: [0.31259037367999554], AE loss: [0.1426742235198617], TF loss: [0.16991615016013384]\n",
      "Training loss EPOCH: [892|1000], training loss: [0.452057518530637], AE loss: [0.24656354077160358], TF loss: [0.20549398032017052] took 26.389007091522217\n",
      "Validation loss EPOCH: [892|1000], validation loss: [0.3137681484222412], AE loss: [0.14317544410005212], TF loss: [0.17059270339086652]\n",
      "Training loss EPOCH: [893|1000], training loss: [0.4552814606577158], AE loss: [0.24971010396257043], TF loss: [0.20557135762646794] took 26.271445274353027\n",
      "Validation loss EPOCH: [893|1000], validation loss: [0.31438962183892727], AE loss: [0.1432544244453311], TF loss: [0.17113519925624132]\n",
      "Training loss EPOCH: [894|1000], training loss: [0.45482697430998087], AE loss: [0.24953302228823304], TF loss: [0.20529395015910268] took 29.07150936126709\n",
      "Validation loss EPOCH: [894|1000], validation loss: [0.31417995132505894], AE loss: [0.14290120010264218], TF loss: [0.17127875098958611]\n",
      "Training loss EPOCH: [895|1000], training loss: [0.45349810225889087], AE loss: [0.24811039003543556], TF loss: [0.2053877126891166] took 25.12164068222046\n",
      "Validation loss EPOCH: [895|1000], validation loss: [0.31401199009269476], AE loss: [0.14332663244567811], TF loss: [0.17068535927683115]\n",
      "Training loss EPOCH: [896|1000], training loss: [0.45786769362166524], AE loss: [0.25208550156094134], TF loss: [0.20578219136223197] took 24.68240475654602\n",
      "Validation loss EPOCH: [896|1000], validation loss: [0.314131579361856], AE loss: [0.143316957866773], TF loss: [0.17081462033092976]\n",
      "Training loss EPOCH: [897|1000], training loss: [0.4566952483728528], AE loss: [0.25107598141767085], TF loss: [0.20561926835216582] took 20.597440242767334\n",
      "Validation loss EPOCH: [897|1000], validation loss: [0.3147231750190258], AE loss: [0.14321370795369148], TF loss: [0.17150946473702788]\n",
      "Training loss EPOCH: [898|1000], training loss: [0.4548612404614687], AE loss: [0.24937462573871017], TF loss: [0.20548661588691175] took 27.971193075180054\n",
      "Validation loss EPOCH: [898|1000], validation loss: [0.31439286936074495], AE loss: [0.14303996739909053], TF loss: [0.17135290103033185]\n",
      "Training loss EPOCH: [899|1000], training loss: [0.45556362392380834], AE loss: [0.2501160877291113], TF loss: [0.20544753968715668] took 25.24135446548462\n",
      "Validation loss EPOCH: [899|1000], validation loss: [0.31448329240083694], AE loss: [0.14349710871465504], TF loss: [0.17098618391901255]\n",
      "Training loss EPOCH: [900|1000], training loss: [0.46001114696264267], AE loss: [0.2545649923849851], TF loss: [0.20544615481048822] took 30.100692987442017\n",
      "Validation loss EPOCH: [900|1000], validation loss: [0.3138962220400572], AE loss: [0.14312513591721654], TF loss: [0.17077108565717936]\n",
      "Training loss EPOCH: [901|1000], training loss: [0.4531000657007098], AE loss: [0.24769476288929582], TF loss: [0.20540530397556722] took 25.12161636352539\n",
      "Validation loss EPOCH: [901|1000], validation loss: [0.31431297585368156], AE loss: [0.142913606017828], TF loss: [0.17139936983585358]\n",
      "Training loss EPOCH: [902|1000], training loss: [0.4512901655398309], AE loss: [0.2460049802903086], TF loss: [0.20528518431819975] took 29.316627740859985\n",
      "Validation loss EPOCH: [902|1000], validation loss: [0.31395437754690647], AE loss: [0.14343725587241352], TF loss: [0.17051712097600102]\n",
      "Training loss EPOCH: [903|1000], training loss: [0.4550218638032675], AE loss: [0.2495198652613908], TF loss: [0.20550200040452182] took 29.84435486793518\n",
      "Validation loss EPOCH: [903|1000], validation loss: [0.31338376831263304], AE loss: [0.14275679271668196], TF loss: [0.17062697606161237]\n",
      "Training loss EPOCH: [904|1000], training loss: [0.46609080769121647], AE loss: [0.26053991145454347], TF loss: [0.20555089646950364] took 27.41831874847412\n",
      "Validation loss EPOCH: [904|1000], validation loss: [0.31452024448662996], AE loss: [0.14288649102672935], TF loss: [0.1716337539255619]\n",
      "Training loss EPOCH: [905|1000], training loss: [0.4516941043548286], AE loss: [0.24627185286954045], TF loss: [0.20542224985547364] took 30.38845705986023\n",
      "Validation loss EPOCH: [905|1000], validation loss: [0.3139065019786358], AE loss: [0.14302776753902435], TF loss: [0.170878735370934]\n",
      "Training loss EPOCH: [906|1000], training loss: [0.4522904916666448], AE loss: [0.24697934207506478], TF loss: [0.20531114866025746] took 29.58504581451416\n",
      "Validation loss EPOCH: [906|1000], validation loss: [0.3149162260815501], AE loss: [0.14322883915156126], TF loss: [0.17168738646432757]\n",
      "Training loss EPOCH: [907|1000], training loss: [0.4534035688266158], AE loss: [0.2480378106702119], TF loss: [0.20536575932055712] took 25.914002895355225\n",
      "Validation loss EPOCH: [907|1000], validation loss: [0.31470546033233404], AE loss: [0.14331314526498318], TF loss: [0.17139231273904443]\n",
      "Training loss EPOCH: [908|1000], training loss: [0.464225965552032], AE loss: [0.25904749031178653], TF loss: [0.20517847407609224] took 29.706896781921387\n",
      "Validation loss EPOCH: [908|1000], validation loss: [0.3138078050687909], AE loss: [0.14274990372359753], TF loss: [0.17105790274217725]\n",
      "Training loss EPOCH: [909|1000], training loss: [0.4517132407054305], AE loss: [0.24642064957879484], TF loss: [0.20529259205795825] took 26.78837275505066\n",
      "Validation loss EPOCH: [909|1000], validation loss: [0.3144714590162039], AE loss: [0.14299883833155036], TF loss: [0.17147262301295996]\n",
      "Training loss EPOCH: [910|1000], training loss: [0.45429718075320125], AE loss: [0.24891965789720416], TF loss: [0.20537752355448902] took 26.21995258331299\n",
      "Validation loss EPOCH: [910|1000], validation loss: [0.31407878175377846], AE loss: [0.14312024181708694], TF loss: [0.1709585366770625]\n",
      "Training loss EPOCH: [911|1000], training loss: [0.45320882741361856], AE loss: [0.24778172164224088], TF loss: [0.20542710460722446] took 29.64661693572998\n",
      "Validation loss EPOCH: [911|1000], validation loss: [0.3140351353213191], AE loss: [0.14291189587675035], TF loss: [0.17112323828041553]\n",
      "Training loss EPOCH: [912|1000], training loss: [0.45935913641005754], AE loss: [0.2540912216063589], TF loss: [0.20526791363954544] took 29.719294548034668\n",
      "Validation loss EPOCH: [912|1000], validation loss: [0.31466498877853155], AE loss: [0.14294525794684887], TF loss: [0.17171972943469882]\n",
      "Training loss EPOCH: [913|1000], training loss: [0.4550287229940295], AE loss: [0.24963090172968805], TF loss: [0.20539782289415598] took 27.361418962478638\n",
      "Validation loss EPOCH: [913|1000], validation loss: [0.3142118100076914], AE loss: [0.1427477253600955], TF loss: [0.17146408278495073]\n",
      "Training loss EPOCH: [914|1000], training loss: [0.46138559840619564], AE loss: [0.2559001096524298], TF loss: [0.20548549038358033] took 30.3660888671875\n",
      "Validation loss EPOCH: [914|1000], validation loss: [0.3138040276244283], AE loss: [0.14258840261027217], TF loss: [0.17121562315151095]\n",
      "Training loss EPOCH: [915|1000], training loss: [0.452518274076283], AE loss: [0.24700395530089736], TF loss: [0.20551431528292596] took 24.84408974647522\n",
      "Validation loss EPOCH: [915|1000], validation loss: [0.3132019517943263], AE loss: [0.14289069245569408], TF loss: [0.17031125957146287]\n",
      "Training loss EPOCH: [916|1000], training loss: [0.45503713143989444], AE loss: [0.24979959381744266], TF loss: [0.20523753692395985] took 27.539544105529785\n",
      "Validation loss EPOCH: [916|1000], validation loss: [0.3140649236738682], AE loss: [0.1434657177887857], TF loss: [0.17059920309111476]\n",
      "Training loss EPOCH: [917|1000], training loss: [0.4595715827308595], AE loss: [0.25425323424860835], TF loss: [0.20531835150904953] took 28.954270362854004\n",
      "Validation loss EPOCH: [917|1000], validation loss: [0.31466079596430063], AE loss: [0.1431847100611776], TF loss: [0.17147608753293753]\n",
      "Training loss EPOCH: [918|1000], training loss: [0.4509122706949711], AE loss: [0.24561154330149293], TF loss: [0.20530072739347816] took 23.066935300827026\n",
      "Validation loss EPOCH: [918|1000], validation loss: [0.31383184157311916], AE loss: [0.14304277184419334], TF loss: [0.17078906670212746]\n",
      "Training loss EPOCH: [919|1000], training loss: [0.45602396596223116], AE loss: [0.25077197211794555], TF loss: [0.20525199337862432] took 29.203571796417236\n",
      "Validation loss EPOCH: [919|1000], validation loss: [0.3132736897096038], AE loss: [0.14314000122249126], TF loss: [0.1701336894184351]\n",
      "Training loss EPOCH: [920|1000], training loss: [0.45100980810821056], AE loss: [0.24580988544039428], TF loss: [0.20519992290064692] took 25.41312026977539\n",
      "Validation loss EPOCH: [920|1000], validation loss: [0.3142656348645687], AE loss: [0.1434288900345564], TF loss: [0.17083674250170588]\n",
      "Training loss EPOCH: [921|1000], training loss: [0.45559554593637586], AE loss: [0.2501675561070442], TF loss: [0.20542799006216228] took 27.690194606781006\n",
      "Validation loss EPOCH: [921|1000], validation loss: [0.3131567994132638], AE loss: [0.14249525382183492], TF loss: [0.1706615425646305]\n",
      "Training loss EPOCH: [922|1000], training loss: [0.44954521069303155], AE loss: [0.2442688443697989], TF loss: [0.2052763677202165] took 24.51648473739624\n",
      "Validation loss EPOCH: [922|1000], validation loss: [0.31348412204533815], AE loss: [0.1430882157292217], TF loss: [0.17039590422064066]\n",
      "Training loss EPOCH: [923|1000], training loss: [0.46020721225067973], AE loss: [0.2549720788374543], TF loss: [0.2052351322490722] took 29.296951055526733\n",
      "Validation loss EPOCH: [923|1000], validation loss: [0.313817897811532], AE loss: [0.142799575580284], TF loss: [0.17101832339540124]\n",
      "Training loss EPOCH: [924|1000], training loss: [0.4555959445424378], AE loss: [0.25020568212494254], TF loss: [0.20539026358164847] took 25.53460955619812\n",
      "Validation loss EPOCH: [924|1000], validation loss: [0.3129686154425144], AE loss: [0.14198107924312353], TF loss: [0.17098753433674574]\n",
      "Training loss EPOCH: [925|1000], training loss: [0.45482171420007944], AE loss: [0.2495280303992331], TF loss: [0.2052936835680157] took 29.73050856590271\n",
      "Validation loss EPOCH: [925|1000], validation loss: [0.31475632451474667], AE loss: [0.1432341868057847], TF loss: [0.1715221367776394]\n",
      "Training loss EPOCH: [926|1000], training loss: [0.44971149507910013], AE loss: [0.24436666071414948], TF loss: [0.20534483226947486] took 28.796560049057007\n",
      "Validation loss EPOCH: [926|1000], validation loss: [0.3143934290856123], AE loss: [0.14323254162445664], TF loss: [0.17116088746115565]\n",
      "Training loss EPOCH: [927|1000], training loss: [0.4535014289431274], AE loss: [0.24808758054859936], TF loss: [0.20541385002434254] took 29.44226050376892\n",
      "Validation loss EPOCH: [927|1000], validation loss: [0.3146054679527879], AE loss: [0.14284705417230725], TF loss: [0.17175841704010963]\n",
      "Training loss EPOCH: [928|1000], training loss: [0.4523815531283617], AE loss: [0.2471175198443234], TF loss: [0.2052640337496996] took 29.208330154418945\n",
      "Validation loss EPOCH: [928|1000], validation loss: [0.31416177470237017], AE loss: [0.1433343410026282], TF loss: [0.1708274302072823]\n",
      "Training loss EPOCH: [929|1000], training loss: [0.4597583026625216], AE loss: [0.25455751875415444], TF loss: [0.2052007836755365] took 27.220612287521362\n",
      "Validation loss EPOCH: [929|1000], validation loss: [0.3142541414126754], AE loss: [0.14305119100026786], TF loss: [0.171202948782593]\n",
      "Training loss EPOCH: [930|1000], training loss: [0.45296749845147133], AE loss: [0.24765024799853563], TF loss: [0.20531724928878248] took 28.258314847946167\n",
      "Validation loss EPOCH: [930|1000], validation loss: [0.3136995891109109], AE loss: [0.14288681861944497], TF loss: [0.17081277212128043]\n",
      "Training loss EPOCH: [931|1000], training loss: [0.45109031768515706], AE loss: [0.24593351315706968], TF loss: [0.20515680313110352] took 27.80375337600708\n",
      "Validation loss EPOCH: [931|1000], validation loss: [0.3144970601424575], AE loss: [0.14328142115846276], TF loss: [0.17121563525870442]\n",
      "Training loss EPOCH: [932|1000], training loss: [0.45527431508526206], AE loss: [0.25015709712170064], TF loss: [0.20511721749790013] took 26.493962287902832\n",
      "Validation loss EPOCH: [932|1000], validation loss: [0.31379276514053345], AE loss: [0.14324450329877436], TF loss: [0.17054826021194458]\n",
      "Training loss EPOCH: [933|1000], training loss: [0.45032401382923126], AE loss: [0.24527571140788496], TF loss: [0.2050483024213463] took 29.2893226146698\n",
      "Validation loss EPOCH: [933|1000], validation loss: [0.31364569067955017], AE loss: [0.1432459014467895], TF loss: [0.17039978969842196]\n",
      "Training loss EPOCH: [934|1000], training loss: [0.449979149736464], AE loss: [0.2447164033073932], TF loss: [0.20526274549774826] took 26.57166814804077\n",
      "Validation loss EPOCH: [934|1000], validation loss: [0.3142391899600625], AE loss: [0.14315778226591647], TF loss: [0.17108140466734767]\n",
      "Training loss EPOCH: [935|1000], training loss: [0.4590385244227946], AE loss: [0.2536452782806009], TF loss: [0.2053932456765324] took 30.592305898666382\n",
      "Validation loss EPOCH: [935|1000], validation loss: [0.31448167003691196], AE loss: [0.1431460517924279], TF loss: [0.17133561661466956]\n",
      "Training loss EPOCH: [936|1000], training loss: [0.454336651135236], AE loss: [0.24939737073145807], TF loss: [0.2049392806366086] took 27.708987712860107\n",
      "Validation loss EPOCH: [936|1000], validation loss: [0.31433151569217443], AE loss: [0.14321649982593954], TF loss: [0.17111501563340425]\n",
      "Training loss EPOCH: [937|1000], training loss: [0.4551335764117539], AE loss: [0.24984597717411816], TF loss: [0.20528759993612766] took 25.416337251663208\n",
      "Validation loss EPOCH: [937|1000], validation loss: [0.31378856766968966], AE loss: [0.14305575261823833], TF loss: [0.17073281528428197]\n",
      "Training loss EPOCH: [938|1000], training loss: [0.45205458672717214], AE loss: [0.24675720185041428], TF loss: [0.205297383479774] took 25.13523840904236\n",
      "Validation loss EPOCH: [938|1000], validation loss: [0.31467395555227995], AE loss: [0.14338072715327144], TF loss: [0.17129323026165366]\n",
      "Training loss EPOCH: [939|1000], training loss: [0.4510476849973202], AE loss: [0.24576476658694446], TF loss: [0.20528291747905314] took 24.54476308822632\n",
      "Validation loss EPOCH: [939|1000], validation loss: [0.3148073023185134], AE loss: [0.144357037730515], TF loss: [0.17045026365667582]\n",
      "Training loss EPOCH: [940|1000], training loss: [0.4589017201215029], AE loss: [0.2536556604318321], TF loss: [0.20524605666287243] took 30.16931653022766\n",
      "Validation loss EPOCH: [940|1000], validation loss: [0.31363906618207693], AE loss: [0.142625275766477], TF loss: [0.171013789717108]\n",
      "Training loss EPOCH: [941|1000], training loss: [0.45243854727596045], AE loss: [0.24716590787284076], TF loss: [0.20527263940311968] took 28.92140293121338\n",
      "Validation loss EPOCH: [941|1000], validation loss: [0.3139006644487381], AE loss: [0.14311776403337717], TF loss: [0.17078290414065123]\n",
      "Training loss EPOCH: [942|1000], training loss: [0.4510299460962415], AE loss: [0.24564892915077507], TF loss: [0.20538101717829704] took 25.35541796684265\n",
      "Validation loss EPOCH: [942|1000], validation loss: [0.313830797560513], AE loss: [0.14280399912968278], TF loss: [0.1710267998278141]\n",
      "Training loss EPOCH: [943|1000], training loss: [0.4529187688603997], AE loss: [0.2477063392288983], TF loss: [0.2052124289330095] took 26.75156545639038\n",
      "Validation loss EPOCH: [943|1000], validation loss: [0.3135344395413995], AE loss: [0.14307032199576497], TF loss: [0.17046411940827966]\n",
      "Training loss EPOCH: [944|1000], training loss: [0.4504941077902913], AE loss: [0.245436746859923], TF loss: [0.20505736046470702] took 23.897906064987183\n",
      "Validation loss EPOCH: [944|1000], validation loss: [0.3148448057472706], AE loss: [0.14330870541743934], TF loss: [0.17153609916567802]\n",
      "Training loss EPOCH: [945|1000], training loss: [0.4575820886529982], AE loss: [0.25241086375899613], TF loss: [0.205171225592494] took 23.6877019405365\n",
      "Validation loss EPOCH: [945|1000], validation loss: [0.3145197508856654], AE loss: [0.14338249480351806], TF loss: [0.1711372546851635]\n",
      "Training loss EPOCH: [946|1000], training loss: [0.4540544915944338], AE loss: [0.24892775155603886], TF loss: [0.20512674027122557] took 28.126523733139038\n",
      "Validation loss EPOCH: [946|1000], validation loss: [0.31373156234622], AE loss: [0.14265817822888494], TF loss: [0.1710733831860125]\n",
      "Training loss EPOCH: [947|1000], training loss: [0.45540406461805105], AE loss: [0.25011442485265434], TF loss: [0.20528963976539671] took 26.43737292289734\n",
      "Validation loss EPOCH: [947|1000], validation loss: [0.31275567784905434], AE loss: [0.1425395137630403], TF loss: [0.1702161650173366]\n",
      "Training loss EPOCH: [948|1000], training loss: [0.4524798602797091], AE loss: [0.24709708336740732], TF loss: [0.20538277574814856] took 28.41298198699951\n",
      "Validation loss EPOCH: [948|1000], validation loss: [0.3146397387608886], AE loss: [0.1433812843170017], TF loss: [0.17125845467671752]\n",
      "Training loss EPOCH: [949|1000], training loss: [0.4540873649530113], AE loss: [0.2487756283953786], TF loss: [0.20531173492781818] took 25.197510242462158\n",
      "Validation loss EPOCH: [949|1000], validation loss: [0.3123005470260978], AE loss: [0.14239931432530284], TF loss: [0.16990123083814979]\n",
      "Training loss EPOCH: [950|1000], training loss: [0.4490118226967752], AE loss: [0.2437704592011869], TF loss: [0.20524136233143508] took 29.931142330169678\n",
      "Validation loss EPOCH: [950|1000], validation loss: [0.31429011560976505], AE loss: [0.14327174122445285], TF loss: [0.17101837741211057]\n",
      "Training loss EPOCH: [951|1000], training loss: [0.4573197443969548], AE loss: [0.25224031531251967], TF loss: [0.20507942931726575] took 25.98654055595398\n",
      "Validation loss EPOCH: [951|1000], validation loss: [0.3133777305483818], AE loss: [0.14250978850759566], TF loss: [0.1708679385483265]\n",
      "Training loss EPOCH: [952|1000], training loss: [0.45930617954581976], AE loss: [0.2540458410512656], TF loss: [0.20526033686473966] took 27.46890139579773\n",
      "Validation loss EPOCH: [952|1000], validation loss: [0.31384746078401804], AE loss: [0.1425361626315862], TF loss: [0.17131129978224635]\n",
      "Training loss EPOCH: [953|1000], training loss: [0.4517655740492046], AE loss: [0.24667238118126988], TF loss: [0.20509319310076535] took 23.427465438842773\n",
      "Validation loss EPOCH: [953|1000], validation loss: [0.31345160491764545], AE loss: [0.14296338125132024], TF loss: [0.17048822296783328]\n",
      "Training loss EPOCH: [954|1000], training loss: [0.4524986236356199], AE loss: [0.2473573093302548], TF loss: [0.2051413138397038] took 27.790456533432007\n",
      "Validation loss EPOCH: [954|1000], validation loss: [0.3142142593860626], AE loss: [0.1427797586657107], TF loss: [0.17143450025469065]\n",
      "Training loss EPOCH: [955|1000], training loss: [0.44822788890451193], AE loss: [0.24315585242584348], TF loss: [0.2050720346160233] took 29.076545238494873\n",
      "Validation loss EPOCH: [955|1000], validation loss: [0.31411286257207394], AE loss: [0.14334239880554378], TF loss: [0.17077046120539308]\n",
      "Training loss EPOCH: [956|1000], training loss: [0.45778412465006113], AE loss: [0.25256736180745065], TF loss: [0.20521676097996533] took 20.974968910217285\n",
      "Validation loss EPOCH: [956|1000], validation loss: [0.31514821108430624], AE loss: [0.1436449741013348], TF loss: [0.171503237914294]\n",
      "Training loss EPOCH: [957|1000], training loss: [0.4545394042506814], AE loss: [0.24933732557110488], TF loss: [0.20520207774825394] took 24.686529874801636\n",
      "Validation loss EPOCH: [957|1000], validation loss: [0.31366823986172676], AE loss: [0.14274877309799194], TF loss: [0.17091946955770254]\n",
      "Training loss EPOCH: [958|1000], training loss: [0.45369391376152635], AE loss: [0.2483337614685297], TF loss: [0.205360152060166] took 22.236146688461304\n",
      "Validation loss EPOCH: [958|1000], validation loss: [0.3149471627548337], AE loss: [0.1431134040467441], TF loss: [0.1718337582424283]\n",
      "Training loss EPOCH: [959|1000], training loss: [0.44960451824590564], AE loss: [0.24445504369214177], TF loss: [0.2051494736224413] took 27.828901767730713\n",
      "Validation loss EPOCH: [959|1000], validation loss: [0.3136917548254132], AE loss: [0.14298135414719582], TF loss: [0.17071039974689484]\n",
      "Training loss EPOCH: [960|1000], training loss: [0.44843898992985487], AE loss: [0.2431925639975816], TF loss: [0.20524642523378134] took 28.53121781349182\n",
      "Validation loss EPOCH: [960|1000], validation loss: [0.3137783231213689], AE loss: [0.1431172713637352], TF loss: [0.17066105036064982]\n",
      "Training loss EPOCH: [961|1000], training loss: [0.4596069846302271], AE loss: [0.25431381026282907], TF loss: [0.2052931736689061] took 25.518691539764404\n",
      "Validation loss EPOCH: [961|1000], validation loss: [0.3131914082914591], AE loss: [0.14230603026226163], TF loss: [0.1708853803575039]\n",
      "Training loss EPOCH: [962|1000], training loss: [0.45075895404443145], AE loss: [0.24553939467296004], TF loss: [0.2052195598371327] took 26.643873691558838\n",
      "Validation loss EPOCH: [962|1000], validation loss: [0.31431033834815025], AE loss: [0.1431088405661285], TF loss: [0.17120149824768305]\n",
      "Training loss EPOCH: [963|1000], training loss: [0.45116576785221696], AE loss: [0.24616864509880543], TF loss: [0.20499712508171797] took 26.478854417800903\n",
      "Validation loss EPOCH: [963|1000], validation loss: [0.3133679525926709], AE loss: [0.143180669285357], TF loss: [0.17018727865070105]\n",
      "Training loss EPOCH: [964|1000], training loss: [0.44934381265193224], AE loss: [0.24422480631619692], TF loss: [0.20511900633573532] took 25.37276291847229\n",
      "Validation loss EPOCH: [964|1000], validation loss: [0.3145216088742018], AE loss: [0.14358425699174404], TF loss: [0.17093735095113516]\n",
      "Training loss EPOCH: [965|1000], training loss: [0.4549139179289341], AE loss: [0.2498558305669576], TF loss: [0.20505808712914586] took 29.588438749313354\n",
      "Validation loss EPOCH: [965|1000], validation loss: [0.31395498383790255], AE loss: [0.14293124177493155], TF loss: [0.1710237404331565]\n",
      "Training loss EPOCH: [966|1000], training loss: [0.45462782960385084], AE loss: [0.24954819842241704], TF loss: [0.2050796295516193] took 28.76794743537903\n",
      "Validation loss EPOCH: [966|1000], validation loss: [0.3135993480682373], AE loss: [0.14266514498740435], TF loss: [0.17093420587480068]\n",
      "Training loss EPOCH: [967|1000], training loss: [0.45405619079247117], AE loss: [0.24908411595970392], TF loss: [0.20497207529842854] took 26.088982105255127\n",
      "Validation loss EPOCH: [967|1000], validation loss: [0.3143648514524102], AE loss: [0.14335198421031237], TF loss: [0.171012865845114]\n",
      "Training loss EPOCH: [968|1000], training loss: [0.45184944616630673], AE loss: [0.24666630732826889], TF loss: [0.20518313883803785] took 27.078941822052002\n",
      "Validation loss EPOCH: [968|1000], validation loss: [0.3134483937174082], AE loss: [0.14299376518465579], TF loss: [0.17045462876558304]\n",
      "Training loss EPOCH: [969|1000], training loss: [0.4506560177542269], AE loss: [0.24551390972919762], TF loss: [0.20514210546389222] took 29.12394404411316\n",
      "Validation loss EPOCH: [969|1000], validation loss: [0.3137925937771797], AE loss: [0.14296603458933532], TF loss: [0.17082655942067504]\n",
      "Training loss EPOCH: [970|1000], training loss: [0.4570764824748039], AE loss: [0.25204391428269446], TF loss: [0.20503257028758526] took 26.67833423614502\n",
      "Validation loss EPOCH: [970|1000], validation loss: [0.31293613091111183], AE loss: [0.14241323433816433], TF loss: [0.17052289750427008]\n",
      "Training loss EPOCH: [971|1000], training loss: [0.4510791474021971], AE loss: [0.24580098129808903], TF loss: [0.20527816866524518] took 27.8169686794281\n",
      "Validation loss EPOCH: [971|1000], validation loss: [0.3136731069535017], AE loss: [0.1427660493645817], TF loss: [0.17090705689042807]\n",
      "Training loss EPOCH: [972|1000], training loss: [0.4517909395508468], AE loss: [0.24660421046428382], TF loss: [0.20518672885373235] took 26.684273958206177\n",
      "Validation loss EPOCH: [972|1000], validation loss: [0.3141598515212536], AE loss: [0.1430796894710511], TF loss: [0.17108016135171056]\n",
      "Training loss EPOCH: [973|1000], training loss: [0.45566090289503336], AE loss: [0.2505576254334301], TF loss: [0.20510327839292586] took 28.099980115890503\n",
      "Validation loss EPOCH: [973|1000], validation loss: [0.3142202915623784], AE loss: [0.14290763856843114], TF loss: [0.1713126515969634]\n",
      "Training loss EPOCH: [974|1000], training loss: [0.4516550558619201], AE loss: [0.24640399729833007], TF loss: [0.2052510587964207] took 28.04895257949829\n",
      "Validation loss EPOCH: [974|1000], validation loss: [0.31348091177642345], AE loss: [0.14309539832174778], TF loss: [0.17038551811128855]\n",
      "Training loss EPOCH: [975|1000], training loss: [0.45214252080768347], AE loss: [0.24711823626421392], TF loss: [0.20502428454346955] took 26.8565890789032\n",
      "Validation loss EPOCH: [975|1000], validation loss: [0.3144619967788458], AE loss: [0.1434653690084815], TF loss: [0.1709966310299933]\n",
      "Training loss EPOCH: [976|1000], training loss: [0.4495175485499203], AE loss: [0.24443344376049936], TF loss: [0.2050841054879129] took 18.011208295822144\n",
      "Validation loss EPOCH: [976|1000], validation loss: [0.3133630771189928], AE loss: [0.14289524499326944], TF loss: [0.17046783305704594]\n",
      "Training loss EPOCH: [977|1000], training loss: [0.44686148408800364], AE loss: [0.24177751457318664], TF loss: [0.2050839716102928] took 27.25548815727234\n",
      "Validation loss EPOCH: [977|1000], validation loss: [0.3146820953115821], AE loss: [0.1433354071341455], TF loss: [0.17134668724611402]\n",
      "Training loss EPOCH: [978|1000], training loss: [0.4564473954960704], AE loss: [0.25133812171407044], TF loss: [0.2051092702895403] took 25.382097721099854\n",
      "Validation loss EPOCH: [978|1000], validation loss: [0.3134347777813673], AE loss: [0.14281219523400068], TF loss: [0.1706225834786892]\n",
      "Training loss EPOCH: [979|1000], training loss: [0.4485712517052889], AE loss: [0.2434424082748592], TF loss: [0.20512884273193777] took 27.039106607437134\n",
      "Validation loss EPOCH: [979|1000], validation loss: [0.3149807685986161], AE loss: [0.14366938173770905], TF loss: [0.17131138546392322]\n",
      "Training loss EPOCH: [980|1000], training loss: [0.45616578310728073], AE loss: [0.25119018694385886], TF loss: [0.2049755968619138] took 26.71399998664856\n",
      "Validation loss EPOCH: [980|1000], validation loss: [0.3118379535153508], AE loss: [0.14173501753248274], TF loss: [0.17010293575003743]\n",
      "Training loss EPOCH: [981|1000], training loss: [0.4527572034858167], AE loss: [0.2475484935566783], TF loss: [0.2052087103947997] took 24.972366333007812\n",
      "Validation loss EPOCH: [981|1000], validation loss: [0.31433446891605854], AE loss: [0.14310002559795976], TF loss: [0.17123444564640522]\n",
      "Training loss EPOCH: [982|1000], training loss: [0.4518408323638141], AE loss: [0.2468026306014508], TF loss: [0.2050382022280246] took 29.173888206481934\n",
      "Validation loss EPOCH: [982|1000], validation loss: [0.314265307970345], AE loss: [0.14315453451126814], TF loss: [0.1711107729934156]\n",
      "Training loss EPOCH: [983|1000], training loss: [0.4495180700905621], AE loss: [0.24437808245420456], TF loss: [0.20513998647220433] took 28.639365673065186\n",
      "Validation loss EPOCH: [983|1000], validation loss: [0.3143985737115145], AE loss: [0.14308501034975052], TF loss: [0.1713135652244091]\n",
      "Training loss EPOCH: [984|1000], training loss: [0.45198072120547295], AE loss: [0.24692806764505804], TF loss: [0.20505265449173748] took 27.558988571166992\n",
      "Validation loss EPOCH: [984|1000], validation loss: [0.31346617825329304], AE loss: [0.14298321143724024], TF loss: [0.1704829651862383]\n",
      "Training loss EPOCH: [985|1000], training loss: [0.45868537202477455], AE loss: [0.25373172922991216], TF loss: [0.2049536423292011] took 26.48685050010681\n",
      "Validation loss EPOCH: [985|1000], validation loss: [0.31440657656639814], AE loss: [0.14293067809194326], TF loss: [0.17147589707747102]\n",
      "Training loss EPOCH: [986|1000], training loss: [0.45738580729812384], AE loss: [0.2525781854055822], TF loss: [0.20480762142688036] took 26.392868280410767\n",
      "Validation loss EPOCH: [986|1000], validation loss: [0.3142639212310314], AE loss: [0.1426399031188339], TF loss: [0.17162401834502816]\n",
      "Training loss EPOCH: [987|1000], training loss: [0.45170483412221074], AE loss: [0.2467898998875171], TF loss: [0.20491493586450815] took 28.102560997009277\n",
      "Validation loss EPOCH: [987|1000], validation loss: [0.3133595287799835], AE loss: [0.14204877009615302], TF loss: [0.1713107582181692]\n",
      "Training loss EPOCH: [988|1000], training loss: [0.4580803466960788], AE loss: [0.25298159499652684], TF loss: [0.20509874913841486] took 31.178409576416016\n",
      "Validation loss EPOCH: [988|1000], validation loss: [0.3130936147645116], AE loss: [0.1428309939801693], TF loss: [0.17026261938735843]\n",
      "Training loss EPOCH: [989|1000], training loss: [0.45317394053563476], AE loss: [0.24817346036434174], TF loss: [0.2050004794728011] took 21.9028377532959\n",
      "Validation loss EPOCH: [989|1000], validation loss: [0.3141117412596941], AE loss: [0.14290049741975963], TF loss: [0.17121124221011996]\n",
      "Training loss EPOCH: [990|1000], training loss: [0.4487957078963518], AE loss: [0.2437227878253907], TF loss: [0.20507292007096112] took 27.656697750091553\n",
      "Validation loss EPOCH: [990|1000], validation loss: [0.3133146921172738], AE loss: [0.14282866101711988], TF loss: [0.1704860352911055]\n",
      "Training loss EPOCH: [991|1000], training loss: [0.4505715947598219], AE loss: [0.24566841963678598], TF loss: [0.2049031751230359] took 24.302966117858887\n",
      "Validation loss EPOCH: [991|1000], validation loss: [0.31457980535924435], AE loss: [0.14260325231589377], TF loss: [0.1719765542075038]\n",
      "Training loss EPOCH: [992|1000], training loss: [0.44772871024906635], AE loss: [0.24276051297783852], TF loss: [0.2049681949429214] took 26.94097661972046\n",
      "Validation loss EPOCH: [992|1000], validation loss: [0.31418085750192404], AE loss: [0.14298452762886882], TF loss: [0.17119633220136166]\n",
      "Training loss EPOCH: [993|1000], training loss: [0.4644905449822545], AE loss: [0.2594659700989723], TF loss: [0.20502457628026605] took 26.9514799118042\n",
      "Validation loss EPOCH: [993|1000], validation loss: [0.31304273940622807], AE loss: [0.14192831725813448], TF loss: [0.17111442424356937]\n",
      "Training loss EPOCH: [994|1000], training loss: [0.4543267199769616], AE loss: [0.24937194189988077], TF loss: [0.20495478063821793] took 27.63434672355652\n",
      "Validation loss EPOCH: [994|1000], validation loss: [0.31285124365240335], AE loss: [0.14245622884482145], TF loss: [0.1703950148075819]\n",
      "Training loss EPOCH: [995|1000], training loss: [0.4571485542692244], AE loss: [0.25206412584520876], TF loss: [0.205084428191185] took 28.219726085662842\n",
      "Validation loss EPOCH: [995|1000], validation loss: [0.31399523187428713], AE loss: [0.14225733513012528], TF loss: [0.1717378944158554]\n",
      "Training loss EPOCH: [996|1000], training loss: [0.44733908167108893], AE loss: [0.24232583050616086], TF loss: [0.20501325139775872] took 27.06695580482483\n",
      "Validation loss EPOCH: [996|1000], validation loss: [0.31397385988384485], AE loss: [0.14273251919075847], TF loss: [0.1712413402274251]\n",
      "Training loss EPOCH: [997|1000], training loss: [0.4572625649161637], AE loss: [0.25235939770936966], TF loss: [0.20490316534414887] took 28.36059260368347\n",
      "Validation loss EPOCH: [997|1000], validation loss: [0.31322366278618574], AE loss: [0.14258317067287862], TF loss: [0.17064049234613776]\n",
      "Training loss EPOCH: [998|1000], training loss: [0.45362016139551997], AE loss: [0.2487058131955564], TF loss: [0.20491434866562486] took 25.81874942779541\n",
      "Validation loss EPOCH: [998|1000], validation loss: [0.31415544357150793], AE loss: [0.14278622576966882], TF loss: [0.1713692182675004]\n",
      "Training loss EPOCH: [999|1000], training loss: [0.45013807294890285], AE loss: [0.24508603871800005], TF loss: [0.20505203306674957] took 20.68108057975769\n",
      "Validation loss EPOCH: [999|1000], validation loss: [0.31393340416252613], AE loss: [0.1430000071413815], TF loss: [0.17093339376151562]\n",
      "Training loss EPOCH: [1000|1000], training loss: [0.4489715415984392], AE loss: [0.24417182616889477], TF loss: [0.2047997135668993] took 27.751107931137085\n",
      "Validation loss EPOCH: [1000|1000], validation loss: [0.3138813842087984], AE loss: [0.14291998511180282], TF loss: [0.17096139956265688]\n"
     ]
    }
   ],
   "source": [
    "model_name = 'SalGATConvGRUwoAll_saliency_MSL'\n",
    "BEST_MODEL, LOSS_HISTORY, LOSS_HISTORY_AE, LOSS_HISTORY_TF = train_model(train_loader, val_loader, MODEL, batch_size, 1000, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'SalGATConvGRUwo_saliency_MSL'\n",
    "with open(\"result/model_\" + model_name + \"_best.pt\", \"rb\") as f:\n",
    "    SAVED_MODEL = torch.load(f)\n",
    "\n",
    "print(SAVED_MODEL['best_epoch'])\n",
    "\n",
    "\n",
    "MODEL = SalGATConvGRU(seq_len=window_size, output_len=10, n_features=x_train.shape[1], out_n_features=x_train.shape[1], embedding_dim=int(x_train.shape[1]/2), kernel_size=3, cell='gru')\n",
    "# MODEL = SalGATConvGRUwoSal(seq_len=window_size, output_len=10, n_features=x_train.shape[1], out_n_features=x_train.shape[1], embedding_dim=int(x_train.shape[1]/2), kernel_size=3, cell='gru')\n",
    "# MODEL = SalConvGRUwoALL(seq_len=window_size, output_len=10, n_features=x_train.shape[1], out_n_features=x_train.shape[1], embedding_dim=int(x_train.shape[1]/2), kernel_size=3, cell='gru')\n",
    "\n",
    "MODEL.cuda()    \n",
    "MODEL.load_state_dict(SAVED_MODEL[\"state\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_SAL(dataloader, model, batch_size, TF_alpha):\n",
    "    dist, dist_sal, fin_dist1, fin_dist2, guess, sal_list = [], [], [], [], [], []\n",
    "    mse = torch.nn.MSELoss()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (x,y_recon,y_fore) in enumerate(dataloader):\n",
    "            x = x.cuda()\n",
    "            y_recon = y_recon.cuda()\n",
    "            y_fore = y_fore.cuda()\n",
    "            \n",
    "            sal, dec_x, out = model(x)\n",
    "            \n",
    "            for y_r, y_f, d, o in zip(y_recon, y_fore, dec_x, out):\n",
    "                d_s = torch.sum(torch.square(y_r - d)).cpu().numpy()\n",
    "                d_o = torch.sum(torch.square(y_f - o)).cpu().numpy()\n",
    "                # d_s = torch.mean(torch.square(y_r - d)).cpu().numpy()\n",
    "                # d_o = torch.mean(torch.square(y_f - o)).cpu().numpy()\n",
    "                \n",
    "                dist_sal.append(d_s)\n",
    "                dist.append(d_o)\n",
    "\n",
    "                # inference_score1 = (d_s + d_o)/(1+TF_alpha)\n",
    "                inference_score1 = ((1-TF_alpha)*d_s + TF_alpha*d_o)/(1+TF_alpha)\n",
    "                inference_score2 = (d_s + TF_alpha*d_o)/(1+TF_alpha)\n",
    "                fin_dist1.append(inference_score1)\n",
    "                fin_dist2.append(inference_score2)\n",
    "                # fin_dist.append((1-TF_alpha)*mse(y_s,d).item() + TF_alpha*mse(y_s, o).item())\n",
    "                # fin_dist.append((TF_alpha*torch.cdist(y_s, o, p=2.0) + (1-TF_alpha)*torch.cdist(y_s, d, p=2.0)).cpu().numpy())\n",
    "\n",
    "            guess.append(out.cpu().numpy())\n",
    "            sal_list.append(sal.cpu().numpy())\n",
    "        \n",
    "            \n",
    "    return (\n",
    "        dist,\n",
    "        dist_sal,\n",
    "        fin_dist1,\n",
    "        fin_dist2,\n",
    "        np.concatenate(guess),\n",
    "        np.concatenate(sal_list)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20min 19s, sys: 33.4 s, total: 20min 52s\n",
      "Wall time: 29.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "MODEL.eval()\n",
    "DIST, DIST_SAL, FIN_DIST1, FIN_DIST2, GUESS, SAL_LIST = inference_SAL(test_loader, MODEL, batch_size, TF_alpha=1.0)\n",
    "DIST_train, DIST_SAL_train, FIN_DIST1_train, FIN_DIST2_train, GUESS_train, SAL_LIST_train = inference_SAL(train_loader, MODEL, batch_size, TF_alpha=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "res = SAL_LIST[:,-1:,:]\n",
    "res = res.reshape(res.shape[0], res.shape[2])\n",
    "res_mean = np.mean(res, axis=1)\n",
    "FD2wSAL = np.array(FIN_DIST2)*res_mean\n",
    "\n",
    "res_train = SAL_LIST_train[:,-1:,:]\n",
    "res_train = res_train.reshape(res_train.shape[0], res_train.shape[2])\n",
    "res_mean_train = np.mean(res_train, axis=1)\n",
    "FD2wSAL_train = np.array(FIN_DIST2_train)*res_mean_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "saliency",
   "language": "python",
   "name": "saliency"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
